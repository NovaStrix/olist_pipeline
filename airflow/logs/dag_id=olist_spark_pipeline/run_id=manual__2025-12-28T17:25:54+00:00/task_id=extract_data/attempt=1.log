{"timestamp":"2025-12-28T17:26:18.654537Z","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2025-12-28T17:26:18.686354Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/ecom_pipeline.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2025-12-28T17:26:20.219927Z","level":"warning","event":"The `airflow.hooks.base.BaseHook` attribute is deprecated. Please use `'airflow.sdk.bases.hook.BaseHook'`.","category":"DeprecatedImportWarning","filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py","lineno":35,"logger":"py.warnings"}
{"timestamp":"2025-12-28T17:26:20.989048Z","level":"info","event":"Task instance is in running state","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:26:20.994603Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:26:20.998640Z","level":"info","event":"Current task name:extract_data","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:26:20.999561Z","level":"info","event":"Dag name:olist_spark_pipeline","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:26:21.866300Z","level":"info","event":"Spark-Submit cmd: spark-submit --master local[*] --name arrow-spark --verbose --deploy-mode client /opt/airflow/src/extract.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":474}
{"timestamp":"2025-12-28T17:26:33.829121Z","level":"info","event":"Using properties file: null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.101514Z","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.103763Z","level":"info","event":"master                  local[*]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.104173Z","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.104241Z","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.105706Z","level":"info","event":"executorMemory          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.106677Z","level":"info","event":"executorCores           null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.106873Z","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.108012Z","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.109020Z","level":"info","event":"driverMemory            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.109085Z","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.109136Z","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.109198Z","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.109257Z","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.109392Z","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.109737Z","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.109829Z","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.110044Z","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.110135Z","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.110298Z","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.110343Z","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.110612Z","level":"info","event":"primaryResource         file:/opt/airflow/src/extract.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.110763Z","level":"info","event":"name                    arrow-spark","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.110882Z","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.110961Z","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.111082Z","level":"info","event":"packages                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.111183Z","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.111271Z","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.111394Z","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.111494Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.111650Z","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.112389Z","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.112454Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.112484Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.112508Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.613616Z","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.614969Z","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.615089Z","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.615127Z","level":"info","event":"file:/opt/airflow/src/extract.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.615166Z","level":"info","event":"null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.618022Z","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.618182Z","level":"info","event":"(spark.app.name,arrow-spark)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.618212Z","level":"info","event":"(spark.app.submitTime,1766942794590)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.618229Z","level":"info","event":"(spark.master,local[*])","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.618363Z","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.618393Z","level":"info","event":"(spark.submit.pyFiles,)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.618425Z","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.618460Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.618495Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:34.618537Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:39.094462Z","level":"info","event":"Downloading from https://www.kaggle.com/api/v1/datasets/download/olistbr/brazilian-ecommerce?dataset_version_number=2...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:39.136774Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:39.768698Z","level":"info","event":"0%|          | 0.00/42.6M [00:00<?, ?B/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:39.970704Z","level":"info","event":"2%|▏         | 1.00M/42.6M [00:00<00:26, 1.67MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:40.423893Z","level":"info","event":"5%|▍         | 2.00M/42.6M [00:00<00:15, 2.77MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:40.809982Z","level":"info","event":"7%|▋         | 3.00M/42.6M [00:01<00:16, 2.54MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:41.192356Z","level":"info","event":"9%|▉         | 4.00M/42.6M [00:01<00:15, 2.61MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:41.527957Z","level":"info","event":"12%|█▏        | 5.00M/42.6M [00:02<00:14, 2.65MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:41.923039Z","level":"info","event":"14%|█▍        | 6.00M/42.6M [00:02<00:13, 2.80MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:42.189900Z","level":"info","event":"16%|█▋        | 7.00M/42.6M [00:02<00:13, 2.75MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:42.600292Z","level":"info","event":"19%|█▉        | 8.00M/42.6M [00:03<00:11, 3.04MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:42.949449Z","level":"info","event":"21%|██        | 9.00M/42.6M [00:03<00:12, 2.87MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:43.287211Z","level":"info","event":"23%|██▎       | 10.0M/42.6M [00:03<00:11, 2.91MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:43.739529Z","level":"info","event":"26%|██▌       | 11.0M/42.6M [00:04<00:11, 2.97MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:44.127991Z","level":"info","event":"28%|██▊       | 12.0M/42.6M [00:04<00:11, 2.73MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:44.565823Z","level":"info","event":"30%|███       | 13.0M/42.6M [00:04<00:11, 2.72MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:44.931083Z","level":"info","event":"33%|███▎      | 14.0M/42.6M [00:05<00:11, 2.63MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:45.334059Z","level":"info","event":"35%|███▌      | 15.0M/42.6M [00:05<00:10, 2.68MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:45.794510Z","level":"info","event":"38%|███▊      | 16.0M/42.6M [00:06<00:10, 2.66MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:46.242658Z","level":"info","event":"40%|███▉      | 17.0M/42.6M [00:06<00:10, 2.53MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:46.783162Z","level":"info","event":"42%|████▏     | 18.0M/42.6M [00:07<00:10, 2.47MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:47.318364Z","level":"info","event":"45%|████▍     | 19.0M/42.6M [00:07<00:10, 2.28MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:47.801609Z","level":"info","event":"47%|████▋     | 20.0M/42.6M [00:08<00:10, 2.17MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:48.333862Z","level":"info","event":"49%|████▉     | 21.0M/42.6M [00:08<00:10, 2.17MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:48.874464Z","level":"info","event":"52%|█████▏    | 22.0M/42.6M [00:09<00:10, 2.13MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:49.555119Z","level":"info","event":"54%|█████▍    | 23.0M/42.6M [00:09<00:10, 2.05MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:50.344786Z","level":"info","event":"56%|█████▋    | 24.0M/42.6M [00:10<00:10, 1.87MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:51.163669Z","level":"info","event":"59%|█████▊    | 25.0M/42.6M [00:11<00:11, 1.66MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:51.816678Z","level":"info","event":"61%|██████    | 26.0M/42.6M [00:12<00:11, 1.53MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:52.539964Z","level":"info","event":"63%|██████▎   | 27.0M/42.6M [00:12<00:10, 1.55MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:53.147429Z","level":"info","event":"66%|██████▌   | 28.0M/42.6M [00:13<00:10, 1.52MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:53.741244Z","level":"info","event":"68%|██████▊   | 29.0M/42.6M [00:14<00:09, 1.58MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:54.343048Z","level":"info","event":"70%|███████   | 30.0M/42.6M [00:14<00:08, 1.63MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:55.058543Z","level":"info","event":"73%|███████▎  | 31.0M/42.6M [00:15<00:07, 1.66MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:55.775117Z","level":"info","event":"75%|███████▌  | 32.0M/42.6M [00:15<00:06, 1.60MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:56.583264Z","level":"info","event":"77%|███████▋  | 33.0M/42.6M [00:16<00:06, 1.55MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:57.534699Z","level":"info","event":"80%|███████▉  | 34.0M/42.6M [00:17<00:06, 1.47MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:58.462507Z","level":"info","event":"82%|████████▏ | 35.0M/42.6M [00:18<00:05, 1.34MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:59.333796Z","level":"info","event":"84%|████████▍ | 36.0M/42.6M [00:19<00:05, 1.26MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:26:59.982300Z","level":"info","event":"87%|████████▋ | 37.0M/42.6M [00:20<00:04, 1.24MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:00.504293Z","level":"info","event":"89%|████████▉ | 38.0M/42.6M [00:20<00:03, 1.34MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:01.311066Z","level":"info","event":"91%|█████████▏| 39.0M/42.6M [00:21<00:02, 1.49MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:02.433454Z","level":"info","event":"94%|█████████▍| 40.0M/42.6M [00:22<00:01, 1.43MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:03.415129Z","level":"info","event":"96%|█████████▌| 41.0M/42.6M [00:23<00:01, 1.23MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:03.990984Z","level":"info","event":"98%|█████████▊| 42.0M/42.6M [00:24<00:00, 1.18MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:03.992201Z","level":"info","event":"100%|██████████| 42.6M/42.6M [00:24<00:00, 1.18MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:03.992311Z","level":"info","event":"100%|██████████| 42.6M/42.6M [00:24<00:00, 1.80MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:04.021327Z","level":"info","event":"Extracting files...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:06.023568Z","level":"info","event":"Path to dataset files: /home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:07.313183Z","level":"info","event":"25/12/28 17:27:07 INFO SparkContext: Running Spark version 3.5.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:07.317810Z","level":"info","event":"25/12/28 17:27:07 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, aarch64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:07.318279Z","level":"info","event":"25/12/28 17:27:07 INFO SparkContext: Java version 17.0.17","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:07.450781Z","level":"info","event":"25/12/28 17:27:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:07.601245Z","level":"info","event":"25/12/28 17:27:07 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:07.601454Z","level":"info","event":"25/12/28 17:27:07 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:07.601783Z","level":"info","event":"25/12/28 17:27:07 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:07.602249Z","level":"info","event":"25/12/28 17:27:07 INFO SparkContext: Submitted application: Data Extraction","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:07.621312Z","level":"info","event":"25/12/28 17:27:07 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:07.629267Z","level":"info","event":"25/12/28 17:27:07 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:07.630585Z","level":"info","event":"25/12/28 17:27:07 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:07.755084Z","level":"info","event":"25/12/28 17:27:07 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:07.758831Z","level":"info","event":"25/12/28 17:27:07 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:07.758989Z","level":"info","event":"25/12/28 17:27:07 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:07.759299Z","level":"info","event":"25/12/28 17:27:07 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:07.759347Z","level":"info","event":"25/12/28 17:27:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:08.134985Z","level":"info","event":"25/12/28 17:27:08 INFO Utils: Successfully started service 'sparkDriver' on port 41685.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:08.205215Z","level":"info","event":"25/12/28 17:27:08 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:08.254981Z","level":"info","event":"25/12/28 17:27:08 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:08.274730Z","level":"info","event":"25/12/28 17:27:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:08.275258Z","level":"info","event":"25/12/28 17:27:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:08.280507Z","level":"info","event":"25/12/28 17:27:08 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:08.304914Z","level":"info","event":"25/12/28 17:27:08 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-56cb8393-3a7e-4f82-a490-83828a6fa090","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:08.321857Z","level":"info","event":"25/12/28 17:27:08 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:08.335294Z","level":"info","event":"25/12/28 17:27:08 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:08.585433Z","level":"info","event":"25/12/28 17:27:08 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:08.700191Z","level":"info","event":"25/12/28 17:27:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:08.903054Z","level":"info","event":"25/12/28 17:27:08 INFO Executor: Starting executor ID driver on host 28b45f86de62","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:08.903617Z","level":"info","event":"25/12/28 17:27:08 INFO Executor: OS info Linux, 6.10.14-linuxkit, aarch64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:08.903863Z","level":"info","event":"25/12/28 17:27:08 INFO Executor: Java version 17.0.17","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:08.909763Z","level":"info","event":"25/12/28 17:27:08 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:08.910200Z","level":"info","event":"25/12/28 17:27:08 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@3f5bdc65 for default.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:08.934037Z","level":"info","event":"25/12/28 17:27:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35353.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:08.934254Z","level":"info","event":"25/12/28 17:27:08 INFO NettyBlockTransferService: Server created on 28b45f86de62:35353","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:08.935932Z","level":"info","event":"25/12/28 17:27:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:08.940830Z","level":"info","event":"25/12/28 17:27:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 28b45f86de62, 35353, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:08.944086Z","level":"info","event":"25/12/28 17:27:08 INFO BlockManagerMasterEndpoint: Registering block manager 28b45f86de62:35353 with 434.4 MiB RAM, BlockManagerId(driver, 28b45f86de62, 35353, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:08.945719Z","level":"info","event":"25/12/28 17:27:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 28b45f86de62, 35353, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:08.946920Z","level":"info","event":"25/12/28 17:27:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 28b45f86de62, 35353, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:09.521102Z","level":"info","event":"25/12/28 17:27:09 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:09.528596Z","level":"info","event":"25/12/28 17:27:09 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:14.369872Z","level":"info","event":"25/12/28 17:27:14 INFO InMemoryFileIndex: It took 298 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:14.757413Z","level":"info","event":"25/12/28 17:27:14 INFO InMemoryFileIndex: It took 12 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:23.084280Z","level":"info","event":"25/12/28 17:27:23 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:23.093436Z","level":"info","event":"25/12/28 17:27:23 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:24.334084Z","level":"info","event":"25/12/28 17:27:24 INFO CodeGenerator: Code generated in 349.595834 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:24.400141Z","level":"info","event":"25/12/28 17:27:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 199.5 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:24.484829Z","level":"info","event":"25/12/28 17:27:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:24.500657Z","level":"info","event":"25/12/28 17:27:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 28b45f86de62:35353 (size: 34.2 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:24.512832Z","level":"info","event":"25/12/28 17:27:24 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:24.602021Z","level":"info","event":"25/12/28 17:27:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:24.915312Z","level":"info","event":"25/12/28 17:27:24 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.094639Z","level":"info","event":"25/12/28 17:27:25 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.097787Z","level":"info","event":"25/12/28 17:27:25 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.099680Z","level":"info","event":"25/12/28 17:27:25 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.107086Z","level":"info","event":"25/12/28 17:27:25 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.118181Z","level":"info","event":"25/12/28 17:27:25 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.392971Z","level":"info","event":"25/12/28 17:27:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 13.5 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.402069Z","level":"info","event":"25/12/28 17:27:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.403105Z","level":"info","event":"25/12/28 17:27:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 28b45f86de62:35353 (size: 6.4 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.404206Z","level":"info","event":"25/12/28 17:27:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.425132Z","level":"info","event":"25/12/28 17:27:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.428603Z","level":"info","event":"25/12/28 17:27:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.475406Z","level":"info","event":"25/12/28 17:27:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (28b45f86de62, executor driver, partition 0, PROCESS_LOCAL, 8291 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.493088Z","level":"info","event":"25/12/28 17:27:25 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.623510Z","level":"info","event":"25/12/28 17:27:25 INFO CodeGenerator: Code generated in 22.497792 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.629853Z","level":"info","event":"25/12/28 17:27:25 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.647187Z","level":"info","event":"25/12/28 17:27:25 INFO CodeGenerator: Code generated in 9.898375 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.712508Z","level":"info","event":"25/12/28 17:27:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1672 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.719939Z","level":"info","event":"25/12/28 17:27:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 262 ms on 28b45f86de62 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.721444Z","level":"info","event":"25/12/28 17:27:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.726887Z","level":"info","event":"25/12/28 17:27:25 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 0.510 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.742352Z","level":"info","event":"25/12/28 17:27:25 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.743578Z","level":"info","event":"25/12/28 17:27:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.752724Z","level":"info","event":"25/12/28 17:27:25 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 0.839229 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.790785Z","level":"info","event":"25/12/28 17:27:25 INFO CodeGenerator: Code generated in 9.975666 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.900476Z","level":"info","event":"25/12/28 17:27:25 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.900633Z","level":"info","event":"25/12/28 17:27:25 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.911392Z","level":"info","event":"25/12/28 17:27:25 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 199.5 KiB, free 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.936795Z","level":"info","event":"25/12/28 17:27:25 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.938454Z","level":"info","event":"25/12/28 17:27:25 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 28b45f86de62:35353 (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.941527Z","level":"info","event":"25/12/28 17:27:25 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:25.948443Z","level":"info","event":"25/12/28 17:27:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:26.158769Z","level":"info","event":"25/12/28 17:27:26 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:26.163852Z","level":"info","event":"25/12/28 17:27:26 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 3 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:26.164185Z","level":"info","event":"25/12/28 17:27:26 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:26.164576Z","level":"info","event":"25/12/28 17:27:26 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:26.166194Z","level":"info","event":"25/12/28 17:27:26 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:26.171051Z","level":"info","event":"25/12/28 17:27:26 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:26.233627Z","level":"info","event":"25/12/28 17:27:26 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 27.4 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:26.253789Z","level":"info","event":"25/12/28 17:27:26 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 12.6 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:26.257860Z","level":"info","event":"25/12/28 17:27:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 28b45f86de62:35353 (size: 12.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:26.259484Z","level":"info","event":"25/12/28 17:27:26 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:26.261158Z","level":"info","event":"25/12/28 17:27:26 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:26.261620Z","level":"info","event":"25/12/28 17:27:26 INFO TaskSchedulerImpl: Adding task set 1.0 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:26.267470Z","level":"info","event":"25/12/28 17:27:26 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (28b45f86de62, executor driver, partition 0, PROCESS_LOCAL, 8291 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:26.268634Z","level":"info","event":"25/12/28 17:27:26 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (28b45f86de62, executor driver, partition 1, PROCESS_LOCAL, 8291 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:26.269941Z","level":"info","event":"25/12/28 17:27:26 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (28b45f86de62, executor driver, partition 2, PROCESS_LOCAL, 8291 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:26.276294Z","level":"info","event":"25/12/28 17:27:26 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:26.276532Z","level":"info","event":"25/12/28 17:27:26 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:26.281498Z","level":"info","event":"25/12/28 17:27:26 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:26.431237Z","level":"info","event":"25/12/28 17:27:26 INFO CodeGenerator: Code generated in 43.66625 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:26.438299Z","level":"info","event":"25/12/28 17:27:26 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:26.438574Z","level":"info","event":"25/12/28 17:27:26 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:26.442167Z","level":"info","event":"25/12/28 17:27:26 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 8388608-9033957, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.000055Z","level":"info","event":"25/12/28 17:27:26 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1626 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.025675Z","level":"info","event":"25/12/28 17:27:27 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 755 ms on 28b45f86de62 (executor driver) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.101943Z","level":"info","event":"25/12/28 17:27:27 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 28b45f86de62:35353 in memory (size: 6.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.311603Z","level":"info","event":"25/12/28 17:27:27 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1626 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.317229Z","level":"info","event":"25/12/28 17:27:27 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1669 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.320459Z","level":"info","event":"25/12/28 17:27:27 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1052 ms on 28b45f86de62 (executor driver) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.321641Z","level":"info","event":"25/12/28 17:27:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1055 ms on 28b45f86de62 (executor driver) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.321738Z","level":"info","event":"25/12/28 17:27:27 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.322859Z","level":"info","event":"25/12/28 17:27:27 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 1.147 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.323938Z","level":"info","event":"25/12/28 17:27:27 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.324309Z","level":"info","event":"25/12/28 17:27:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.325366Z","level":"info","event":"25/12/28 17:27:27 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 1.165863 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.386717Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.493638Z","level":"info","event":"25/12/28 17:27:27 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.493840Z","level":"info","event":"25/12/28 17:27:27 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.529351Z","level":"info","event":"25/12/28 17:27:27 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 28b45f86de62:35353 in memory (size: 12.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.635836Z","level":"info","event":"25/12/28 17:27:27 INFO CodeGenerator: Code generated in 30.205375 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.649284Z","level":"info","event":"25/12/28 17:27:27 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 199.4 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.682569Z","level":"info","event":"25/12/28 17:27:27 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.686347Z","level":"info","event":"25/12/28 17:27:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 28b45f86de62:35353 (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.690228Z","level":"info","event":"25/12/28 17:27:27 INFO SparkContext: Created broadcast 4 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.709669Z","level":"info","event":"25/12/28 17:27:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.775454Z","level":"info","event":"25/12/28 17:27:27 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.779353Z","level":"info","event":"25/12/28 17:27:27 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 3 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.779689Z","level":"info","event":"25/12/28 17:27:27 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.781504Z","level":"info","event":"25/12/28 17:27:27 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.783568Z","level":"info","event":"25/12/28 17:27:27 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.789489Z","level":"info","event":"25/12/28 17:27:27 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.812121Z","level":"info","event":"25/12/28 17:27:27 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 17.8 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.818626Z","level":"info","event":"25/12/28 17:27:27 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.819466Z","level":"info","event":"25/12/28 17:27:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 28b45f86de62:35353 (size: 8.8 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.820393Z","level":"info","event":"25/12/28 17:27:27 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.825850Z","level":"info","event":"25/12/28 17:27:27 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.826465Z","level":"info","event":"25/12/28 17:27:27 INFO TaskSchedulerImpl: Adding task set 2.0 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.832894Z","level":"info","event":"25/12/28 17:27:27 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4) (28b45f86de62, executor driver, partition 0, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.833671Z","level":"info","event":"25/12/28 17:27:27 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5) (28b45f86de62, executor driver, partition 1, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.834280Z","level":"info","event":"25/12/28 17:27:27 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 6) (28b45f86de62, executor driver, partition 2, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.835656Z","level":"info","event":"25/12/28 17:27:27 INFO Executor: Running task 2.0 in stage 2.0 (TID 6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.835907Z","level":"info","event":"25/12/28 17:27:27 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.836010Z","level":"info","event":"25/12/28 17:27:27 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.882312Z","level":"info","event":"25/12/28 17:27:27 INFO CodeGenerator: Code generated in 19.418125 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.901867Z","level":"info","event":"25/12/28 17:27:27 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.902033Z","level":"info","event":"25/12/28 17:27:27 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.903268Z","level":"info","event":"25/12/28 17:27:27 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 8388608-9033957, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:27.909542Z","level":"info","event":"25/12/28 17:27:27 INFO CodeGenerator: Code generated in 6.000833 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.103197Z","level":"info","event":"25/12/28 17:27:28 INFO Executor: Finished task 2.0 in stage 2.0 (TID 6). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.122444Z","level":"info","event":"25/12/28 17:27:28 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 6) in 284 ms on 28b45f86de62 (executor driver) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.203480Z","level":"info","event":"25/12/28 17:27:28 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.204561Z","level":"info","event":"25/12/28 17:27:28 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.208053Z","level":"info","event":"25/12/28 17:27:28 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 376 ms on 28b45f86de62 (executor driver) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.209797Z","level":"info","event":"25/12/28 17:27:28 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 375 ms on 28b45f86de62 (executor driver) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.210041Z","level":"info","event":"25/12/28 17:27:28 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.216473Z","level":"info","event":"25/12/28 17:27:28 INFO DAGScheduler: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.417 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.219370Z","level":"info","event":"25/12/28 17:27:28 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.221369Z","level":"info","event":"25/12/28 17:27:28 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.225767Z","level":"info","event":"25/12/28 17:27:28 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.226902Z","level":"info","event":"25/12/28 17:27:28 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.376939Z","level":"info","event":"25/12/28 17:27:28 INFO CodeGenerator: Code generated in 48.018 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.454648Z","level":"info","event":"25/12/28 17:27:28 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.464928Z","level":"info","event":"25/12/28 17:27:28 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.465660Z","level":"info","event":"25/12/28 17:27:28 INFO DAGScheduler: Final stage: ResultStage 4 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.465766Z","level":"info","event":"25/12/28 17:27:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.465831Z","level":"info","event":"25/12/28 17:27:28 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.470390Z","level":"info","event":"25/12/28 17:27:28 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.505060Z","level":"info","event":"25/12/28 17:27:28 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 12.5 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.519837Z","level":"info","event":"25/12/28 17:27:28 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.522985Z","level":"info","event":"25/12/28 17:27:28 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 28b45f86de62:35353 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.524639Z","level":"info","event":"25/12/28 17:27:28 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.526352Z","level":"info","event":"25/12/28 17:27:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.526601Z","level":"info","event":"25/12/28 17:27:28 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.536973Z","level":"info","event":"25/12/28 17:27:28 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 7) (28b45f86de62, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.539392Z","level":"info","event":"25/12/28 17:27:28 INFO Executor: Running task 0.0 in stage 4.0 (TID 7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.615335Z","level":"info","event":"25/12/28 17:27:28 INFO ShuffleBlockFetcherIterator: Getting 3 (180.0 B) non-empty blocks including 3 (180.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.618427Z","level":"info","event":"25/12/28 17:27:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.648204Z","level":"info","event":"25/12/28 17:27:28 INFO CodeGenerator: Code generated in 18.191667 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.670983Z","level":"info","event":"25/12/28 17:27:28 INFO Executor: Finished task 0.0 in stage 4.0 (TID 7). 4038 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.673096Z","level":"info","event":"25/12/28 17:27:28 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 7) in 139 ms on 28b45f86de62 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.673687Z","level":"info","event":"25/12/28 17:27:28 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.674963Z","level":"info","event":"25/12/28 17:27:28 INFO DAGScheduler: ResultStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.180 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.675860Z","level":"info","event":"25/12/28 17:27:28 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.676168Z","level":"info","event":"25/12/28 17:27:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.678163Z","level":"info","event":"25/12/28 17:27:28 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.222789 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.690363Z","level":"info","event":"Loaded olist_customers with 99441 records.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.905431Z","level":"info","event":"25/12/28 17:27:28 INFO FileSourceStrategy: Pushed Filters: IsNull(customer_id)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:28.906319Z","level":"info","event":"25/12/28 17:27:28 INFO FileSourceStrategy: Post-Scan Filters: isnull(customer_id#17)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.002534Z","level":"info","event":"25/12/28 17:27:29 INFO CodeGenerator: Code generated in 34.373833 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.010357Z","level":"info","event":"25/12/28 17:27:29 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 199.4 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.064364Z","level":"info","event":"25/12/28 17:27:29 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 28b45f86de62:35353 in memory (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.076875Z","level":"info","event":"25/12/28 17:27:29 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.086355Z","level":"info","event":"25/12/28 17:27:29 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 28b45f86de62:35353 (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.088014Z","level":"info","event":"25/12/28 17:27:29 INFO SparkContext: Created broadcast 7 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.097066Z","level":"info","event":"25/12/28 17:27:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.104022Z","level":"info","event":"25/12/28 17:27:29 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 28b45f86de62:35353 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.108474Z","level":"info","event":"25/12/28 17:27:29 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.109613Z","level":"info","event":"25/12/28 17:27:29 INFO DAGScheduler: Got map stage job 4 (count at NativeMethodAccessorImpl.java:0) with 3 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.112447Z","level":"info","event":"25/12/28 17:27:29 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.112565Z","level":"info","event":"25/12/28 17:27:29 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.112590Z","level":"info","event":"25/12/28 17:27:29 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.113279Z","level":"info","event":"25/12/28 17:27:29 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.115123Z","level":"info","event":"25/12/28 17:27:29 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 28b45f86de62:35353 in memory (size: 8.8 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.126096Z","level":"info","event":"25/12/28 17:27:29 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 18.4 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.135690Z","level":"info","event":"25/12/28 17:27:29 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.138334Z","level":"info","event":"25/12/28 17:27:29 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 28b45f86de62:35353 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.141506Z","level":"info","event":"25/12/28 17:27:29 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.143634Z","level":"info","event":"25/12/28 17:27:29 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.143761Z","level":"info","event":"25/12/28 17:27:29 INFO TaskSchedulerImpl: Adding task set 5.0 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.147564Z","level":"info","event":"25/12/28 17:27:29 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 8) (28b45f86de62, executor driver, partition 0, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.147865Z","level":"info","event":"25/12/28 17:27:29 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 9) (28b45f86de62, executor driver, partition 1, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.148034Z","level":"info","event":"25/12/28 17:27:29 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 10) (28b45f86de62, executor driver, partition 2, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.153362Z","level":"info","event":"25/12/28 17:27:29 INFO Executor: Running task 1.0 in stage 5.0 (TID 9)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.153551Z","level":"info","event":"25/12/28 17:27:29 INFO Executor: Running task 0.0 in stage 5.0 (TID 8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.153607Z","level":"info","event":"25/12/28 17:27:29 INFO Executor: Running task 2.0 in stage 5.0 (TID 10)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.179068Z","level":"info","event":"25/12/28 17:27:29 INFO CodeGenerator: Code generated in 18.509958 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.183606Z","level":"info","event":"25/12/28 17:27:29 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.184658Z","level":"info","event":"25/12/28 17:27:29 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 8388608-9033957, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.185354Z","level":"info","event":"25/12/28 17:27:29 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.247540Z","level":"info","event":"25/12/28 17:27:29 INFO CodeGenerator: Code generated in 17.991791 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.432455Z","level":"info","event":"25/12/28 17:27:29 INFO Executor: Finished task 2.0 in stage 5.0 (TID 10). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.443053Z","level":"info","event":"25/12/28 17:27:29 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 10) in 293 ms on 28b45f86de62 (executor driver) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.962295Z","level":"info","event":"25/12/28 17:27:29 INFO Executor: Finished task 0.0 in stage 5.0 (TID 8). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.966699Z","level":"info","event":"25/12/28 17:27:29 INFO Executor: Finished task 1.0 in stage 5.0 (TID 9). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.969949Z","level":"info","event":"25/12/28 17:27:29 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 9) in 820 ms on 28b45f86de62 (executor driver) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.971711Z","level":"info","event":"25/12/28 17:27:29 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 8) in 825 ms on 28b45f86de62 (executor driver) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.972080Z","level":"info","event":"25/12/28 17:27:29 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.983370Z","level":"info","event":"25/12/28 17:27:29 INFO DAGScheduler: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.863 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.983845Z","level":"info","event":"25/12/28 17:27:29 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.987084Z","level":"info","event":"25/12/28 17:27:29 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.987362Z","level":"info","event":"25/12/28 17:27:29 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:29.987618Z","level":"info","event":"25/12/28 17:27:29 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.126506Z","level":"info","event":"25/12/28 17:27:30 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.133863Z","level":"info","event":"25/12/28 17:27:30 INFO DAGScheduler: Got job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.134080Z","level":"info","event":"25/12/28 17:27:30 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.134396Z","level":"info","event":"25/12/28 17:27:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.134939Z","level":"info","event":"25/12/28 17:27:30 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.138361Z","level":"info","event":"25/12/28 17:27:30 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.151305Z","level":"info","event":"25/12/28 17:27:30 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 12.5 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.211843Z","level":"info","event":"25/12/28 17:27:30 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.216947Z","level":"info","event":"25/12/28 17:27:30 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 28b45f86de62:35353 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.217982Z","level":"info","event":"25/12/28 17:27:30 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 28b45f86de62:35353 in memory (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.218224Z","level":"info","event":"25/12/28 17:27:30 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.219839Z","level":"info","event":"25/12/28 17:27:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.220099Z","level":"info","event":"25/12/28 17:27:30 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.230064Z","level":"info","event":"25/12/28 17:27:30 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 11) (28b45f86de62, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.233715Z","level":"info","event":"25/12/28 17:27:30 INFO Executor: Running task 0.0 in stage 7.0 (TID 11)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.267949Z","level":"info","event":"25/12/28 17:27:30 INFO ShuffleBlockFetcherIterator: Getting 3 (180.0 B) non-empty blocks including 3 (180.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.268719Z","level":"info","event":"25/12/28 17:27:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.289739Z","level":"info","event":"25/12/28 17:27:30 INFO Executor: Finished task 0.0 in stage 7.0 (TID 11). 4031 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.301810Z","level":"info","event":"25/12/28 17:27:30 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 11) in 76 ms on 28b45f86de62 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.302576Z","level":"info","event":"25/12/28 17:27:30 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.307970Z","level":"info","event":"25/12/28 17:27:30 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.162 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.308220Z","level":"info","event":"25/12/28 17:27:30 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.308449Z","level":"info","event":"25/12/28 17:27:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.314387Z","level":"info","event":"25/12/28 17:27:30 INFO DAGScheduler: Job 5 finished: count at NativeMethodAccessorImpl.java:0, took 0.187478 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.493003Z","level":"info","event":"25/12/28 17:27:30 INFO FileSourceStrategy: Pushed Filters: IsNull(customer_unique_id)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.493262Z","level":"info","event":"25/12/28 17:27:30 INFO FileSourceStrategy: Post-Scan Filters: isnull(customer_unique_id#18)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.556865Z","level":"info","event":"25/12/28 17:27:30 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 199.4 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.592276Z","level":"info","event":"25/12/28 17:27:30 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.596023Z","level":"info","event":"25/12/28 17:27:30 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 28b45f86de62:35353 (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.599128Z","level":"info","event":"25/12/28 17:27:30 INFO SparkContext: Created broadcast 10 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.607842Z","level":"info","event":"25/12/28 17:27:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.621972Z","level":"info","event":"25/12/28 17:27:30 INFO DAGScheduler: Registering RDD 27 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.622677Z","level":"info","event":"25/12/28 17:27:30 INFO DAGScheduler: Got map stage job 6 (count at NativeMethodAccessorImpl.java:0) with 3 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.622787Z","level":"info","event":"25/12/28 17:27:30 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.622893Z","level":"info","event":"25/12/28 17:27:30 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.623672Z","level":"info","event":"25/12/28 17:27:30 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.626321Z","level":"info","event":"25/12/28 17:27:30 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.639793Z","level":"info","event":"25/12/28 17:27:30 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 18.4 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.652417Z","level":"info","event":"25/12/28 17:27:30 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.654335Z","level":"info","event":"25/12/28 17:27:30 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 28b45f86de62:35353 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.655827Z","level":"info","event":"25/12/28 17:27:30 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.657832Z","level":"info","event":"25/12/28 17:27:30 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.658368Z","level":"info","event":"25/12/28 17:27:30 INFO TaskSchedulerImpl: Adding task set 8.0 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.661334Z","level":"info","event":"25/12/28 17:27:30 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 12) (28b45f86de62, executor driver, partition 0, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.662301Z","level":"info","event":"25/12/28 17:27:30 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 13) (28b45f86de62, executor driver, partition 1, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.663161Z","level":"info","event":"25/12/28 17:27:30 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 14) (28b45f86de62, executor driver, partition 2, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.665955Z","level":"info","event":"25/12/28 17:27:30 INFO Executor: Running task 0.0 in stage 8.0 (TID 12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.666183Z","level":"info","event":"25/12/28 17:27:30 INFO Executor: Running task 2.0 in stage 8.0 (TID 14)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.666358Z","level":"info","event":"25/12/28 17:27:30 INFO Executor: Running task 1.0 in stage 8.0 (TID 13)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.682759Z","level":"info","event":"25/12/28 17:27:30 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.683549Z","level":"info","event":"25/12/28 17:27:30 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 8388608-9033957, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.686033Z","level":"info","event":"25/12/28 17:27:30 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.839532Z","level":"info","event":"25/12/28 17:27:30 INFO Executor: Finished task 2.0 in stage 8.0 (TID 14). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:30.853227Z","level":"info","event":"25/12/28 17:27:30 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 14) in 187 ms on 28b45f86de62 (executor driver) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:31.531496Z","level":"info","event":"25/12/28 17:27:31 INFO Executor: Finished task 0.0 in stage 8.0 (TID 12). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:31.916959Z","level":"info","event":"25/12/28 17:27:31 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 28b45f86de62:35353 in memory (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:31.961301Z","level":"info","event":"25/12/28 17:27:31 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 12) in 1294 ms on 28b45f86de62 (executor driver) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:32.096028Z","level":"info","event":"25/12/28 17:27:32 INFO Executor: Finished task 1.0 in stage 8.0 (TID 13). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:32.134354Z","level":"info","event":"25/12/28 17:27:32 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 13) in 1455 ms on 28b45f86de62 (executor driver) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:32.134556Z","level":"info","event":"25/12/28 17:27:32 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 28b45f86de62:35353 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:32.135880Z","level":"info","event":"25/12/28 17:27:32 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:32.148432Z","level":"info","event":"25/12/28 17:27:32 INFO DAGScheduler: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 1.499 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:32.160562Z","level":"info","event":"25/12/28 17:27:32 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:32.161233Z","level":"info","event":"25/12/28 17:27:32 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:32.161406Z","level":"info","event":"25/12/28 17:27:32 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:32.161645Z","level":"info","event":"25/12/28 17:27:32 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:32.617754Z","level":"info","event":"25/12/28 17:27:32 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:32.641376Z","level":"info","event":"25/12/28 17:27:32 INFO DAGScheduler: Got job 7 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:32.649446Z","level":"info","event":"25/12/28 17:27:32 INFO DAGScheduler: Final stage: ResultStage 10 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:32.649921Z","level":"info","event":"25/12/28 17:27:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:32.650103Z","level":"info","event":"25/12/28 17:27:32 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:32.662203Z","level":"info","event":"25/12/28 17:27:32 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:32.711805Z","level":"info","event":"25/12/28 17:27:32 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 12.5 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:32.757070Z","level":"info","event":"25/12/28 17:27:32 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:32.766959Z","level":"info","event":"25/12/28 17:27:32 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 28b45f86de62:35353 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:32.774427Z","level":"info","event":"25/12/28 17:27:32 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:32.784918Z","level":"info","event":"25/12/28 17:27:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:32.785415Z","level":"info","event":"25/12/28 17:27:32 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:32.842324Z","level":"info","event":"25/12/28 17:27:32 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 15) (28b45f86de62, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:32.855090Z","level":"info","event":"25/12/28 17:27:32 INFO Executor: Running task 0.0 in stage 10.0 (TID 15)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:33.053352Z","level":"info","event":"25/12/28 17:27:33 INFO ShuffleBlockFetcherIterator: Getting 3 (180.0 B) non-empty blocks including 3 (180.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:33.060730Z","level":"info","event":"25/12/28 17:27:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:33.114505Z","level":"info","event":"25/12/28 17:27:33 INFO Executor: Finished task 0.0 in stage 10.0 (TID 15). 4031 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:33.132305Z","level":"info","event":"25/12/28 17:27:33 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 15) in 322 ms on 28b45f86de62 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:33.132787Z","level":"info","event":"25/12/28 17:27:33 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:33.148454Z","level":"info","event":"25/12/28 17:27:33 INFO DAGScheduler: ResultStage 10 (count at NativeMethodAccessorImpl.java:0) finished in 0.457 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:33.153836Z","level":"info","event":"25/12/28 17:27:33 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:33.154136Z","level":"info","event":"25/12/28 17:27:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:33.157387Z","level":"info","event":"25/12/28 17:27:33 INFO DAGScheduler: Job 7 finished: count at NativeMethodAccessorImpl.java:0, took 0.540252 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:33.945050Z","level":"info","event":"25/12/28 17:27:33 INFO FileSourceStrategy: Pushed Filters: IsNull(customer_zip_code_prefix)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:33.963520Z","level":"info","event":"25/12/28 17:27:33 INFO FileSourceStrategy: Post-Scan Filters: isnull(customer_zip_code_prefix#19)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:34.681944Z","level":"info","event":"25/12/28 17:27:34 INFO CodeGenerator: Code generated in 370.217958 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:34.782115Z","level":"info","event":"25/12/28 17:27:34 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 199.4 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:34.960135Z","level":"info","event":"25/12/28 17:27:34 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:35.014963Z","level":"info","event":"25/12/28 17:27:35 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 28b45f86de62:35353 (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:35.099468Z","level":"info","event":"25/12/28 17:27:35 INFO SparkContext: Created broadcast 13 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:35.218179Z","level":"info","event":"25/12/28 17:27:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:35.483310Z","level":"info","event":"25/12/28 17:27:35 INFO DAGScheduler: Registering RDD 34 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:35.509136Z","level":"info","event":"25/12/28 17:27:35 INFO DAGScheduler: Got map stage job 8 (count at NativeMethodAccessorImpl.java:0) with 3 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:35.509311Z","level":"info","event":"25/12/28 17:27:35 INFO DAGScheduler: Final stage: ShuffleMapStage 11 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:35.509386Z","level":"info","event":"25/12/28 17:27:35 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:35.509434Z","level":"info","event":"25/12/28 17:27:35 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:35.510046Z","level":"info","event":"25/12/28 17:27:35 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:35.578058Z","level":"info","event":"25/12/28 17:27:35 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 18.4 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:35.645727Z","level":"info","event":"25/12/28 17:27:35 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:35.651832Z","level":"info","event":"25/12/28 17:27:35 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 28b45f86de62:35353 (size: 9.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:35.662463Z","level":"info","event":"25/12/28 17:27:35 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:35.677527Z","level":"info","event":"25/12/28 17:27:35 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:35.677945Z","level":"info","event":"25/12/28 17:27:35 INFO TaskSchedulerImpl: Adding task set 11.0 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:35.764513Z","level":"info","event":"25/12/28 17:27:35 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 16) (28b45f86de62, executor driver, partition 0, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:35.772279Z","level":"info","event":"25/12/28 17:27:35 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 17) (28b45f86de62, executor driver, partition 1, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:35.783132Z","level":"info","event":"25/12/28 17:27:35 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 18) (28b45f86de62, executor driver, partition 2, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:35.808611Z","level":"info","event":"25/12/28 17:27:35 INFO Executor: Running task 1.0 in stage 11.0 (TID 17)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:35.821488Z","level":"info","event":"25/12/28 17:27:35 INFO Executor: Running task 0.0 in stage 11.0 (TID 16)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:35.832728Z","level":"info","event":"25/12/28 17:27:35 INFO Executor: Running task 2.0 in stage 11.0 (TID 18)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:37.505221Z","level":"info","event":"25/12/28 17:27:37 INFO CodeGenerator: Code generated in 1281.941626 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:37.788374Z","level":"info","event":"25/12/28 17:27:37 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:37.788864Z","level":"info","event":"25/12/28 17:27:37 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 8388608-9033957, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:37.788944Z","level":"info","event":"25/12/28 17:27:37 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:38.522115Z","level":"info","event":"25/12/28 17:27:38 INFO CodeGenerator: Code generated in 516.690125 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:39.131764Z","level":"info","event":"25/12/28 17:27:39 INFO CodeGenerator: Code generated in 272.406834 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:40.244580Z","level":"info","event":"25/12/28 17:27:40 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 28b45f86de62:35353 in memory (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:40.323957Z","level":"info","event":"25/12/28 17:27:40 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 28b45f86de62:35353 in memory (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:40.469512Z","level":"info","event":"25/12/28 17:27:40 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 28b45f86de62:35353 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:40.540760Z","level":"info","event":"25/12/28 17:27:40 INFO Executor: Finished task 2.0 in stage 11.0 (TID 18). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:40.662772Z","level":"info","event":"25/12/28 17:27:40 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 18) in 4887 ms on 28b45f86de62 (executor driver) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:40.820850Z","level":"info","event":"25/12/28 17:27:40 INFO Executor: Finished task 0.0 in stage 11.0 (TID 16). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:40.848959Z","level":"info","event":"25/12/28 17:27:40 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 16) in 5102 ms on 28b45f86de62 (executor driver) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:40.942967Z","level":"info","event":"25/12/28 17:27:40 INFO Executor: Finished task 1.0 in stage 11.0 (TID 17). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:40.953678Z","level":"info","event":"25/12/28 17:27:40 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 17) in 5185 ms on 28b45f86de62 (executor driver) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:40.960620Z","level":"info","event":"25/12/28 17:27:40 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:40.961144Z","level":"info","event":"25/12/28 17:27:40 INFO DAGScheduler: ShuffleMapStage 11 (count at NativeMethodAccessorImpl.java:0) finished in 5.429 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:40.961722Z","level":"info","event":"25/12/28 17:27:40 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:40.963536Z","level":"info","event":"25/12/28 17:27:40 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:40.963905Z","level":"info","event":"25/12/28 17:27:40 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:40.964272Z","level":"info","event":"25/12/28 17:27:40 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:41.547976Z","level":"info","event":"25/12/28 17:27:41 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:41.554402Z","level":"info","event":"25/12/28 17:27:41 INFO DAGScheduler: Got job 9 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:41.554981Z","level":"info","event":"25/12/28 17:27:41 INFO DAGScheduler: Final stage: ResultStage 13 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:41.555081Z","level":"info","event":"25/12/28 17:27:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:41.563009Z","level":"info","event":"25/12/28 17:27:41 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:41.598259Z","level":"info","event":"25/12/28 17:27:41 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[37] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:41.694826Z","level":"info","event":"25/12/28 17:27:41 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 12.5 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:41.752720Z","level":"info","event":"25/12/28 17:27:41 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:41.765704Z","level":"info","event":"25/12/28 17:27:41 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 28b45f86de62:35353 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:41.790672Z","level":"info","event":"25/12/28 17:27:41 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:41.801681Z","level":"info","event":"25/12/28 17:27:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[37] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:41.802958Z","level":"info","event":"25/12/28 17:27:41 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:41.883027Z","level":"info","event":"25/12/28 17:27:41 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 19) (28b45f86de62, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:41.893910Z","level":"info","event":"25/12/28 17:27:41 INFO Executor: Running task 0.0 in stage 13.0 (TID 19)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:42.253672Z","level":"info","event":"25/12/28 17:27:42 INFO ShuffleBlockFetcherIterator: Getting 3 (180.0 B) non-empty blocks including 3 (180.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:42.272152Z","level":"info","event":"25/12/28 17:27:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 70 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:42.498569Z","level":"info","event":"25/12/28 17:27:42 INFO Executor: Finished task 0.0 in stage 13.0 (TID 19). 4031 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:42.541975Z","level":"info","event":"25/12/28 17:27:42 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 19) in 690 ms on 28b45f86de62 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:42.544770Z","level":"info","event":"25/12/28 17:27:42 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:42.602494Z","level":"info","event":"25/12/28 17:27:42 INFO DAGScheduler: ResultStage 13 (count at NativeMethodAccessorImpl.java:0) finished in 0.949 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:42.611608Z","level":"info","event":"25/12/28 17:27:42 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:42.613433Z","level":"info","event":"25/12/28 17:27:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:42.658666Z","level":"info","event":"25/12/28 17:27:42 INFO DAGScheduler: Job 9 finished: count at NativeMethodAccessorImpl.java:0, took 1.124487 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:44.483724Z","level":"info","event":"25/12/28 17:27:44 INFO FileSourceStrategy: Pushed Filters: IsNull(customer_city)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:44.501467Z","level":"info","event":"25/12/28 17:27:44 INFO FileSourceStrategy: Post-Scan Filters: isnull(customer_city#20)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:45.745612Z","level":"info","event":"25/12/28 17:27:45 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 199.4 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:45.981633Z","level":"info","event":"25/12/28 17:27:45 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.000970Z","level":"info","event":"25/12/28 17:27:46 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 28b45f86de62:35353 (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.062974Z","level":"info","event":"25/12/28 17:27:46 INFO SparkContext: Created broadcast 16 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.135934Z","level":"info","event":"25/12/28 17:27:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.348686Z","level":"info","event":"25/12/28 17:27:46 INFO DAGScheduler: Registering RDD 41 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.365205Z","level":"info","event":"25/12/28 17:27:46 INFO DAGScheduler: Got map stage job 10 (count at NativeMethodAccessorImpl.java:0) with 3 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.366000Z","level":"info","event":"25/12/28 17:27:46 INFO DAGScheduler: Final stage: ShuffleMapStage 14 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.366703Z","level":"info","event":"25/12/28 17:27:46 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.371084Z","level":"info","event":"25/12/28 17:27:46 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.376505Z","level":"info","event":"25/12/28 17:27:46 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[41] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.414156Z","level":"info","event":"25/12/28 17:27:46 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 18.4 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.745379Z","level":"info","event":"25/12/28 17:27:46 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 28b45f86de62:35353 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.754584Z","level":"info","event":"25/12/28 17:27:46 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.755019Z","level":"info","event":"25/12/28 17:27:46 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 28b45f86de62:35353 (size: 9.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.768299Z","level":"info","event":"25/12/28 17:27:46 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.778692Z","level":"info","event":"25/12/28 17:27:46 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[41] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.779541Z","level":"info","event":"25/12/28 17:27:46 INFO TaskSchedulerImpl: Adding task set 14.0 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.830949Z","level":"info","event":"25/12/28 17:27:46 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 20) (28b45f86de62, executor driver, partition 0, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.831843Z","level":"info","event":"25/12/28 17:27:46 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 28b45f86de62:35353 in memory (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.832000Z","level":"info","event":"25/12/28 17:27:46 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 21) (28b45f86de62, executor driver, partition 1, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.832071Z","level":"info","event":"25/12/28 17:27:46 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 22) (28b45f86de62, executor driver, partition 2, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.843711Z","level":"info","event":"25/12/28 17:27:46 INFO Executor: Running task 1.0 in stage 14.0 (TID 21)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.849454Z","level":"info","event":"25/12/28 17:27:46 INFO Executor: Running task 0.0 in stage 14.0 (TID 20)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.857646Z","level":"info","event":"25/12/28 17:27:46 INFO Executor: Running task 2.0 in stage 14.0 (TID 22)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.927567Z","level":"info","event":"25/12/28 17:27:46 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 28b45f86de62:35353 in memory (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.928860Z","level":"info","event":"25/12/28 17:27:46 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.950412Z","level":"info","event":"25/12/28 17:27:46 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:46.950764Z","level":"info","event":"25/12/28 17:27:46 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 8388608-9033957, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:47.304560Z","level":"info","event":"25/12/28 17:27:47 INFO Executor: Finished task 2.0 in stage 14.0 (TID 22). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:47.322719Z","level":"info","event":"25/12/28 17:27:47 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 22) in 488 ms on 28b45f86de62 (executor driver) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:48.014341Z","level":"info","event":"25/12/28 17:27:47 INFO Executor: Finished task 0.0 in stage 14.0 (TID 20). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:48.066187Z","level":"info","event":"25/12/28 17:27:48 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 20) in 1241 ms on 28b45f86de62 (executor driver) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:48.161965Z","level":"info","event":"25/12/28 17:27:48 INFO Executor: Finished task 1.0 in stage 14.0 (TID 21). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:48.171769Z","level":"info","event":"25/12/28 17:27:48 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 21) in 1340 ms on 28b45f86de62 (executor driver) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:48.172220Z","level":"info","event":"25/12/28 17:27:48 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:48.180204Z","level":"info","event":"25/12/28 17:27:48 INFO DAGScheduler: ShuffleMapStage 14 (count at NativeMethodAccessorImpl.java:0) finished in 1.776 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:48.180739Z","level":"info","event":"25/12/28 17:27:48 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:48.184198Z","level":"info","event":"25/12/28 17:27:48 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:48.186710Z","level":"info","event":"25/12/28 17:27:48 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:48.187158Z","level":"info","event":"25/12/28 17:27:48 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:48.676007Z","level":"info","event":"25/12/28 17:27:48 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:48.748957Z","level":"info","event":"25/12/28 17:27:48 INFO DAGScheduler: Got job 11 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:48.753805Z","level":"info","event":"25/12/28 17:27:48 INFO DAGScheduler: Final stage: ResultStage 16 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:48.755306Z","level":"info","event":"25/12/28 17:27:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:48.785878Z","level":"info","event":"25/12/28 17:27:48 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:48.812337Z","level":"info","event":"25/12/28 17:27:48 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[44] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:48.996477Z","level":"info","event":"25/12/28 17:27:48 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 12.5 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:49.110679Z","level":"info","event":"25/12/28 17:27:49 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:49.141534Z","level":"info","event":"25/12/28 17:27:49 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 28b45f86de62:35353 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:49.165897Z","level":"info","event":"25/12/28 17:27:49 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:49.174408Z","level":"info","event":"25/12/28 17:27:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[44] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:49.174646Z","level":"info","event":"25/12/28 17:27:49 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:49.226773Z","level":"info","event":"25/12/28 17:27:49 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 23) (28b45f86de62, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:49.231746Z","level":"info","event":"25/12/28 17:27:49 INFO Executor: Running task 0.0 in stage 16.0 (TID 23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:49.378080Z","level":"info","event":"25/12/28 17:27:49 INFO ShuffleBlockFetcherIterator: Getting 3 (180.0 B) non-empty blocks including 3 (180.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:49.380480Z","level":"info","event":"25/12/28 17:27:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 30 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:49.452621Z","level":"info","event":"25/12/28 17:27:49 INFO Executor: Finished task 0.0 in stage 16.0 (TID 23). 4031 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:49.488315Z","level":"info","event":"25/12/28 17:27:49 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 23) in 277 ms on 28b45f86de62 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:49.490042Z","level":"info","event":"25/12/28 17:27:49 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:49.511125Z","level":"info","event":"25/12/28 17:27:49 INFO DAGScheduler: ResultStage 16 (count at NativeMethodAccessorImpl.java:0) finished in 0.595 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:49.519527Z","level":"info","event":"25/12/28 17:27:49 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:49.519975Z","level":"info","event":"25/12/28 17:27:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:49.522563Z","level":"info","event":"25/12/28 17:27:49 INFO DAGScheduler: Job 11 finished: count at NativeMethodAccessorImpl.java:0, took 0.849306 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.216855Z","level":"info","event":"25/12/28 17:27:50 INFO FileSourceStrategy: Pushed Filters: IsNull(customer_state)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.222729Z","level":"info","event":"25/12/28 17:27:50 INFO FileSourceStrategy: Post-Scan Filters: isnull(customer_state#21)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.393344Z","level":"info","event":"25/12/28 17:27:50 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 199.4 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.463719Z","level":"info","event":"25/12/28 17:27:50 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.479391Z","level":"info","event":"25/12/28 17:27:50 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 28b45f86de62:35353 (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.492871Z","level":"info","event":"25/12/28 17:27:50 INFO SparkContext: Created broadcast 19 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.520132Z","level":"info","event":"25/12/28 17:27:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.603648Z","level":"info","event":"25/12/28 17:27:50 INFO DAGScheduler: Registering RDD 48 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 5","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.609730Z","level":"info","event":"25/12/28 17:27:50 INFO DAGScheduler: Got map stage job 12 (count at NativeMethodAccessorImpl.java:0) with 3 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.610966Z","level":"info","event":"25/12/28 17:27:50 INFO DAGScheduler: Final stage: ShuffleMapStage 17 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.611070Z","level":"info","event":"25/12/28 17:27:50 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.611108Z","level":"info","event":"25/12/28 17:27:50 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.615637Z","level":"info","event":"25/12/28 17:27:50 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[48] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.649534Z","level":"info","event":"25/12/28 17:27:50 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 18.4 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.676677Z","level":"info","event":"25/12/28 17:27:50 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.684831Z","level":"info","event":"25/12/28 17:27:50 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 28b45f86de62:35353 (size: 9.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.690831Z","level":"info","event":"25/12/28 17:27:50 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.692155Z","level":"info","event":"25/12/28 17:27:50 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[48] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.693390Z","level":"info","event":"25/12/28 17:27:50 INFO TaskSchedulerImpl: Adding task set 17.0 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.725032Z","level":"info","event":"25/12/28 17:27:50 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 24) (28b45f86de62, executor driver, partition 0, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.730652Z","level":"info","event":"25/12/28 17:27:50 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 25) (28b45f86de62, executor driver, partition 1, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.731338Z","level":"info","event":"25/12/28 17:27:50 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 26) (28b45f86de62, executor driver, partition 2, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.755967Z","level":"info","event":"25/12/28 17:27:50 INFO Executor: Running task 0.0 in stage 17.0 (TID 24)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.760858Z","level":"info","event":"25/12/28 17:27:50 INFO Executor: Running task 1.0 in stage 17.0 (TID 25)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.767194Z","level":"info","event":"25/12/28 17:27:50 INFO Executor: Running task 2.0 in stage 17.0 (TID 26)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.848048Z","level":"info","event":"25/12/28 17:27:50 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 8388608-9033957, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.848567Z","level":"info","event":"25/12/28 17:27:50 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:50.848723Z","level":"info","event":"25/12/28 17:27:50 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:51.248028Z","level":"info","event":"25/12/28 17:27:51 INFO Executor: Finished task 2.0 in stage 17.0 (TID 26). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:51.317808Z","level":"info","event":"25/12/28 17:27:51 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 26) in 581 ms on 28b45f86de62 (executor driver) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:51.437876Z","level":"info","event":"25/12/28 17:27:51 INFO Executor: Finished task 0.0 in stage 17.0 (TID 24). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:51.448079Z","level":"info","event":"25/12/28 17:27:51 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 24) in 732 ms on 28b45f86de62 (executor driver) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:51.471224Z","level":"info","event":"25/12/28 17:27:51 INFO Executor: Finished task 1.0 in stage 17.0 (TID 25). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:51.476284Z","level":"info","event":"25/12/28 17:27:51 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 25) in 747 ms on 28b45f86de62 (executor driver) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:51.481095Z","level":"info","event":"25/12/28 17:27:51 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:51.483474Z","level":"info","event":"25/12/28 17:27:51 INFO DAGScheduler: ShuffleMapStage 17 (count at NativeMethodAccessorImpl.java:0) finished in 0.858 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:51.484772Z","level":"info","event":"25/12/28 17:27:51 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:51.486651Z","level":"info","event":"25/12/28 17:27:51 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:51.495191Z","level":"info","event":"25/12/28 17:27:51 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:51.495330Z","level":"info","event":"25/12/28 17:27:51 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:51.806938Z","level":"info","event":"25/12/28 17:27:51 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:51.831983Z","level":"info","event":"25/12/28 17:27:51 INFO DAGScheduler: Got job 13 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:51.832170Z","level":"info","event":"25/12/28 17:27:51 INFO DAGScheduler: Final stage: ResultStage 19 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:51.832568Z","level":"info","event":"25/12/28 17:27:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:51.836286Z","level":"info","event":"25/12/28 17:27:51 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:51.843884Z","level":"info","event":"25/12/28 17:27:51 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[51] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:51.894459Z","level":"info","event":"25/12/28 17:27:51 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 12.5 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:52.043444Z","level":"info","event":"25/12/28 17:27:52 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 28b45f86de62:35353 in memory (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:52.049019Z","level":"info","event":"25/12/28 17:27:52 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:52.050162Z","level":"info","event":"25/12/28 17:27:52 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 28b45f86de62:35353 (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:52.054461Z","level":"info","event":"25/12/28 17:27:52 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:52.057971Z","level":"info","event":"25/12/28 17:27:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[51] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:52.061590Z","level":"info","event":"25/12/28 17:27:52 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:52.091495Z","level":"info","event":"25/12/28 17:27:52 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 27) (28b45f86de62, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:52.104248Z","level":"info","event":"25/12/28 17:27:52 INFO Executor: Running task 0.0 in stage 19.0 (TID 27)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:52.111763Z","level":"info","event":"25/12/28 17:27:52 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 28b45f86de62:35353 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:52.144089Z","level":"info","event":"25/12/28 17:27:52 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 28b45f86de62:35353 in memory (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:52.152800Z","level":"info","event":"25/12/28 17:27:52 INFO ShuffleBlockFetcherIterator: Getting 3 (180.0 B) non-empty blocks including 3 (180.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:52.152984Z","level":"info","event":"25/12/28 17:27:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:52.167198Z","level":"info","event":"25/12/28 17:27:52 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 28b45f86de62:35353 in memory (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:52.190619Z","level":"info","event":"25/12/28 17:27:52 INFO Executor: Finished task 0.0 in stage 19.0 (TID 27). 4031 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:52.200432Z","level":"info","event":"25/12/28 17:27:52 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 27) in 119 ms on 28b45f86de62 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:52.204733Z","level":"info","event":"25/12/28 17:27:52 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:52.206201Z","level":"info","event":"25/12/28 17:27:52 INFO DAGScheduler: ResultStage 19 (count at NativeMethodAccessorImpl.java:0) finished in 0.344 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:52.208216Z","level":"info","event":"25/12/28 17:27:52 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:52.208399Z","level":"info","event":"25/12/28 17:27:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:52.210865Z","level":"info","event":"25/12/28 17:27:52 INFO DAGScheduler: Job 13 finished: count at NativeMethodAccessorImpl.java:0, took 0.403596 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:52.549747Z","level":"info","event":"25/12/28 17:27:52 INFO InMemoryFileIndex: It took 14 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:52.649896Z","level":"info","event":"25/12/28 17:27:52 INFO InMemoryFileIndex: It took 21 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:54.177209Z","level":"info","event":"25/12/28 17:27:54 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:54.187685Z","level":"info","event":"25/12/28 17:27:54 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#93, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:54.394278Z","level":"info","event":"25/12/28 17:27:54 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 199.5 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:54.492334Z","level":"info","event":"25/12/28 17:27:54 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:54.518521Z","level":"info","event":"25/12/28 17:27:54 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 28b45f86de62:35353 (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:54.555836Z","level":"info","event":"25/12/28 17:27:54 INFO SparkContext: Created broadcast 22 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:54.593193Z","level":"info","event":"25/12/28 17:27:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8183523 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:54.730528Z","level":"info","event":"25/12/28 17:27:54 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:54.742244Z","level":"info","event":"25/12/28 17:27:54 INFO DAGScheduler: Got job 14 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:54.742554Z","level":"info","event":"25/12/28 17:27:54 INFO DAGScheduler: Final stage: ResultStage 20 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:54.742672Z","level":"info","event":"25/12/28 17:27:54 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:54.743325Z","level":"info","event":"25/12/28 17:27:54 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:54.750823Z","level":"info","event":"25/12/28 17:27:54 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[55] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:54.793135Z","level":"info","event":"25/12/28 17:27:54 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 13.5 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:54.825111Z","level":"info","event":"25/12/28 17:27:54 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:54.841886Z","level":"info","event":"25/12/28 17:27:54 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 28b45f86de62:35353 (size: 6.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:54.846760Z","level":"info","event":"25/12/28 17:27:54 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:54.848904Z","level":"info","event":"25/12/28 17:27:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[55] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:54.852540Z","level":"info","event":"25/12/28 17:27:54 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:54.865189Z","level":"info","event":"25/12/28 17:27:54 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 28) (28b45f86de62, executor driver, partition 0, PROCESS_LOCAL, 8293 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:54.880371Z","level":"info","event":"25/12/28 17:27:54 INFO Executor: Running task 0.0 in stage 20.0 (TID 28)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:54.969869Z","level":"info","event":"25/12/28 17:27:54 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 0-8183523, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.099384Z","level":"info","event":"25/12/28 17:27:55 INFO Executor: Finished task 0.0 in stage 20.0 (TID 28). 1669 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.124743Z","level":"info","event":"25/12/28 17:27:55 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 28) in 259 ms on 28b45f86de62 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.125403Z","level":"info","event":"25/12/28 17:27:55 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.129106Z","level":"info","event":"25/12/28 17:27:55 INFO DAGScheduler: ResultStage 20 (csv at NativeMethodAccessorImpl.java:0) finished in 0.364 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.130895Z","level":"info","event":"25/12/28 17:27:55 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.131031Z","level":"info","event":"25/12/28 17:27:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.134953Z","level":"info","event":"25/12/28 17:27:55 INFO DAGScheduler: Job 14 finished: csv at NativeMethodAccessorImpl.java:0, took 0.403847 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.440734Z","level":"info","event":"25/12/28 17:27:55 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.443084Z","level":"info","event":"25/12/28 17:27:55 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.555289Z","level":"info","event":"25/12/28 17:27:55 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 199.5 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.611617Z","level":"info","event":"25/12/28 17:27:55 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.618642Z","level":"info","event":"25/12/28 17:27:55 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 28b45f86de62:35353 (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.628720Z","level":"info","event":"25/12/28 17:27:55 INFO SparkContext: Created broadcast 24 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.638175Z","level":"info","event":"25/12/28 17:27:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8183523 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.721457Z","level":"info","event":"25/12/28 17:27:55 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.743823Z","level":"info","event":"25/12/28 17:27:55 INFO DAGScheduler: Got job 15 (csv at NativeMethodAccessorImpl.java:0) with 8 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.745626Z","level":"info","event":"25/12/28 17:27:55 INFO DAGScheduler: Final stage: ResultStage 21 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.749851Z","level":"info","event":"25/12/28 17:27:55 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.754764Z","level":"info","event":"25/12/28 17:27:55 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.767574Z","level":"info","event":"25/12/28 17:27:55 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[61] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.800249Z","level":"info","event":"25/12/28 17:27:55 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 27.4 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.830895Z","level":"info","event":"25/12/28 17:27:55 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 12.6 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.837162Z","level":"info","event":"25/12/28 17:27:55 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 28b45f86de62:35353 (size: 12.6 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.842413Z","level":"info","event":"25/12/28 17:27:55 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.848616Z","level":"info","event":"25/12/28 17:27:55 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 21 (MapPartitionsRDD[61] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.853521Z","level":"info","event":"25/12/28 17:27:55 INFO TaskSchedulerImpl: Adding task set 21.0 with 8 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.871013Z","level":"info","event":"25/12/28 17:27:55 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 29) (28b45f86de62, executor driver, partition 0, PROCESS_LOCAL, 8293 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.877712Z","level":"info","event":"25/12/28 17:27:55 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 30) (28b45f86de62, executor driver, partition 1, PROCESS_LOCAL, 8293 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.882046Z","level":"info","event":"25/12/28 17:27:55 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 31) (28b45f86de62, executor driver, partition 2, PROCESS_LOCAL, 8293 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.882240Z","level":"info","event":"25/12/28 17:27:55 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 32) (28b45f86de62, executor driver, partition 3, PROCESS_LOCAL, 8293 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.886298Z","level":"info","event":"25/12/28 17:27:55 INFO TaskSetManager: Starting task 4.0 in stage 21.0 (TID 33) (28b45f86de62, executor driver, partition 4, PROCESS_LOCAL, 8293 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.888617Z","level":"info","event":"25/12/28 17:27:55 INFO TaskSetManager: Starting task 5.0 in stage 21.0 (TID 34) (28b45f86de62, executor driver, partition 5, PROCESS_LOCAL, 8293 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.892951Z","level":"info","event":"25/12/28 17:27:55 INFO TaskSetManager: Starting task 6.0 in stage 21.0 (TID 35) (28b45f86de62, executor driver, partition 6, PROCESS_LOCAL, 8293 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.893678Z","level":"info","event":"25/12/28 17:27:55 INFO TaskSetManager: Starting task 7.0 in stage 21.0 (TID 36) (28b45f86de62, executor driver, partition 7, PROCESS_LOCAL, 8293 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.905736Z","level":"info","event":"25/12/28 17:27:55 INFO Executor: Running task 0.0 in stage 21.0 (TID 29)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.906149Z","level":"info","event":"25/12/28 17:27:55 INFO Executor: Running task 2.0 in stage 21.0 (TID 31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.911965Z","level":"info","event":"25/12/28 17:27:55 INFO Executor: Running task 1.0 in stage 21.0 (TID 30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.920937Z","level":"info","event":"25/12/28 17:27:55 INFO Executor: Running task 3.0 in stage 21.0 (TID 32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.921292Z","level":"info","event":"25/12/28 17:27:55 INFO Executor: Running task 4.0 in stage 21.0 (TID 33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.928887Z","level":"info","event":"25/12/28 17:27:55 INFO Executor: Running task 5.0 in stage 21.0 (TID 34)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.943652Z","level":"info","event":"25/12/28 17:27:55 INFO Executor: Running task 6.0 in stage 21.0 (TID 35)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:55.949750Z","level":"info","event":"25/12/28 17:27:55 INFO Executor: Running task 7.0 in stage 21.0 (TID 36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:56.048055Z","level":"info","event":"25/12/28 17:27:56 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 16367046-24550569, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:56.049877Z","level":"info","event":"25/12/28 17:27:56 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 40917615-49101138, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:56.050285Z","level":"info","event":"25/12/28 17:27:56 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 49101138-57284661, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:56.051948Z","level":"info","event":"25/12/28 17:27:56 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 57284661-61273883, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:56.077687Z","level":"info","event":"25/12/28 17:27:56 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 24550569-32734092, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:56.078514Z","level":"info","event":"25/12/28 17:27:56 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 0-8183523, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:56.083017Z","level":"info","event":"25/12/28 17:27:56 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 8183523-16367046, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:56.102616Z","level":"info","event":"25/12/28 17:27:56 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 32734092-40917615, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:57.783528Z","level":"info","event":"25/12/28 17:27:57 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 28b45f86de62:35353 in memory (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:57.963518Z","level":"info","event":"25/12/28 17:27:57 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 28b45f86de62:35353 in memory (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:58.172236Z","level":"info","event":"25/12/28 17:27:58 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 28b45f86de62:35353 in memory (size: 6.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:27:59.164282Z","level":"info","event":"25/12/28 17:27:59 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 28b45f86de62:35353 in memory (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:12.910642Z","level":"info","event":"25/12/28 17:28:12 INFO Executor: Finished task 7.0 in stage 21.0 (TID 36). 1719 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:14.960413Z","level":"info","event":"25/12/28 17:28:14 INFO TaskSetManager: Finished task 7.0 in stage 21.0 (TID 36) in 18721 ms on 28b45f86de62 (executor driver) (1/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:18.050441Z","level":"info","event":"25/12/28 17:28:18 INFO Executor: Finished task 4.0 in stage 21.0 (TID 33). 1719 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:18.268021Z","level":"info","event":"25/12/28 17:28:18 INFO Executor: Finished task 6.0 in stage 21.0 (TID 35). 1719 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:18.450414Z","level":"info","event":"25/12/28 17:28:18 INFO TaskSetManager: Finished task 6.0 in stage 21.0 (TID 35) in 22536 ms on 28b45f86de62 (executor driver) (2/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:18.483911Z","level":"info","event":"25/12/28 17:28:18 INFO TaskSetManager: Finished task 4.0 in stage 21.0 (TID 33) in 22598 ms on 28b45f86de62 (executor driver) (3/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:18.813205Z","level":"info","event":"25/12/28 17:28:18 INFO Executor: Finished task 2.0 in stage 21.0 (TID 31). 1719 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:18.889214Z","level":"info","event":"25/12/28 17:28:18 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 31) in 22998 ms on 28b45f86de62 (executor driver) (4/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:18.951778Z","level":"info","event":"25/12/28 17:28:18 INFO Executor: Finished task 1.0 in stage 21.0 (TID 30). 1719 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:18.971474Z","level":"info","event":"25/12/28 17:28:18 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 30) in 23093 ms on 28b45f86de62 (executor driver) (5/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:19.473530Z","level":"info","event":"25/12/28 17:28:19 INFO Executor: Finished task 5.0 in stage 21.0 (TID 34). 1719 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:19.529108Z","level":"info","event":"25/12/28 17:28:19 INFO Executor: Finished task 3.0 in stage 21.0 (TID 32). 1719 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:19.618362Z","level":"info","event":"25/12/28 17:28:19 INFO TaskSetManager: Finished task 5.0 in stage 21.0 (TID 34) in 23722 ms on 28b45f86de62 (executor driver) (6/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:19.642520Z","level":"info","event":"25/12/28 17:28:19 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 32) in 23751 ms on 28b45f86de62 (executor driver) (7/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:19.688600Z","level":"info","event":"25/12/28 17:28:19 INFO Executor: Finished task 0.0 in stage 21.0 (TID 29). 1719 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:19.712393Z","level":"info","event":"25/12/28 17:28:19 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 29) in 23843 ms on 28b45f86de62 (executor driver) (8/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:19.719870Z","level":"info","event":"25/12/28 17:28:19 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:19.827348Z","level":"info","event":"25/12/28 17:28:19 INFO DAGScheduler: ResultStage 21 (csv at NativeMethodAccessorImpl.java:0) finished in 23.956 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:19.857429Z","level":"info","event":"25/12/28 17:28:19 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:19.889064Z","level":"info","event":"25/12/28 17:28:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:19.916236Z","level":"info","event":"25/12/28 17:28:19 INFO DAGScheduler: Job 15 finished: csv at NativeMethodAccessorImpl.java:0, took 24.204731 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:20.698968Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:21.614950Z","level":"info","event":"25/12/28 17:28:21 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:21.623818Z","level":"info","event":"25/12/28 17:28:21 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:22.114717Z","level":"info","event":"25/12/28 17:28:22 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 199.4 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:22.193787Z","level":"info","event":"25/12/28 17:28:22 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:22.217107Z","level":"info","event":"25/12/28 17:28:22 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 28b45f86de62:35353 (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:22.238711Z","level":"info","event":"25/12/28 17:28:22 INFO SparkContext: Created broadcast 26 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:22.292836Z","level":"info","event":"25/12/28 17:28:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8183523 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:22.859194Z","level":"info","event":"25/12/28 17:28:22 INFO DAGScheduler: Registering RDD 65 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 6","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:22.911865Z","level":"info","event":"25/12/28 17:28:22 INFO DAGScheduler: Got map stage job 16 (count at NativeMethodAccessorImpl.java:0) with 8 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:22.912602Z","level":"info","event":"25/12/28 17:28:22 INFO DAGScheduler: Final stage: ShuffleMapStage 22 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:22.921663Z","level":"info","event":"25/12/28 17:28:22 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:22.922592Z","level":"info","event":"25/12/28 17:28:22 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:22.957416Z","level":"info","event":"25/12/28 17:28:22 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[65] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:23.165228Z","level":"info","event":"25/12/28 17:28:23 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 17.9 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:23.360795Z","level":"info","event":"25/12/28 17:28:23 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:23.409133Z","level":"info","event":"25/12/28 17:28:23 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 28b45f86de62:35353 (size: 8.8 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:23.441117Z","level":"info","event":"25/12/28 17:28:23 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:23.499410Z","level":"info","event":"25/12/28 17:28:23 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[65] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:23.506397Z","level":"info","event":"25/12/28 17:28:23 INFO TaskSchedulerImpl: Adding task set 22.0 with 8 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:23.660042Z","level":"info","event":"25/12/28 17:28:23 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 37) (28b45f86de62, executor driver, partition 0, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:23.671722Z","level":"info","event":"25/12/28 17:28:23 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 38) (28b45f86de62, executor driver, partition 1, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:23.679123Z","level":"info","event":"25/12/28 17:28:23 INFO TaskSetManager: Starting task 2.0 in stage 22.0 (TID 39) (28b45f86de62, executor driver, partition 2, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:23.685658Z","level":"info","event":"25/12/28 17:28:23 INFO TaskSetManager: Starting task 3.0 in stage 22.0 (TID 40) (28b45f86de62, executor driver, partition 3, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:23.699741Z","level":"info","event":"25/12/28 17:28:23 INFO TaskSetManager: Starting task 4.0 in stage 22.0 (TID 41) (28b45f86de62, executor driver, partition 4, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:23.699963Z","level":"info","event":"25/12/28 17:28:23 INFO TaskSetManager: Starting task 5.0 in stage 22.0 (TID 42) (28b45f86de62, executor driver, partition 5, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:23.700107Z","level":"info","event":"25/12/28 17:28:23 INFO TaskSetManager: Starting task 6.0 in stage 22.0 (TID 43) (28b45f86de62, executor driver, partition 6, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:23.700210Z","level":"info","event":"25/12/28 17:28:23 INFO TaskSetManager: Starting task 7.0 in stage 22.0 (TID 44) (28b45f86de62, executor driver, partition 7, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:23.746908Z","level":"info","event":"25/12/28 17:28:23 INFO Executor: Running task 1.0 in stage 22.0 (TID 38)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:23.757085Z","level":"info","event":"25/12/28 17:28:23 INFO Executor: Running task 0.0 in stage 22.0 (TID 37)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:23.763535Z","level":"info","event":"25/12/28 17:28:23 INFO Executor: Running task 5.0 in stage 22.0 (TID 42)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:23.763669Z","level":"info","event":"25/12/28 17:28:23 INFO Executor: Running task 7.0 in stage 22.0 (TID 44)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:23.779769Z","level":"info","event":"25/12/28 17:28:23 INFO Executor: Running task 4.0 in stage 22.0 (TID 41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:23.785702Z","level":"info","event":"25/12/28 17:28:23 INFO Executor: Running task 6.0 in stage 22.0 (TID 43)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:23.795273Z","level":"info","event":"25/12/28 17:28:23 INFO Executor: Running task 2.0 in stage 22.0 (TID 39)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:23.831983Z","level":"info","event":"25/12/28 17:28:23 INFO Executor: Running task 3.0 in stage 22.0 (TID 40)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:24.053568Z","level":"info","event":"25/12/28 17:28:24 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 0-8183523, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:24.107746Z","level":"info","event":"25/12/28 17:28:24 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 16367046-24550569, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:24.108040Z","level":"info","event":"25/12/28 17:28:24 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 57284661-61273883, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:24.108397Z","level":"info","event":"25/12/28 17:28:24 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 32734092-40917615, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:24.108479Z","level":"info","event":"25/12/28 17:28:24 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 40917615-49101138, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:24.108523Z","level":"info","event":"25/12/28 17:28:24 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 8183523-16367046, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:24.108567Z","level":"info","event":"25/12/28 17:28:24 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 24550569-32734092, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:24.108614Z","level":"info","event":"25/12/28 17:28:24 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 49101138-57284661, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:26.682131Z","level":"info","event":"25/12/28 17:28:26 INFO Executor: Finished task 6.0 in stage 22.0 (TID 43). 2014 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:26.737797Z","level":"info","event":"25/12/28 17:28:26 INFO Executor: Finished task 2.0 in stage 22.0 (TID 39). 2014 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:26.738245Z","level":"info","event":"25/12/28 17:28:26 INFO Executor: Finished task 5.0 in stage 22.0 (TID 42). 2014 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:26.738278Z","level":"info","event":"25/12/28 17:28:26 INFO Executor: Finished task 3.0 in stage 22.0 (TID 40). 2014 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:26.738295Z","level":"info","event":"25/12/28 17:28:26 INFO Executor: Finished task 7.0 in stage 22.0 (TID 44). 2014 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:26.738356Z","level":"info","event":"25/12/28 17:28:26 INFO Executor: Finished task 4.0 in stage 22.0 (TID 41). 2014 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:26.738397Z","level":"info","event":"25/12/28 17:28:26 INFO Executor: Finished task 1.0 in stage 22.0 (TID 38). 2014 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:26.774655Z","level":"info","event":"25/12/28 17:28:26 INFO TaskSetManager: Finished task 2.0 in stage 22.0 (TID 39) in 3098 ms on 28b45f86de62 (executor driver) (1/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:26.775177Z","level":"info","event":"25/12/28 17:28:26 INFO TaskSetManager: Finished task 3.0 in stage 22.0 (TID 40) in 3095 ms on 28b45f86de62 (executor driver) (2/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:26.782017Z","level":"info","event":"25/12/28 17:28:26 INFO TaskSetManager: Finished task 5.0 in stage 22.0 (TID 42) in 3095 ms on 28b45f86de62 (executor driver) (3/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:26.789489Z","level":"info","event":"25/12/28 17:28:26 INFO TaskSetManager: Finished task 4.0 in stage 22.0 (TID 41) in 3104 ms on 28b45f86de62 (executor driver) (4/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:26.789757Z","level":"info","event":"25/12/28 17:28:26 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 38) in 3126 ms on 28b45f86de62 (executor driver) (5/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:26.789892Z","level":"info","event":"25/12/28 17:28:26 INFO TaskSetManager: Finished task 7.0 in stage 22.0 (TID 44) in 3109 ms on 28b45f86de62 (executor driver) (6/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:26.794364Z","level":"info","event":"25/12/28 17:28:26 INFO TaskSetManager: Finished task 6.0 in stage 22.0 (TID 43) in 3113 ms on 28b45f86de62 (executor driver) (7/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:27.050632Z","level":"info","event":"25/12/28 17:28:27 INFO Executor: Finished task 0.0 in stage 22.0 (TID 37). 2014 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:27.073418Z","level":"info","event":"25/12/28 17:28:27 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 37) in 3431 ms on 28b45f86de62 (executor driver) (8/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:27.144515Z","level":"info","event":"25/12/28 17:28:27 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:27.173625Z","level":"info","event":"25/12/28 17:28:27 INFO DAGScheduler: ShuffleMapStage 22 (count at NativeMethodAccessorImpl.java:0) finished in 4.086 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:27.174766Z","level":"info","event":"25/12/28 17:28:27 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:27.191395Z","level":"info","event":"25/12/28 17:28:27 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:27.195983Z","level":"info","event":"25/12/28 17:28:27 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:27.196464Z","level":"info","event":"25/12/28 17:28:27 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:28.181360Z","level":"info","event":"25/12/28 17:28:28 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:28.216514Z","level":"info","event":"25/12/28 17:28:28 INFO DAGScheduler: Got job 17 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:28.223095Z","level":"info","event":"25/12/28 17:28:28 INFO DAGScheduler: Final stage: ResultStage 24 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:28.223541Z","level":"info","event":"25/12/28 17:28:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:28.232573Z","level":"info","event":"25/12/28 17:28:28 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:28.258204Z","level":"info","event":"25/12/28 17:28:28 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[68] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:28.367121Z","level":"info","event":"25/12/28 17:28:28 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 12.5 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:28.439534Z","level":"info","event":"25/12/28 17:28:28 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:28.464745Z","level":"info","event":"25/12/28 17:28:28 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 28b45f86de62:35353 (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:28.483119Z","level":"info","event":"25/12/28 17:28:28 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:28.502144Z","level":"info","event":"25/12/28 17:28:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[68] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:28.512202Z","level":"info","event":"25/12/28 17:28:28 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:28.659837Z","level":"info","event":"25/12/28 17:28:28 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 45) (28b45f86de62, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:28.677063Z","level":"info","event":"25/12/28 17:28:28 INFO Executor: Running task 0.0 in stage 24.0 (TID 45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:28.973386Z","level":"info","event":"25/12/28 17:28:28 INFO ShuffleBlockFetcherIterator: Getting 8 (480.0 B) non-empty blocks including 8 (480.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:28.979392Z","level":"info","event":"25/12/28 17:28:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 56 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:29.402265Z","level":"info","event":"25/12/28 17:28:29 INFO Executor: Finished task 0.0 in stage 24.0 (TID 45). 4038 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:29.423373Z","level":"info","event":"25/12/28 17:28:29 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 45) in 780 ms on 28b45f86de62 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:29.424271Z","level":"info","event":"25/12/28 17:28:29 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:29.446073Z","level":"info","event":"25/12/28 17:28:29 INFO DAGScheduler: ResultStage 24 (count at NativeMethodAccessorImpl.java:0) finished in 1.104 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:29.447278Z","level":"info","event":"25/12/28 17:28:29 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:29.452797Z","level":"info","event":"25/12/28 17:28:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:29.476341Z","level":"info","event":"25/12/28 17:28:29 INFO DAGScheduler: Job 17 finished: count at NativeMethodAccessorImpl.java:0, took 1.299315 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:29.597104Z","level":"info","event":"Loaded olist_geolocation with 1000163 records.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:31.208313Z","level":"info","event":"25/12/28 17:28:31 INFO FileSourceStrategy: Pushed Filters: IsNull(geolocation_zip_code_prefix)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:31.268801Z","level":"info","event":"25/12/28 17:28:31 INFO FileSourceStrategy: Post-Scan Filters: isnull(geolocation_zip_code_prefix#110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:32.403367Z","level":"info","event":"25/12/28 17:28:32 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 199.4 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:32.697133Z","level":"info","event":"25/12/28 17:28:32 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:32.767498Z","level":"info","event":"25/12/28 17:28:32 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 28b45f86de62:35353 (size: 34.3 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:32.852356Z","level":"info","event":"25/12/28 17:28:32 INFO SparkContext: Created broadcast 29 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:32.945369Z","level":"info","event":"25/12/28 17:28:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8183523 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.208882Z","level":"info","event":"25/12/28 17:28:33 INFO DAGScheduler: Registering RDD 72 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 7","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.238639Z","level":"info","event":"25/12/28 17:28:33 INFO DAGScheduler: Got map stage job 18 (count at NativeMethodAccessorImpl.java:0) with 8 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.239234Z","level":"info","event":"25/12/28 17:28:33 INFO DAGScheduler: Final stage: ShuffleMapStage 25 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.239289Z","level":"info","event":"25/12/28 17:28:33 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.241119Z","level":"info","event":"25/12/28 17:28:33 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.253074Z","level":"info","event":"25/12/28 17:28:33 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[72] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.334524Z","level":"info","event":"25/12/28 17:28:33 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 18.5 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.432014Z","level":"info","event":"25/12/28 17:28:33 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.458350Z","level":"info","event":"25/12/28 17:28:33 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 28b45f86de62:35353 (size: 9.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.472531Z","level":"info","event":"25/12/28 17:28:33 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.485812Z","level":"info","event":"25/12/28 17:28:33 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[72] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.488228Z","level":"info","event":"25/12/28 17:28:33 INFO TaskSchedulerImpl: Adding task set 25.0 with 8 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.535182Z","level":"info","event":"25/12/28 17:28:33 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 46) (28b45f86de62, executor driver, partition 0, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.540824Z","level":"info","event":"25/12/28 17:28:33 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 47) (28b45f86de62, executor driver, partition 1, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.542072Z","level":"info","event":"25/12/28 17:28:33 INFO TaskSetManager: Starting task 2.0 in stage 25.0 (TID 48) (28b45f86de62, executor driver, partition 2, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.542578Z","level":"info","event":"25/12/28 17:28:33 INFO TaskSetManager: Starting task 3.0 in stage 25.0 (TID 49) (28b45f86de62, executor driver, partition 3, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.542885Z","level":"info","event":"25/12/28 17:28:33 INFO TaskSetManager: Starting task 4.0 in stage 25.0 (TID 50) (28b45f86de62, executor driver, partition 4, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.543239Z","level":"info","event":"25/12/28 17:28:33 INFO TaskSetManager: Starting task 5.0 in stage 25.0 (TID 51) (28b45f86de62, executor driver, partition 5, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.543469Z","level":"info","event":"25/12/28 17:28:33 INFO TaskSetManager: Starting task 6.0 in stage 25.0 (TID 52) (28b45f86de62, executor driver, partition 6, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.553064Z","level":"info","event":"25/12/28 17:28:33 INFO TaskSetManager: Starting task 7.0 in stage 25.0 (TID 53) (28b45f86de62, executor driver, partition 7, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.581599Z","level":"info","event":"25/12/28 17:28:33 INFO Executor: Running task 4.0 in stage 25.0 (TID 50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.582088Z","level":"info","event":"25/12/28 17:28:33 INFO Executor: Running task 3.0 in stage 25.0 (TID 49)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.582332Z","level":"info","event":"25/12/28 17:28:33 INFO Executor: Running task 7.0 in stage 25.0 (TID 53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.582507Z","level":"info","event":"25/12/28 17:28:33 INFO Executor: Running task 1.0 in stage 25.0 (TID 47)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.587263Z","level":"info","event":"25/12/28 17:28:33 INFO Executor: Running task 5.0 in stage 25.0 (TID 51)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.587614Z","level":"info","event":"25/12/28 17:28:33 INFO Executor: Running task 0.0 in stage 25.0 (TID 46)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.589726Z","level":"info","event":"25/12/28 17:28:33 INFO Executor: Running task 6.0 in stage 25.0 (TID 52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.596966Z","level":"info","event":"25/12/28 17:28:33 INFO Executor: Running task 2.0 in stage 25.0 (TID 48)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.827717Z","level":"info","event":"25/12/28 17:28:33 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 57284661-61273883, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.902627Z","level":"info","event":"25/12/28 17:28:33 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 16367046-24550569, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.903873Z","level":"info","event":"25/12/28 17:28:33 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 32734092-40917615, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.914350Z","level":"info","event":"25/12/28 17:28:33 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 24550569-32734092, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.914648Z","level":"info","event":"25/12/28 17:28:33 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 40917615-49101138, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.914873Z","level":"info","event":"25/12/28 17:28:33 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 49101138-57284661, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.919250Z","level":"info","event":"25/12/28 17:28:33 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 8183523-16367046, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:33.919459Z","level":"info","event":"25/12/28 17:28:33 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 0-8183523, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:36.294646Z","level":"info","event":"25/12/28 17:28:36 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 28b45f86de62:35353 in memory (size: 34.3 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:38.787638Z","level":"info","event":"25/12/28 17:28:38 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 28b45f86de62:35353 in memory (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:38.903210Z","level":"info","event":"25/12/28 17:28:38 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 28b45f86de62:35353 in memory (size: 8.8 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:40.100865Z","level":"info","event":"25/12/28 17:28:40 INFO Executor: Finished task 7.0 in stage 25.0 (TID 53). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:40.383923Z","level":"info","event":"25/12/28 17:28:40 INFO TaskSetManager: Finished task 7.0 in stage 25.0 (TID 53) in 6836 ms on 28b45f86de62 (executor driver) (1/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:42.731494Z","level":"info","event":"25/12/28 17:28:42 INFO Executor: Finished task 6.0 in stage 25.0 (TID 52). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:42.748595Z","level":"info","event":"25/12/28 17:28:42 INFO Executor: Finished task 3.0 in stage 25.0 (TID 49). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:42.798709Z","level":"info","event":"25/12/28 17:28:42 INFO TaskSetManager: Finished task 3.0 in stage 25.0 (TID 49) in 9257 ms on 28b45f86de62 (executor driver) (2/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:42.868643Z","level":"info","event":"25/12/28 17:28:42 INFO TaskSetManager: Finished task 6.0 in stage 25.0 (TID 52) in 9319 ms on 28b45f86de62 (executor driver) (3/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:43.019257Z","level":"info","event":"25/12/28 17:28:43 INFO Executor: Finished task 1.0 in stage 25.0 (TID 47). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:43.019554Z","level":"info","event":"25/12/28 17:28:43 INFO Executor: Finished task 2.0 in stage 25.0 (TID 48). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:43.053126Z","level":"info","event":"25/12/28 17:28:43 INFO TaskSetManager: Finished task 2.0 in stage 25.0 (TID 48) in 9516 ms on 28b45f86de62 (executor driver) (4/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:43.080396Z","level":"info","event":"25/12/28 17:28:43 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 47) in 9520 ms on 28b45f86de62 (executor driver) (5/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:43.208417Z","level":"info","event":"25/12/28 17:28:43 INFO Executor: Finished task 5.0 in stage 25.0 (TID 51). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:43.219690Z","level":"info","event":"25/12/28 17:28:43 INFO TaskSetManager: Finished task 5.0 in stage 25.0 (TID 51) in 9683 ms on 28b45f86de62 (executor driver) (6/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:43.252631Z","level":"info","event":"25/12/28 17:28:43 INFO Executor: Finished task 0.0 in stage 25.0 (TID 46). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:43.256934Z","level":"info","event":"25/12/28 17:28:43 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 46) in 9727 ms on 28b45f86de62 (executor driver) (7/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:43.314141Z","level":"info","event":"25/12/28 17:28:43 INFO Executor: Finished task 4.0 in stage 25.0 (TID 50). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:43.345992Z","level":"info","event":"25/12/28 17:28:43 INFO TaskSetManager: Finished task 4.0 in stage 25.0 (TID 50) in 9804 ms on 28b45f86de62 (executor driver) (8/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:43.346568Z","level":"info","event":"25/12/28 17:28:43 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:43.393743Z","level":"info","event":"25/12/28 17:28:43 INFO DAGScheduler: ShuffleMapStage 25 (count at NativeMethodAccessorImpl.java:0) finished in 10.065 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:43.421661Z","level":"info","event":"25/12/28 17:28:43 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:43.422063Z","level":"info","event":"25/12/28 17:28:43 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:43.422194Z","level":"info","event":"25/12/28 17:28:43 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:43.422376Z","level":"info","event":"25/12/28 17:28:43 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:46.026526Z","level":"info","event":"25/12/28 17:28:45 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:46.309699Z","level":"info","event":"25/12/28 17:28:46 INFO DAGScheduler: Got job 19 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:46.310107Z","level":"info","event":"25/12/28 17:28:46 INFO DAGScheduler: Final stage: ResultStage 27 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:46.310283Z","level":"info","event":"25/12/28 17:28:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:46.328961Z","level":"info","event":"25/12/28 17:28:46 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:46.365215Z","level":"info","event":"25/12/28 17:28:46 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[75] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:47.046367Z","level":"info","event":"25/12/28 17:28:46 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 12.5 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:47.253075Z","level":"info","event":"25/12/28 17:28:47 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:47.293101Z","level":"info","event":"25/12/28 17:28:47 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 28b45f86de62:35353 (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:47.347955Z","level":"info","event":"25/12/28 17:28:47 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:47.406355Z","level":"info","event":"25/12/28 17:28:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[75] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:47.408884Z","level":"info","event":"25/12/28 17:28:47 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:47.546764Z","level":"info","event":"25/12/28 17:28:47 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 54) (28b45f86de62, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:47.604037Z","level":"info","event":"25/12/28 17:28:47 INFO Executor: Running task 0.0 in stage 27.0 (TID 54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:48.039385Z","level":"info","event":"25/12/28 17:28:48 INFO ShuffleBlockFetcherIterator: Getting 8 (480.0 B) non-empty blocks including 8 (480.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:48.057114Z","level":"info","event":"25/12/28 17:28:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 116 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:48.445569Z","level":"info","event":"25/12/28 17:28:48 INFO Executor: Finished task 0.0 in stage 27.0 (TID 54). 4031 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:48.610090Z","level":"info","event":"25/12/28 17:28:48 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 54) in 1069 ms on 28b45f86de62 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:48.630237Z","level":"info","event":"25/12/28 17:28:48 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:48.743369Z","level":"info","event":"25/12/28 17:28:48 INFO DAGScheduler: ResultStage 27 (count at NativeMethodAccessorImpl.java:0) finished in 2.206 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:48.842926Z","level":"info","event":"25/12/28 17:28:48 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:48.854411Z","level":"info","event":"25/12/28 17:28:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:48.905207Z","level":"info","event":"25/12/28 17:28:48 INFO DAGScheduler: Job 19 finished: count at NativeMethodAccessorImpl.java:0, took 2.873822 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:51.103506Z","level":"info","event":"25/12/28 17:28:51 INFO FileSourceStrategy: Pushed Filters: IsNull(geolocation_lat)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:51.112025Z","level":"info","event":"25/12/28 17:28:51 INFO FileSourceStrategy: Post-Scan Filters: isnull(geolocation_lat#111)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:53.340743Z","level":"info","event":"25/12/28 17:28:53 INFO CodeGenerator: Code generated in 1560.094335 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:53.808647Z","level":"info","event":"25/12/28 17:28:53 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 199.4 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:54.058966Z","level":"info","event":"25/12/28 17:28:54 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:54.150308Z","level":"info","event":"25/12/28 17:28:54 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 28b45f86de62:35353 (size: 34.3 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:54.232088Z","level":"info","event":"25/12/28 17:28:54 INFO SparkContext: Created broadcast 32 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:54.383257Z","level":"info","event":"25/12/28 17:28:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8183523 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:55.464178Z","level":"info","event":"25/12/28 17:28:55 INFO DAGScheduler: Registering RDD 79 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 8","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:55.493523Z","level":"info","event":"25/12/28 17:28:55 INFO DAGScheduler: Got map stage job 20 (count at NativeMethodAccessorImpl.java:0) with 8 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:55.520474Z","level":"info","event":"25/12/28 17:28:55 INFO DAGScheduler: Final stage: ShuffleMapStage 28 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:55.521182Z","level":"info","event":"25/12/28 17:28:55 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:55.574597Z","level":"info","event":"25/12/28 17:28:55 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:55.618769Z","level":"info","event":"25/12/28 17:28:55 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[79] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:57.451754Z","level":"info","event":"25/12/28 17:28:57 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 18.5 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:58.089543Z","level":"info","event":"25/12/28 17:28:58 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:58.205629Z","level":"info","event":"25/12/28 17:28:58 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 28b45f86de62:35353 (size: 9.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:58.327216Z","level":"info","event":"25/12/28 17:28:58 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:58.515274Z","level":"info","event":"25/12/28 17:28:58 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[79] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:58.528471Z","level":"info","event":"25/12/28 17:28:58 INFO TaskSchedulerImpl: Adding task set 28.0 with 8 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:58.806617Z","level":"info","event":"25/12/28 17:28:58 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 55) (28b45f86de62, executor driver, partition 0, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:58.812163Z","level":"info","event":"25/12/28 17:28:58 INFO TaskSetManager: Starting task 1.0 in stage 28.0 (TID 56) (28b45f86de62, executor driver, partition 1, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:58.812914Z","level":"info","event":"25/12/28 17:28:58 INFO TaskSetManager: Starting task 2.0 in stage 28.0 (TID 57) (28b45f86de62, executor driver, partition 2, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:58.813199Z","level":"info","event":"25/12/28 17:28:58 INFO TaskSetManager: Starting task 3.0 in stage 28.0 (TID 58) (28b45f86de62, executor driver, partition 3, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:58.814724Z","level":"info","event":"25/12/28 17:28:58 INFO TaskSetManager: Starting task 4.0 in stage 28.0 (TID 59) (28b45f86de62, executor driver, partition 4, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:58.816096Z","level":"info","event":"25/12/28 17:28:58 INFO TaskSetManager: Starting task 5.0 in stage 28.0 (TID 60) (28b45f86de62, executor driver, partition 5, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:58.822449Z","level":"info","event":"25/12/28 17:28:58 INFO TaskSetManager: Starting task 6.0 in stage 28.0 (TID 61) (28b45f86de62, executor driver, partition 6, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:58.829961Z","level":"info","event":"25/12/28 17:28:58 INFO TaskSetManager: Starting task 7.0 in stage 28.0 (TID 62) (28b45f86de62, executor driver, partition 7, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:58.895765Z","level":"info","event":"25/12/28 17:28:58 INFO Executor: Running task 1.0 in stage 28.0 (TID 56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:58.906405Z","level":"info","event":"25/12/28 17:28:58 INFO Executor: Running task 0.0 in stage 28.0 (TID 55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:58.906731Z","level":"info","event":"25/12/28 17:28:58 INFO Executor: Running task 5.0 in stage 28.0 (TID 60)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:58.907076Z","level":"info","event":"25/12/28 17:28:58 INFO Executor: Running task 6.0 in stage 28.0 (TID 61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:58.907250Z","level":"info","event":"25/12/28 17:28:58 INFO Executor: Running task 3.0 in stage 28.0 (TID 58)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:58.907526Z","level":"info","event":"25/12/28 17:28:58 INFO Executor: Running task 2.0 in stage 28.0 (TID 57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:58.910292Z","level":"info","event":"25/12/28 17:28:58 INFO Executor: Running task 4.0 in stage 28.0 (TID 59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:28:59.089881Z","level":"info","event":"25/12/28 17:28:59 INFO Executor: Running task 7.0 in stage 28.0 (TID 62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:00.362119Z","level":"info","event":"25/12/28 17:29:00 INFO CodeGenerator: Code generated in 686.148458 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:00.652364Z","level":"info","event":"25/12/28 17:29:00 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 8183523-16367046, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:00.653108Z","level":"info","event":"25/12/28 17:29:00 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 32734092-40917615, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:00.665130Z","level":"info","event":"25/12/28 17:29:00 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 24550569-32734092, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:00.665526Z","level":"info","event":"25/12/28 17:29:00 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 0-8183523, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:00.666772Z","level":"info","event":"25/12/28 17:29:00 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 16367046-24550569, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:00.671000Z","level":"info","event":"25/12/28 17:29:00 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 40917615-49101138, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:00.671652Z","level":"info","event":"25/12/28 17:29:00 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 49101138-57284661, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:00.711660Z","level":"info","event":"25/12/28 17:29:00 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 57284661-61273883, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:02.868941Z","level":"info","event":"25/12/28 17:29:02 INFO CodeGenerator: Code generated in 1771.295959 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:04.349637Z","level":"info","event":"25/12/28 17:29:03 INFO CodeGenerator: Code generated in 541.97925 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:19.236718Z","level":"info","event":"25/12/28 17:29:18 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 28b45f86de62:35353 in memory (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:28.624996Z","level":"info","event":"25/12/28 17:29:27 INFO Executor: Finished task 7.0 in stage 28.0 (TID 62). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:31.938011Z","level":"info","event":"25/12/28 17:29:31 INFO TaskSetManager: Finished task 7.0 in stage 28.0 (TID 62) in 32995 ms on 28b45f86de62 (executor driver) (1/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:38.137912Z","level":"info","event":"25/12/28 17:29:37 INFO Executor: Finished task 4.0 in stage 28.0 (TID 59). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:38.318402Z","level":"info","event":"25/12/28 17:29:38 INFO Executor: Finished task 2.0 in stage 28.0 (TID 57). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:38.320406Z","level":"info","event":"25/12/28 17:29:38 INFO Executor: Finished task 0.0 in stage 28.0 (TID 55). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:39.131542Z","level":"info","event":"25/12/28 17:29:39 INFO Executor: Finished task 1.0 in stage 28.0 (TID 56). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:39.140968Z","level":"info","event":"25/12/28 17:29:39 INFO Executor: Finished task 3.0 in stage 28.0 (TID 58). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:39.282829Z","level":"info","event":"25/12/28 17:29:39 INFO TaskSetManager: Finished task 4.0 in stage 28.0 (TID 59) in 40255 ms on 28b45f86de62 (executor driver) (2/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:39.409442Z","level":"info","event":"25/12/28 17:29:39 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 55) in 40647 ms on 28b45f86de62 (executor driver) (3/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:39.660726Z","level":"info","event":"25/12/28 17:29:39 INFO TaskSetManager: Finished task 2.0 in stage 28.0 (TID 57) in 40753 ms on 28b45f86de62 (executor driver) (4/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:39.675450Z","level":"info","event":"25/12/28 17:29:39 INFO TaskSetManager: Finished task 1.0 in stage 28.0 (TID 56) in 40860 ms on 28b45f86de62 (executor driver) (5/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:39.697789Z","level":"info","event":"25/12/28 17:29:39 INFO TaskSetManager: Finished task 3.0 in stage 28.0 (TID 58) in 40882 ms on 28b45f86de62 (executor driver) (6/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:40.031007Z","level":"info","event":"25/12/28 17:29:40 INFO Executor: Finished task 5.0 in stage 28.0 (TID 60). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:40.134266Z","level":"info","event":"25/12/28 17:29:40 INFO TaskSetManager: Finished task 5.0 in stage 28.0 (TID 60) in 41315 ms on 28b45f86de62 (executor driver) (7/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:40.895235Z","level":"info","event":"25/12/28 17:29:40 INFO Executor: Finished task 6.0 in stage 28.0 (TID 61). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:41.089700Z","level":"info","event":"25/12/28 17:29:41 INFO TaskSetManager: Finished task 6.0 in stage 28.0 (TID 61) in 42252 ms on 28b45f86de62 (executor driver) (8/8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:41.144361Z","level":"info","event":"25/12/28 17:29:41 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:41.581769Z","level":"info","event":"25/12/28 17:29:41 INFO DAGScheduler: ShuffleMapStage 28 (count at NativeMethodAccessorImpl.java:0) finished in 45.471 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:41.589676Z","level":"info","event":"25/12/28 17:29:41 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:41.643793Z","level":"info","event":"25/12/28 17:29:41 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:41.648770Z","level":"info","event":"25/12/28 17:29:41 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:41.668392Z","level":"info","event":"25/12/28 17:29:41 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:53.949148Z","level":"info","event":"25/12/28 17:29:53 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:54.204877Z","level":"info","event":"25/12/28 17:29:54 INFO DAGScheduler: Got job 21 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:54.206101Z","level":"info","event":"25/12/28 17:29:54 INFO DAGScheduler: Final stage: ResultStage 30 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:54.211618Z","level":"info","event":"25/12/28 17:29:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:54.224482Z","level":"info","event":"25/12/28 17:29:54 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:54.259674Z","level":"info","event":"25/12/28 17:29:54 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[82] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:54.449030Z","level":"info","event":"25/12/28 17:29:54 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 12.5 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:55.766080Z","level":"info","event":"25/12/28 17:29:55 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:55.941525Z","level":"info","event":"25/12/28 17:29:55 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 28b45f86de62:35353 (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:56.533674Z","level":"info","event":"25/12/28 17:29:56 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:56.814886Z","level":"info","event":"25/12/28 17:29:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[82] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:56.819330Z","level":"info","event":"25/12/28 17:29:56 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:58.048367Z","level":"info","event":"25/12/28 17:29:57 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 63) (28b45f86de62, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:29:58.375132Z","level":"info","event":"25/12/28 17:29:58 INFO Executor: Running task 0.0 in stage 30.0 (TID 63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:01.422658Z","level":"info","event":"25/12/28 17:30:01 INFO ShuffleBlockFetcherIterator: Getting 8 (480.0 B) non-empty blocks including 8 (480.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:01.504936Z","level":"info","event":"25/12/28 17:30:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 760 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:03.151778Z","level":"info","event":"25/12/28 17:30:02 INFO Executor: Finished task 0.0 in stage 30.0 (TID 63). 4031 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:03.522102Z","level":"info","event":"25/12/28 17:30:03 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 63) in 6033 ms on 28b45f86de62 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:03.607556Z","level":"info","event":"25/12/28 17:30:03 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:05.251926Z","level":"info","event":"25/12/28 17:30:05 INFO DAGScheduler: ResultStage 30 (count at NativeMethodAccessorImpl.java:0) finished in 10.086 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:05.334132Z","level":"info","event":"25/12/28 17:30:05 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:05.334550Z","level":"info","event":"25/12/28 17:30:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:05.768860Z","level":"info","event":"25/12/28 17:30:05 INFO DAGScheduler: Job 21 finished: count at NativeMethodAccessorImpl.java:0, took 11.544122 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:19.203374Z","level":"info","event":"25/12/28 17:30:18 INFO FileSourceStrategy: Pushed Filters: IsNull(geolocation_lng)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:19.488063Z","level":"info","event":"25/12/28 17:30:19 INFO FileSourceStrategy: Post-Scan Filters: isnull(geolocation_lng#112)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:24.794080Z","level":"info","event":"25/12/28 17:30:24 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 199.4 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:25.476865Z","level":"info","event":"25/12/28 17:30:25 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:25.510287Z","level":"info","event":"25/12/28 17:30:25 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 28b45f86de62:35353 (size: 34.3 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:26.024847Z","level":"info","event":"25/12/28 17:30:25 INFO SparkContext: Created broadcast 35 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:27.889412Z","level":"info","event":"25/12/28 17:30:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8183523 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:29.924355Z","level":"info","event":"25/12/28 17:30:29 INFO DAGScheduler: Registering RDD 86 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 9","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:30.137314Z","level":"info","event":"25/12/28 17:30:30 INFO DAGScheduler: Got map stage job 22 (count at NativeMethodAccessorImpl.java:0) with 8 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:30.137771Z","level":"info","event":"25/12/28 17:30:30 INFO DAGScheduler: Final stage: ShuffleMapStage 31 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:30.137890Z","level":"info","event":"25/12/28 17:30:30 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:30.302063Z","level":"info","event":"25/12/28 17:30:30 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:30.372287Z","level":"info","event":"25/12/28 17:30:30 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[86] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:31.465734Z","level":"info","event":"25/12/28 17:30:31 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 18.5 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:31.761513Z","level":"info","event":"25/12/28 17:30:31 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:31.903281Z","level":"info","event":"25/12/28 17:30:31 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 28b45f86de62:35353 (size: 9.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:31.999962Z","level":"info","event":"25/12/28 17:30:31 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:32.050320Z","level":"info","event":"25/12/28 17:30:32 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[86] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:32.060395Z","level":"info","event":"25/12/28 17:30:32 INFO TaskSchedulerImpl: Adding task set 31.0 with 8 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:32.200820Z","level":"info","event":"25/12/28 17:30:32 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 64) (28b45f86de62, executor driver, partition 0, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:32.212104Z","level":"info","event":"25/12/28 17:30:32 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 65) (28b45f86de62, executor driver, partition 1, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:32.218135Z","level":"info","event":"25/12/28 17:30:32 INFO TaskSetManager: Starting task 2.0 in stage 31.0 (TID 66) (28b45f86de62, executor driver, partition 2, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:32.225998Z","level":"info","event":"25/12/28 17:30:32 INFO TaskSetManager: Starting task 3.0 in stage 31.0 (TID 67) (28b45f86de62, executor driver, partition 3, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:32.226169Z","level":"info","event":"25/12/28 17:30:32 INFO TaskSetManager: Starting task 4.0 in stage 31.0 (TID 68) (28b45f86de62, executor driver, partition 4, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:32.226202Z","level":"info","event":"25/12/28 17:30:32 INFO TaskSetManager: Starting task 5.0 in stage 31.0 (TID 69) (28b45f86de62, executor driver, partition 5, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:32.226219Z","level":"info","event":"25/12/28 17:30:32 INFO TaskSetManager: Starting task 6.0 in stage 31.0 (TID 70) (28b45f86de62, executor driver, partition 6, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:32.277156Z","level":"info","event":"25/12/28 17:30:32 INFO TaskSetManager: Starting task 7.0 in stage 31.0 (TID 71) (28b45f86de62, executor driver, partition 7, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:32.420684Z","level":"info","event":"25/12/28 17:30:32 INFO Executor: Running task 4.0 in stage 31.0 (TID 68)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:32.421678Z","level":"info","event":"25/12/28 17:30:32 INFO Executor: Running task 0.0 in stage 31.0 (TID 64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:32.421956Z","level":"info","event":"25/12/28 17:30:32 INFO Executor: Running task 2.0 in stage 31.0 (TID 66)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:32.440286Z","level":"info","event":"25/12/28 17:30:32 INFO Executor: Running task 6.0 in stage 31.0 (TID 70)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:32.457568Z","level":"info","event":"25/12/28 17:30:32 INFO Executor: Running task 1.0 in stage 31.0 (TID 65)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:32.463046Z","level":"info","event":"25/12/28 17:30:32 INFO Executor: Running task 3.0 in stage 31.0 (TID 67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:32.476079Z","level":"info","event":"25/12/28 17:30:32 INFO Executor: Running task 5.0 in stage 31.0 (TID 69)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:32.829340Z","level":"info","event":"25/12/28 17:30:32 INFO Executor: Running task 7.0 in stage 31.0 (TID 71)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:33.546353Z","level":"info","event":"25/12/28 17:30:33 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 16367046-24550569, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:33.588517Z","level":"info","event":"25/12/28 17:30:33 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 57284661-61273883, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:33.595421Z","level":"info","event":"25/12/28 17:30:33 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 49101138-57284661, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:30:33.595540Z","level":"info","event":"25/12/28 17:30:33 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 32734092-40917615, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
