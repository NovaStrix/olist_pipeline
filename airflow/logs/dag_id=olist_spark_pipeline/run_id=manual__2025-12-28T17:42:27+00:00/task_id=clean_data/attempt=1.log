{"timestamp":"2025-12-28T17:44:04.361806Z","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2025-12-28T17:44:04.362828Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/ecom_pipeline.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2025-12-28T17:44:04.499013Z","level":"warning","event":"The `airflow.hooks.base.BaseHook` attribute is deprecated. Please use `'airflow.sdk.bases.hook.BaseHook'`.","category":"DeprecatedImportWarning","filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py","lineno":35,"logger":"py.warnings"}
{"timestamp":"2025-12-28T17:44:04.540637Z","level":"info","event":"Task instance is in running state","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:44:04.540891Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:44:04.540972Z","level":"info","event":"Current task name:clean_data","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:44:04.541041Z","level":"info","event":"Dag name:olist_spark_pipeline","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:44:04.555567Z","level":"info","event":"Spark-Submit cmd: spark-submit --master local[*] --name arrow-spark --verbose --deploy-mode client /opt/airflow/src/cleaning.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":474}
{"timestamp":"2025-12-28T17:44:06.966566Z","level":"info","event":"Using properties file: null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.066963Z","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.067264Z","level":"info","event":"master                  local[*]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.067400Z","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.067470Z","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.067564Z","level":"info","event":"executorMemory          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.067631Z","level":"info","event":"executorCores           null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.067696Z","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.067755Z","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.067803Z","level":"info","event":"driverMemory            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.067851Z","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.067931Z","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.068049Z","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.068151Z","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.068191Z","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.068212Z","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.068295Z","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.068324Z","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.068339Z","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.068383Z","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.068411Z","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.068468Z","level":"info","event":"primaryResource         file:/opt/airflow/src/cleaning.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.068515Z","level":"info","event":"name                    arrow-spark","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.068555Z","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.068573Z","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.068597Z","level":"info","event":"packages                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.068741Z","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.068850Z","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.068981Z","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.069046Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.069133Z","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.069321Z","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.069797Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.069861Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.069889Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.413843Z","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.414012Z","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.414080Z","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.414135Z","level":"info","event":"file:/opt/airflow/src/cleaning.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.414183Z","level":"info","event":"null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.416739Z","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.416840Z","level":"info","event":"(spark.app.name,arrow-spark)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.416862Z","level":"info","event":"(spark.app.submitTime,1766943847397)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.417096Z","level":"info","event":"(spark.master,local[*])","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.417135Z","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.417163Z","level":"info","event":"(spark.submit.pyFiles,)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.417206Z","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.417256Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.417274Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:07.417302Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:08.770894Z","level":"info","event":"25/12/28 17:44:08 INFO SparkContext: Running Spark version 3.5.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:08.775297Z","level":"info","event":"25/12/28 17:44:08 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, aarch64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:08.775521Z","level":"info","event":"25/12/28 17:44:08 INFO SparkContext: Java version 17.0.17","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:08.939413Z","level":"info","event":"25/12/28 17:44:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:09.175900Z","level":"info","event":"25/12/28 17:44:09 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:09.176829Z","level":"info","event":"25/12/28 17:44:09 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:09.180387Z","level":"info","event":"25/12/28 17:44:09 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:09.181398Z","level":"info","event":"25/12/28 17:44:09 INFO SparkContext: Submitted application: Data_Cleaning","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:09.244704Z","level":"info","event":"25/12/28 17:44:09 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:09.261789Z","level":"info","event":"25/12/28 17:44:09 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:09.265360Z","level":"info","event":"25/12/28 17:44:09 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:09.490638Z","level":"info","event":"25/12/28 17:44:09 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:09.496613Z","level":"info","event":"25/12/28 17:44:09 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:09.496840Z","level":"info","event":"25/12/28 17:44:09 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:09.497229Z","level":"info","event":"25/12/28 17:44:09 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:09.497636Z","level":"info","event":"25/12/28 17:44:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:09.976286Z","level":"info","event":"25/12/28 17:44:09 INFO Utils: Successfully started service 'sparkDriver' on port 35971.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:10.030302Z","level":"info","event":"25/12/28 17:44:10 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:10.062721Z","level":"info","event":"25/12/28 17:44:10 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:10.094017Z","level":"info","event":"25/12/28 17:44:10 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:10.094837Z","level":"info","event":"25/12/28 17:44:10 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:10.103453Z","level":"info","event":"25/12/28 17:44:10 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:10.130863Z","level":"info","event":"25/12/28 17:44:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8ed68dfb-3697-4193-96f8-4f269fb9183e","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:10.144287Z","level":"info","event":"25/12/28 17:44:10 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:10.175326Z","level":"info","event":"25/12/28 17:44:10 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:10.361529Z","level":"info","event":"25/12/28 17:44:10 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:10.507746Z","level":"info","event":"25/12/28 17:44:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:10.716152Z","level":"info","event":"25/12/28 17:44:10 INFO Executor: Starting executor ID driver on host c252dd92c865","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:10.716427Z","level":"info","event":"25/12/28 17:44:10 INFO Executor: OS info Linux, 6.10.14-linuxkit, aarch64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:10.716610Z","level":"info","event":"25/12/28 17:44:10 INFO Executor: Java version 17.0.17","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:10.722267Z","level":"info","event":"25/12/28 17:44:10 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:10.722818Z","level":"info","event":"25/12/28 17:44:10 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4dab4b97 for default.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:10.739297Z","level":"info","event":"25/12/28 17:44:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44075.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:10.739391Z","level":"info","event":"25/12/28 17:44:10 INFO NettyBlockTransferService: Server created on c252dd92c865:44075","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:10.739433Z","level":"info","event":"25/12/28 17:44:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:10.742120Z","level":"info","event":"25/12/28 17:44:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, c252dd92c865, 44075, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:10.745290Z","level":"info","event":"25/12/28 17:44:10 INFO BlockManagerMasterEndpoint: Registering block manager c252dd92c865:44075 with 434.4 MiB RAM, BlockManagerId(driver, c252dd92c865, 44075, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:10.745549Z","level":"info","event":"25/12/28 17:44:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, c252dd92c865, 44075, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:10.746608Z","level":"info","event":"25/12/28 17:44:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, c252dd92c865, 44075, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:11.060658Z","level":"info","event":"25/12/28 17:44:11 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:11.065293Z","level":"info","event":"25/12/28 17:44:11 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:11.573934Z","level":"info","event":"25/12/28 17:44:11 INFO InMemoryFileIndex: It took 46 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:11.644658Z","level":"info","event":"25/12/28 17:44:11 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 3 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:16.568285Z","level":"info","event":"25/12/28 17:44:16 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:16.587962Z","level":"info","event":"25/12/28 17:44:16 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:18.660202Z","level":"info","event":"25/12/28 17:44:18 INFO CodeGenerator: Code generated in 596.158501 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:18.935486Z","level":"info","event":"25/12/28 17:44:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 199.3 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:19.197033Z","level":"info","event":"25/12/28 17:44:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:19.228304Z","level":"info","event":"25/12/28 17:44:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on c252dd92c865:44075 (size: 34.3 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:19.258868Z","level":"info","event":"25/12/28 17:44:19 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:19.340660Z","level":"info","event":"25/12/28 17:44:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:19.990808Z","level":"info","event":"25/12/28 17:44:19 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:20.069411Z","level":"info","event":"25/12/28 17:44:20 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:20.073797Z","level":"info","event":"25/12/28 17:44:20 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:20.073996Z","level":"info","event":"25/12/28 17:44:20 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:20.074247Z","level":"info","event":"25/12/28 17:44:20 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:20.119575Z","level":"info","event":"25/12/28 17:44:20 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:21.099417Z","level":"info","event":"25/12/28 17:44:21 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 13.5 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:21.165035Z","level":"info","event":"25/12/28 17:44:21 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:21.206007Z","level":"info","event":"25/12/28 17:44:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on c252dd92c865:44075 (size: 6.4 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:21.236184Z","level":"info","event":"25/12/28 17:44:21 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:21.604645Z","level":"info","event":"25/12/28 17:44:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:21.667643Z","level":"info","event":"25/12/28 17:44:21 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:22.300125Z","level":"info","event":"25/12/28 17:44:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8279 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:22.405323Z","level":"info","event":"25/12/28 17:44:22 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:23.168641Z","level":"info","event":"25/12/28 17:44:23 INFO CodeGenerator: Code generated in 60.402292 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:23.197908Z","level":"info","event":"25/12/28 17:44:23 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_customers/part-00000-31e9eb32-5a70-4bc3-849f-405945f6bfb6-c000.csv, range: 0-3986750, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:23.278984Z","level":"info","event":"25/12/28 17:44:23 INFO CodeGenerator: Code generated in 23.100417 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:23.437457Z","level":"info","event":"25/12/28 17:44:23 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1671 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:23.472150Z","level":"info","event":"25/12/28 17:44:23 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1260 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:23.477641Z","level":"info","event":"25/12/28 17:44:23 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:23.495177Z","level":"info","event":"25/12/28 17:44:23 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 3.306 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:23.510890Z","level":"info","event":"25/12/28 17:44:23 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:23.511180Z","level":"info","event":"25/12/28 17:44:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:23.516978Z","level":"info","event":"25/12/28 17:44:23 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 3.531442 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:23.595440Z","level":"info","event":"25/12/28 17:44:23 INFO CodeGenerator: Code generated in 33.041708 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:23.798172Z","level":"info","event":"25/12/28 17:44:23 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:23.809395Z","level":"info","event":"25/12/28 17:44:23 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:23.839868Z","level":"info","event":"25/12/28 17:44:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 199.3 KiB, free 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:23.876805Z","level":"info","event":"25/12/28 17:44:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:23.879093Z","level":"info","event":"25/12/28 17:44:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on c252dd92c865:44075 (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:23.889793Z","level":"info","event":"25/12/28 17:44:23 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:23.893052Z","level":"info","event":"25/12/28 17:44:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.040793Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.160138Z","level":"info","event":"25/12/28 17:44:24 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.161140Z","level":"info","event":"25/12/28 17:44:24 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.348473Z","level":"info","event":"25/12/28 17:44:24 INFO CodeGenerator: Code generated in 19.25625 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.354791Z","level":"info","event":"25/12/28 17:44:24 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.415808Z","level":"info","event":"25/12/28 17:44:24 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.418505Z","level":"info","event":"25/12/28 17:44:24 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on c252dd92c865:44075 (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.419815Z","level":"info","event":"25/12/28 17:44:24 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.429926Z","level":"info","event":"25/12/28 17:44:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.455835Z","level":"info","event":"25/12/28 17:44:24 INFO BlockManagerInfo: Removed broadcast_1_piece0 on c252dd92c865:44075 in memory (size: 6.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.476619Z","level":"info","event":"25/12/28 17:44:24 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.480627Z","level":"info","event":"25/12/28 17:44:24 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 3 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.480873Z","level":"info","event":"25/12/28 17:44:24 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.481159Z","level":"info","event":"25/12/28 17:44:24 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.481696Z","level":"info","event":"25/12/28 17:44:24 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.483698Z","level":"info","event":"25/12/28 17:44:24 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.517306Z","level":"info","event":"25/12/28 17:44:24 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 17.8 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.521261Z","level":"info","event":"25/12/28 17:44:24 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.522368Z","level":"info","event":"25/12/28 17:44:24 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on c252dd92c865:44075 (size: 8.7 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.523254Z","level":"info","event":"25/12/28 17:44:24 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.526816Z","level":"info","event":"25/12/28 17:44:24 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.527035Z","level":"info","event":"25/12/28 17:44:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.534206Z","level":"info","event":"25/12/28 17:44:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8268 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.534334Z","level":"info","event":"25/12/28 17:44:24 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8268 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.535132Z","level":"info","event":"25/12/28 17:44:24 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8268 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.536450Z","level":"info","event":"25/12/28 17:44:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.540406Z","level":"info","event":"25/12/28 17:44:24 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.542805Z","level":"info","event":"25/12/28 17:44:24 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.586180Z","level":"info","event":"25/12/28 17:44:24 INFO CodeGenerator: Code generated in 13.532833 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.607027Z","level":"info","event":"25/12/28 17:44:24 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_customers/part-00002-31e9eb32-5a70-4bc3-849f-405945f6bfb6-c000.csv, range: 0-613296, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.607815Z","level":"info","event":"25/12/28 17:44:24 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_customers/part-00000-31e9eb32-5a70-4bc3-849f-405945f6bfb6-c000.csv, range: 0-3986750, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.608069Z","level":"info","event":"25/12/28 17:44:24 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_customers/part-00001-31e9eb32-5a70-4bc3-849f-405945f6bfb6-c000.csv, range: 0-3986389, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:24.626613Z","level":"info","event":"25/12/28 17:44:24 INFO CodeGenerator: Code generated in 20.739458 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:26.378372Z","level":"info","event":"25/12/28 17:44:26 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 2014 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:26.393989Z","level":"info","event":"25/12/28 17:44:26 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 2014 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:26.398010Z","level":"info","event":"25/12/28 17:44:26 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2014 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:26.418894Z","level":"info","event":"25/12/28 17:44:26 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1879 ms on c252dd92c865 (executor driver) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:26.423949Z","level":"info","event":"25/12/28 17:44:26 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1887 ms on c252dd92c865 (executor driver) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:26.424475Z","level":"info","event":"25/12/28 17:44:26 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1886 ms on c252dd92c865 (executor driver) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:26.424644Z","level":"info","event":"25/12/28 17:44:26 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:26.452187Z","level":"info","event":"25/12/28 17:44:26 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.963 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:26.455182Z","level":"info","event":"25/12/28 17:44:26 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:26.456337Z","level":"info","event":"25/12/28 17:44:26 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:26.458844Z","level":"info","event":"25/12/28 17:44:26 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:26.459096Z","level":"info","event":"25/12/28 17:44:26 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:26.742182Z","level":"info","event":"25/12/28 17:44:26 INFO CodeGenerator: Code generated in 45.292209 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:26.893951Z","level":"info","event":"25/12/28 17:44:26 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:26.926272Z","level":"info","event":"25/12/28 17:44:26 INFO DAGScheduler: Got job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:26.927522Z","level":"info","event":"25/12/28 17:44:26 INFO DAGScheduler: Final stage: ResultStage 3 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:26.927932Z","level":"info","event":"25/12/28 17:44:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:26.931591Z","level":"info","event":"25/12/28 17:44:26 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:26.938376Z","level":"info","event":"25/12/28 17:44:26 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.075103Z","level":"info","event":"25/12/28 17:44:27 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 12.5 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.101000Z","level":"info","event":"25/12/28 17:44:27 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.109500Z","level":"info","event":"25/12/28 17:44:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on c252dd92c865:44075 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.113316Z","level":"info","event":"25/12/28 17:44:27 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.117373Z","level":"info","event":"25/12/28 17:44:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.118440Z","level":"info","event":"25/12/28 17:44:27 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.145507Z","level":"info","event":"25/12/28 17:44:27 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.147094Z","level":"info","event":"25/12/28 17:44:27 INFO Executor: Running task 0.0 in stage 3.0 (TID 4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.310824Z","level":"info","event":"25/12/28 17:44:27 INFO ShuffleBlockFetcherIterator: Getting 3 (180.0 B) non-empty blocks including 3 (180.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.313762Z","level":"info","event":"25/12/28 17:44:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 20 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.369950Z","level":"info","event":"25/12/28 17:44:27 INFO CodeGenerator: Code generated in 33.841375 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.464148Z","level":"info","event":"25/12/28 17:44:27 INFO BlockManagerInfo: Removed broadcast_4_piece0 on c252dd92c865:44075 in memory (size: 8.7 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.464651Z","level":"info","event":"25/12/28 17:44:27 INFO Executor: Finished task 0.0 in stage 3.0 (TID 4). 4081 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.468635Z","level":"info","event":"25/12/28 17:44:27 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 330 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.468901Z","level":"info","event":"25/12/28 17:44:27 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.475404Z","level":"info","event":"25/12/28 17:44:27 INFO DAGScheduler: ResultStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.410 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.476309Z","level":"info","event":"25/12/28 17:44:27 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.476821Z","level":"info","event":"25/12/28 17:44:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.478855Z","level":"info","event":"25/12/28 17:44:27 INFO DAGScheduler: Job 2 finished: count at NativeMethodAccessorImpl.java:0, took 0.599875 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.492672Z","level":"info","event":"Loaded olist_customers with 99441 records for cleaning.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.505655Z","level":"info","event":"root","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.505859Z","level":"info","event":"|-- customer_id: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.505898Z","level":"info","event":"|-- customer_unique_id: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.505930Z","level":"info","event":"|-- customer_zip_code_prefix: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.505959Z","level":"info","event":"|-- customer_city: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.505998Z","level":"info","event":"|-- customer_state: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.506038Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.554541Z","level":"info","event":"25/12/28 17:44:27 INFO InMemoryFileIndex: It took 17 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.583688Z","level":"info","event":"25/12/28 17:44:27 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 7 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.963636Z","level":"info","event":"25/12/28 17:44:27 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.965680Z","level":"info","event":"25/12/28 17:44:27 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#37, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:27.997355Z","level":"info","event":"25/12/28 17:44:27 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 199.3 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.018303Z","level":"info","event":"25/12/28 17:44:28 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.018939Z","level":"info","event":"25/12/28 17:44:28 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on c252dd92c865:44075 (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.024755Z","level":"info","event":"25/12/28 17:44:28 INFO SparkContext: Created broadcast 6 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.031816Z","level":"info","event":"25/12/28 17:44:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 12662034 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.119240Z","level":"info","event":"25/12/28 17:44:28 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.133374Z","level":"info","event":"25/12/28 17:44:28 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.133518Z","level":"info","event":"25/12/28 17:44:28 INFO DAGScheduler: Final stage: ResultStage 4 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.133779Z","level":"info","event":"25/12/28 17:44:28 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.136108Z","level":"info","event":"25/12/28 17:44:28 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.137930Z","level":"info","event":"25/12/28 17:44:28 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.173450Z","level":"info","event":"25/12/28 17:44:28 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.5 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.189322Z","level":"info","event":"25/12/28 17:44:28 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.194581Z","level":"info","event":"25/12/28 17:44:28 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on c252dd92c865:44075 (size: 6.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.205837Z","level":"info","event":"25/12/28 17:44:28 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.207994Z","level":"info","event":"25/12/28 17:44:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.211133Z","level":"info","event":"25/12/28 17:44:28 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.228572Z","level":"info","event":"25/12/28 17:44:28 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 5) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8281 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.233402Z","level":"info","event":"25/12/28 17:44:28 INFO Executor: Running task 0.0 in stage 4.0 (TID 5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.295761Z","level":"info","event":"25/12/28 17:44:28 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_geolocation/part-00002-4ee8b33c-5a95-42e9-b0de-6c4f4efc9103-c000.csv, range: 0-9053172, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.347161Z","level":"info","event":"25/12/28 17:44:28 INFO Executor: Finished task 0.0 in stage 4.0 (TID 5). 1625 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.367489Z","level":"info","event":"25/12/28 17:44:28 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 5) in 134 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.368256Z","level":"info","event":"25/12/28 17:44:28 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.381819Z","level":"info","event":"25/12/28 17:44:28 INFO DAGScheduler: ResultStage 4 (csv at NativeMethodAccessorImpl.java:0) finished in 0.226 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.385961Z","level":"info","event":"25/12/28 17:44:28 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.386230Z","level":"info","event":"25/12/28 17:44:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.390104Z","level":"info","event":"25/12/28 17:44:28 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.265567 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.554334Z","level":"info","event":"25/12/28 17:44:28 INFO BlockManagerInfo: Removed broadcast_3_piece0 on c252dd92c865:44075 in memory (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.573784Z","level":"info","event":"25/12/28 17:44:28 INFO BlockManagerInfo: Removed broadcast_5_piece0 on c252dd92c865:44075 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.652252Z","level":"info","event":"25/12/28 17:44:28 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.658069Z","level":"info","event":"25/12/28 17:44:28 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.672599Z","level":"info","event":"25/12/28 17:44:28 INFO BlockManagerInfo: Removed broadcast_7_piece0 on c252dd92c865:44075 in memory (size: 6.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.754271Z","level":"info","event":"25/12/28 17:44:28 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 199.3 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.815691Z","level":"info","event":"25/12/28 17:44:28 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.826807Z","level":"info","event":"25/12/28 17:44:28 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on c252dd92c865:44075 (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.837171Z","level":"info","event":"25/12/28 17:44:28 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:28.867037Z","level":"info","event":"25/12/28 17:44:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 12662034 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:29.236302Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:29.632403Z","level":"info","event":"25/12/28 17:44:29 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:29.646561Z","level":"info","event":"25/12/28 17:44:29 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:29.902419Z","level":"info","event":"25/12/28 17:44:29 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 199.2 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:29.953088Z","level":"info","event":"25/12/28 17:44:29 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:29.990547Z","level":"info","event":"25/12/28 17:44:29 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on c252dd92c865:44075 (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.042955Z","level":"info","event":"25/12/28 17:44:30 INFO SparkContext: Created broadcast 9 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.070763Z","level":"info","event":"25/12/28 17:44:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 12662034 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.195024Z","level":"info","event":"25/12/28 17:44:30 INFO DAGScheduler: Registering RDD 30 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.204245Z","level":"info","event":"25/12/28 17:44:30 INFO DAGScheduler: Got map stage job 4 (count at NativeMethodAccessorImpl.java:0) with 7 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.205801Z","level":"info","event":"25/12/28 17:44:30 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.206828Z","level":"info","event":"25/12/28 17:44:30 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.210383Z","level":"info","event":"25/12/28 17:44:30 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.218330Z","level":"info","event":"25/12/28 17:44:30 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.264485Z","level":"info","event":"25/12/28 17:44:30 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 17.8 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.727793Z","level":"info","event":"25/12/28 17:44:30 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.815986Z","level":"info","event":"25/12/28 17:44:30 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on c252dd92c865:44075 (size: 8.7 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.816407Z","level":"info","event":"25/12/28 17:44:30 INFO BlockManagerInfo: Removed broadcast_6_piece0 on c252dd92c865:44075 in memory (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.818345Z","level":"info","event":"25/12/28 17:44:30 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.857554Z","level":"info","event":"25/12/28 17:44:30 INFO DAGScheduler: Submitting 7 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.862530Z","level":"info","event":"25/12/28 17:44:30 INFO TaskSchedulerImpl: Adding task set 5.0 with 7 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.945444Z","level":"info","event":"25/12/28 17:44:30 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 6) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8270 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.959024Z","level":"info","event":"25/12/28 17:44:30 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 7) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8270 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.959424Z","level":"info","event":"25/12/28 17:44:30 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 8) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8270 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.960480Z","level":"info","event":"25/12/28 17:44:30 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 9) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8270 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.961684Z","level":"info","event":"25/12/28 17:44:30 INFO BlockManagerInfo: Removed broadcast_8_piece0 on c252dd92c865:44075 in memory (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.968451Z","level":"info","event":"25/12/28 17:44:30 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 10) (c252dd92c865, executor driver, partition 4, PROCESS_LOCAL, 8270 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.981888Z","level":"info","event":"25/12/28 17:44:30 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 11) (c252dd92c865, executor driver, partition 5, PROCESS_LOCAL, 8270 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.982449Z","level":"info","event":"25/12/28 17:44:30 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 12) (c252dd92c865, executor driver, partition 6, PROCESS_LOCAL, 8270 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.998612Z","level":"info","event":"25/12/28 17:44:30 INFO Executor: Running task 2.0 in stage 5.0 (TID 8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.999071Z","level":"info","event":"25/12/28 17:44:30 INFO Executor: Running task 3.0 in stage 5.0 (TID 9)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:30.999361Z","level":"info","event":"25/12/28 17:44:30 INFO Executor: Running task 0.0 in stage 5.0 (TID 6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:31.014175Z","level":"info","event":"25/12/28 17:44:31 INFO Executor: Running task 1.0 in stage 5.0 (TID 7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:31.014378Z","level":"info","event":"25/12/28 17:44:31 INFO Executor: Running task 6.0 in stage 5.0 (TID 12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:31.014543Z","level":"info","event":"25/12/28 17:44:31 INFO Executor: Running task 5.0 in stage 5.0 (TID 11)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:31.095107Z","level":"info","event":"25/12/28 17:44:31 INFO Executor: Running task 4.0 in stage 5.0 (TID 10)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:31.137030Z","level":"info","event":"25/12/28 17:44:31 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_geolocation/part-00003-4ee8b33c-5a95-42e9-b0de-6c4f4efc9103-c000.csv, range: 0-9052747, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:31.146327Z","level":"info","event":"25/12/28 17:44:31 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_geolocation/part-00000-4ee8b33c-5a95-42e9-b0de-6c4f4efc9103-c000.csv, range: 0-9039701, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:31.146488Z","level":"info","event":"25/12/28 17:44:31 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_geolocation/part-00006-4ee8b33c-5a95-42e9-b0de-6c4f4efc9103-c000.csv, range: 0-4989944, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:31.146878Z","level":"info","event":"25/12/28 17:44:31 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_geolocation/part-00005-4ee8b33c-5a95-42e9-b0de-6c4f4efc9103-c000.csv, range: 0-9043974, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:31.157632Z","level":"info","event":"25/12/28 17:44:31 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_geolocation/part-00002-4ee8b33c-5a95-42e9-b0de-6c4f4efc9103-c000.csv, range: 0-9053172, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:31.158021Z","level":"info","event":"25/12/28 17:44:31 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_geolocation/part-00001-4ee8b33c-5a95-42e9-b0de-6c4f4efc9103-c000.csv, range: 0-9049376, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:31.159977Z","level":"info","event":"25/12/28 17:44:31 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_geolocation/part-00004-4ee8b33c-5a95-42e9-b0de-6c4f4efc9103-c000.csv, range: 0-9045196, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.068107Z","level":"info","event":"25/12/28 17:44:33 INFO Executor: Finished task 6.0 in stage 5.0 (TID 12). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.154033Z","level":"info","event":"25/12/28 17:44:33 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 12) in 2164 ms on c252dd92c865 (executor driver) (1/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.235891Z","level":"info","event":"25/12/28 17:44:33 INFO Executor: Finished task 4.0 in stage 5.0 (TID 10). 2014 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.237747Z","level":"info","event":"25/12/28 17:44:33 INFO Executor: Finished task 1.0 in stage 5.0 (TID 7). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.240933Z","level":"info","event":"25/12/28 17:44:33 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 7) in 2292 ms on c252dd92c865 (executor driver) (2/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.253190Z","level":"info","event":"25/12/28 17:44:33 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 10) in 2289 ms on c252dd92c865 (executor driver) (3/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.365104Z","level":"info","event":"25/12/28 17:44:33 INFO Executor: Finished task 0.0 in stage 5.0 (TID 6). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.380847Z","level":"info","event":"25/12/28 17:44:33 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 6) in 2441 ms on c252dd92c865 (executor driver) (4/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.392464Z","level":"info","event":"25/12/28 17:44:33 INFO Executor: Finished task 3.0 in stage 5.0 (TID 9). 2014 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.407457Z","level":"info","event":"25/12/28 17:44:33 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 9) in 2444 ms on c252dd92c865 (executor driver) (5/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.435083Z","level":"info","event":"25/12/28 17:44:33 INFO Executor: Finished task 5.0 in stage 5.0 (TID 11). 2014 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.444982Z","level":"info","event":"25/12/28 17:44:33 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 11) in 2483 ms on c252dd92c865 (executor driver) (6/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.467250Z","level":"info","event":"25/12/28 17:44:33 INFO Executor: Finished task 2.0 in stage 5.0 (TID 8). 2014 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.475957Z","level":"info","event":"25/12/28 17:44:33 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 8) in 2518 ms on c252dd92c865 (executor driver) (7/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.476067Z","level":"info","event":"25/12/28 17:44:33 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.476855Z","level":"info","event":"25/12/28 17:44:33 INFO DAGScheduler: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 3.239 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.484941Z","level":"info","event":"25/12/28 17:44:33 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.485153Z","level":"info","event":"25/12/28 17:44:33 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.485235Z","level":"info","event":"25/12/28 17:44:33 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.485628Z","level":"info","event":"25/12/28 17:44:33 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.679218Z","level":"info","event":"25/12/28 17:44:33 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.684989Z","level":"info","event":"25/12/28 17:44:33 INFO DAGScheduler: Got job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.690218Z","level":"info","event":"25/12/28 17:44:33 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.691051Z","level":"info","event":"25/12/28 17:44:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.695591Z","level":"info","event":"25/12/28 17:44:33 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.696788Z","level":"info","event":"25/12/28 17:44:33 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[33] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.708487Z","level":"info","event":"25/12/28 17:44:33 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 12.5 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.726653Z","level":"info","event":"25/12/28 17:44:33 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.731389Z","level":"info","event":"25/12/28 17:44:33 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on c252dd92c865:44075 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.735873Z","level":"info","event":"25/12/28 17:44:33 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.738685Z","level":"info","event":"25/12/28 17:44:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[33] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.740266Z","level":"info","event":"25/12/28 17:44:33 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.758797Z","level":"info","event":"25/12/28 17:44:33 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 13) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.766004Z","level":"info","event":"25/12/28 17:44:33 INFO Executor: Running task 0.0 in stage 7.0 (TID 13)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.911371Z","level":"info","event":"25/12/28 17:44:33 INFO ShuffleBlockFetcherIterator: Getting 7 (420.0 B) non-empty blocks including 7 (420.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.921478Z","level":"info","event":"25/12/28 17:44:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 30 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:33.995833Z","level":"info","event":"25/12/28 17:44:33 INFO Executor: Finished task 0.0 in stage 7.0 (TID 13). 4038 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:34.028301Z","level":"info","event":"25/12/28 17:44:34 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 13) in 265 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:34.036679Z","level":"info","event":"25/12/28 17:44:34 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:34.052709Z","level":"info","event":"25/12/28 17:44:34 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.350 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:34.053202Z","level":"info","event":"25/12/28 17:44:34 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:34.053785Z","level":"info","event":"25/12/28 17:44:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:34.061356Z","level":"info","event":"25/12/28 17:44:34 INFO DAGScheduler: Job 5 finished: count at NativeMethodAccessorImpl.java:0, took 0.380303 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:34.203141Z","level":"info","event":"Loaded olist_geolocation with 1000163 records for cleaning.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:34.273127Z","level":"info","event":"root","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:34.273286Z","level":"info","event":"|-- geolocation_zip_code_prefix: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:34.273342Z","level":"info","event":"|-- geolocation_lat: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:34.273367Z","level":"info","event":"|-- geolocation_lng: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:34.273384Z","level":"info","event":"|-- geolocation_city: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:34.273415Z","level":"info","event":"|-- geolocation_state: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:34.273433Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:34.687072Z","level":"info","event":"25/12/28 17:44:34 INFO InMemoryFileIndex: It took 78 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:34.790155Z","level":"info","event":"25/12/28 17:44:34 INFO InMemoryFileIndex: It took 22 ms to list leaf files for 4 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:36.271356Z","level":"info","event":"25/12/28 17:44:36 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:36.276667Z","level":"info","event":"25/12/28 17:44:36 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#74, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:36.474495Z","level":"info","event":"25/12/28 17:44:36 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 199.3 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:36.632277Z","level":"info","event":"25/12/28 17:44:36 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:36.666827Z","level":"info","event":"25/12/28 17:44:36 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on c252dd92c865:44075 (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:36.685953Z","level":"info","event":"25/12/28 17:44:36 INFO SparkContext: Created broadcast 12 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:36.745090Z","level":"info","event":"25/12/28 17:44:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4540723 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:36.946214Z","level":"info","event":"25/12/28 17:44:36 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:36.968551Z","level":"info","event":"25/12/28 17:44:36 INFO DAGScheduler: Got job 6 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:36.968877Z","level":"info","event":"25/12/28 17:44:36 INFO DAGScheduler: Final stage: ResultStage 8 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:36.969068Z","level":"info","event":"25/12/28 17:44:36 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:36.970371Z","level":"info","event":"25/12/28 17:44:36 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:36.991685Z","level":"info","event":"25/12/28 17:44:36 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[37] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:37.052980Z","level":"info","event":"25/12/28 17:44:37 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 13.5 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:37.153439Z","level":"info","event":"25/12/28 17:44:37 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:37.168865Z","level":"info","event":"25/12/28 17:44:37 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on c252dd92c865:44075 (size: 6.4 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:37.182231Z","level":"info","event":"25/12/28 17:44:37 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:37.187890Z","level":"info","event":"25/12/28 17:44:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[37] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:37.188236Z","level":"info","event":"25/12/28 17:44:37 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:37.219182Z","level":"info","event":"25/12/28 17:44:37 INFO BlockManagerInfo: Removed broadcast_10_piece0 on c252dd92c865:44075 in memory (size: 8.7 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:37.249690Z","level":"info","event":"25/12/28 17:44:37 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 14) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8281 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:37.268035Z","level":"info","event":"25/12/28 17:44:37 INFO Executor: Running task 0.0 in stage 8.0 (TID 14)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:37.273836Z","level":"info","event":"25/12/28 17:44:37 INFO BlockManagerInfo: Removed broadcast_9_piece0 on c252dd92c865:44075 in memory (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:37.322232Z","level":"info","event":"25/12/28 17:44:37 INFO BlockManagerInfo: Removed broadcast_11_piece0 on c252dd92c865:44075 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:37.400091Z","level":"info","event":"25/12/28 17:44:37 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_order_items/part-00002-10a84c44-2dd9-4c81-b80f-3a06198118c9-c000.csv, range: 0-4096412, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:37.704499Z","level":"info","event":"25/12/28 17:44:37 INFO Executor: Finished task 0.0 in stage 8.0 (TID 14). 1692 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:37.773454Z","level":"info","event":"25/12/28 17:44:37 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 14) in 549 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:37.774965Z","level":"info","event":"25/12/28 17:44:37 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:37.799902Z","level":"info","event":"25/12/28 17:44:37 INFO DAGScheduler: ResultStage 8 (csv at NativeMethodAccessorImpl.java:0) finished in 0.778 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:37.812039Z","level":"info","event":"25/12/28 17:44:37 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:37.822515Z","level":"info","event":"25/12/28 17:44:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:37.838382Z","level":"info","event":"25/12/28 17:44:37 INFO DAGScheduler: Job 6 finished: csv at NativeMethodAccessorImpl.java:0, took 0.896865 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.226148Z","level":"info","event":"25/12/28 17:44:38 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.232998Z","level":"info","event":"25/12/28 17:44:38 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.287155Z","level":"info","event":"25/12/28 17:44:38 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 199.3 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.334360Z","level":"info","event":"25/12/28 17:44:38 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.341170Z","level":"info","event":"25/12/28 17:44:38 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on c252dd92c865:44075 (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.346664Z","level":"info","event":"25/12/28 17:44:38 INFO SparkContext: Created broadcast 14 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.356808Z","level":"info","event":"25/12/28 17:44:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4540723 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.488866Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.562824Z","level":"info","event":"25/12/28 17:44:38 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.562990Z","level":"info","event":"25/12/28 17:44:38 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.655786Z","level":"info","event":"25/12/28 17:44:38 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 199.2 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.684613Z","level":"info","event":"25/12/28 17:44:38 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.688120Z","level":"info","event":"25/12/28 17:44:38 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on c252dd92c865:44075 (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.690449Z","level":"info","event":"25/12/28 17:44:38 INFO SparkContext: Created broadcast 15 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.693625Z","level":"info","event":"25/12/28 17:44:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4540723 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.711774Z","level":"info","event":"25/12/28 17:44:38 INFO DAGScheduler: Registering RDD 47 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.718921Z","level":"info","event":"25/12/28 17:44:38 INFO DAGScheduler: Got map stage job 7 (count at NativeMethodAccessorImpl.java:0) with 4 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.719042Z","level":"info","event":"25/12/28 17:44:38 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.719096Z","level":"info","event":"25/12/28 17:44:38 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.719139Z","level":"info","event":"25/12/28 17:44:38 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.725655Z","level":"info","event":"25/12/28 17:44:38 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[47] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.737591Z","level":"info","event":"25/12/28 17:44:38 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 17.8 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.750912Z","level":"info","event":"25/12/28 17:44:38 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.754955Z","level":"info","event":"25/12/28 17:44:38 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on c252dd92c865:44075 (size: 8.8 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.758853Z","level":"info","event":"25/12/28 17:44:38 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.762248Z","level":"info","event":"25/12/28 17:44:38 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[47] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.763867Z","level":"info","event":"25/12/28 17:44:38 INFO TaskSchedulerImpl: Adding task set 9.0 with 4 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.785679Z","level":"info","event":"25/12/28 17:44:38 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 15) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8270 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.797111Z","level":"info","event":"25/12/28 17:44:38 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 16) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8270 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.807854Z","level":"info","event":"25/12/28 17:44:38 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 17) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8270 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.811286Z","level":"info","event":"25/12/28 17:44:38 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 18) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8270 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.817126Z","level":"info","event":"25/12/28 17:44:38 INFO Executor: Running task 3.0 in stage 9.0 (TID 18)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.819292Z","level":"info","event":"25/12/28 17:44:38 INFO Executor: Running task 2.0 in stage 9.0 (TID 17)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.822827Z","level":"info","event":"25/12/28 17:44:38 INFO Executor: Running task 1.0 in stage 9.0 (TID 16)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.827650Z","level":"info","event":"25/12/28 17:44:38 INFO Executor: Running task 0.0 in stage 9.0 (TID 15)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.876890Z","level":"info","event":"25/12/28 17:44:38 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_order_items/part-00002-10a84c44-2dd9-4c81-b80f-3a06198118c9-c000.csv, range: 0-4096412, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.877545Z","level":"info","event":"25/12/28 17:44:38 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_order_items/part-00001-10a84c44-2dd9-4c81-b80f-3a06198118c9-c000.csv, range: 0-4055167, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.887172Z","level":"info","event":"25/12/28 17:44:38 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_order_items/part-00000-10a84c44-2dd9-4c81-b80f-3a06198118c9-c000.csv, range: 0-4055057, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:38.887423Z","level":"info","event":"25/12/28 17:44:38 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_order_items/part-00003-10a84c44-2dd9-4c81-b80f-3a06198118c9-c000.csv, range: 0-2801209, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.296954Z","level":"info","event":"25/12/28 17:44:39 INFO Executor: Finished task 3.0 in stage 9.0 (TID 18). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.335797Z","level":"info","event":"25/12/28 17:44:39 INFO Executor: Finished task 1.0 in stage 9.0 (TID 16). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.336201Z","level":"info","event":"25/12/28 17:44:39 INFO Executor: Finished task 0.0 in stage 9.0 (TID 15). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.362465Z","level":"info","event":"25/12/28 17:44:39 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 15) in 580 ms on c252dd92c865 (executor driver) (1/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.367698Z","level":"info","event":"25/12/28 17:44:39 INFO Executor: Finished task 2.0 in stage 9.0 (TID 17). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.371072Z","level":"info","event":"25/12/28 17:44:39 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 16) in 584 ms on c252dd92c865 (executor driver) (2/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.390910Z","level":"info","event":"25/12/28 17:44:39 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 18) in 582 ms on c252dd92c865 (executor driver) (3/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.396940Z","level":"info","event":"25/12/28 17:44:39 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 17) in 597 ms on c252dd92c865 (executor driver) (4/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.402170Z","level":"info","event":"25/12/28 17:44:39 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.426621Z","level":"info","event":"25/12/28 17:44:39 INFO DAGScheduler: ShuffleMapStage 9 (count at NativeMethodAccessorImpl.java:0) finished in 0.687 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.430881Z","level":"info","event":"25/12/28 17:44:39 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.431308Z","level":"info","event":"25/12/28 17:44:39 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.431557Z","level":"info","event":"25/12/28 17:44:39 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.431846Z","level":"info","event":"25/12/28 17:44:39 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.629153Z","level":"info","event":"25/12/28 17:44:39 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.639792Z","level":"info","event":"25/12/28 17:44:39 INFO DAGScheduler: Got job 8 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.639908Z","level":"info","event":"25/12/28 17:44:39 INFO DAGScheduler: Final stage: ResultStage 11 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.639940Z","level":"info","event":"25/12/28 17:44:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.639967Z","level":"info","event":"25/12/28 17:44:39 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.639985Z","level":"info","event":"25/12/28 17:44:39 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[50] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.656233Z","level":"info","event":"25/12/28 17:44:39 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 12.5 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.758266Z","level":"info","event":"25/12/28 17:44:39 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.766873Z","level":"info","event":"25/12/28 17:44:39 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on c252dd92c865:44075 (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.773789Z","level":"info","event":"25/12/28 17:44:39 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.776150Z","level":"info","event":"25/12/28 17:44:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[50] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.777315Z","level":"info","event":"25/12/28 17:44:39 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.777790Z","level":"info","event":"25/12/28 17:44:39 INFO BlockManagerInfo: Removed broadcast_16_piece0 on c252dd92c865:44075 in memory (size: 8.8 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.799763Z","level":"info","event":"25/12/28 17:44:39 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 19) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.803431Z","level":"info","event":"25/12/28 17:44:39 INFO BlockManagerInfo: Removed broadcast_14_piece0 on c252dd92c865:44075 in memory (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.824104Z","level":"info","event":"25/12/28 17:44:39 INFO Executor: Running task 0.0 in stage 11.0 (TID 19)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.848922Z","level":"info","event":"25/12/28 17:44:39 INFO BlockManagerInfo: Removed broadcast_12_piece0 on c252dd92c865:44075 in memory (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.876819Z","level":"info","event":"25/12/28 17:44:39 INFO BlockManagerInfo: Removed broadcast_13_piece0 on c252dd92c865:44075 in memory (size: 6.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.913790Z","level":"info","event":"25/12/28 17:44:39 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.918029Z","level":"info","event":"25/12/28 17:44:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.946209Z","level":"info","event":"25/12/28 17:44:39 INFO Executor: Finished task 0.0 in stage 11.0 (TID 19). 4038 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.954356Z","level":"info","event":"25/12/28 17:44:39 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 19) in 156 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.958896Z","level":"info","event":"25/12/28 17:44:39 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.965670Z","level":"info","event":"25/12/28 17:44:39 INFO DAGScheduler: ResultStage 11 (count at NativeMethodAccessorImpl.java:0) finished in 0.322 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.965894Z","level":"info","event":"25/12/28 17:44:39 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.965940Z","level":"info","event":"25/12/28 17:44:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.968832Z","level":"info","event":"25/12/28 17:44:39 INFO DAGScheduler: Job 8 finished: count at NativeMethodAccessorImpl.java:0, took 0.338884 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:39.989937Z","level":"info","event":"Loaded olist_order_items with 112650 records for cleaning.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.002335Z","level":"info","event":"root","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.002643Z","level":"info","event":"|-- order_id: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.002800Z","level":"info","event":"|-- order_item_id: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.002942Z","level":"info","event":"|-- product_id: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.003045Z","level":"info","event":"|-- seller_id: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.003146Z","level":"info","event":"|-- shipping_limit_date: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.003561Z","level":"info","event":"|-- price: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.003957Z","level":"info","event":"|-- freight_value: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.004114Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.131101Z","level":"info","event":"25/12/28 17:44:40 INFO InMemoryFileIndex: It took 42 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.173077Z","level":"info","event":"25/12/28 17:44:40 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 2 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.421015Z","level":"info","event":"25/12/28 17:44:40 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.421278Z","level":"info","event":"25/12/28 17:44:40 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#117, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.535856Z","level":"info","event":"25/12/28 17:44:40 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 199.3 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.601818Z","level":"info","event":"25/12/28 17:44:40 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.627303Z","level":"info","event":"25/12/28 17:44:40 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on c252dd92c865:44075 (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.650682Z","level":"info","event":"25/12/28 17:44:40 INFO SparkContext: Created broadcast 18 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.676908Z","level":"info","event":"25/12/28 17:44:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.822034Z","level":"info","event":"25/12/28 17:44:40 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.850771Z","level":"info","event":"25/12/28 17:44:40 INFO DAGScheduler: Got job 9 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.851178Z","level":"info","event":"25/12/28 17:44:40 INFO DAGScheduler: Final stage: ResultStage 12 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.851350Z","level":"info","event":"25/12/28 17:44:40 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.866418Z","level":"info","event":"25/12/28 17:44:40 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.893937Z","level":"info","event":"25/12/28 17:44:40 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[54] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.971650Z","level":"info","event":"25/12/28 17:44:40 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 13.5 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:40.988742Z","level":"info","event":"25/12/28 17:44:40 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:41.008466Z","level":"info","event":"25/12/28 17:44:41 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on c252dd92c865:44075 (size: 6.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:41.021035Z","level":"info","event":"25/12/28 17:44:41 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:41.028085Z","level":"info","event":"25/12/28 17:44:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[54] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:41.028474Z","level":"info","event":"25/12/28 17:44:41 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:41.045938Z","level":"info","event":"25/12/28 17:44:41 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 20) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:41.078051Z","level":"info","event":"25/12/28 17:44:41 INFO Executor: Running task 0.0 in stage 12.0 (TID 20)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:41.242523Z","level":"info","event":"25/12/28 17:44:41 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_order_payments/part-00000-b4069dfd-c683-4904-af70-6ca371afa4a5-c000.csv, range: 0-4100366, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:41.355091Z","level":"info","event":"25/12/28 17:44:41 INFO Executor: Finished task 0.0 in stage 12.0 (TID 20). 1673 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:41.404558Z","level":"info","event":"25/12/28 17:44:41 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 20) in 361 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:41.405622Z","level":"info","event":"25/12/28 17:44:41 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:41.434891Z","level":"info","event":"25/12/28 17:44:41 INFO DAGScheduler: ResultStage 12 (csv at NativeMethodAccessorImpl.java:0) finished in 0.514 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:41.440548Z","level":"info","event":"25/12/28 17:44:41 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:41.448052Z","level":"info","event":"25/12/28 17:44:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:41.448384Z","level":"info","event":"25/12/28 17:44:41 INFO DAGScheduler: Job 9 finished: csv at NativeMethodAccessorImpl.java:0, took 0.619187 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:41.936759Z","level":"info","event":"25/12/28 17:44:41 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:41.943579Z","level":"info","event":"25/12/28 17:44:41 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:42.011138Z","level":"info","event":"25/12/28 17:44:42 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 199.3 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:42.078755Z","level":"info","event":"25/12/28 17:44:42 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:42.104431Z","level":"info","event":"25/12/28 17:44:42 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on c252dd92c865:44075 (size: 34.3 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:42.127164Z","level":"info","event":"25/12/28 17:44:42 INFO SparkContext: Created broadcast 20 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:42.175714Z","level":"info","event":"25/12/28 17:44:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:42.619928Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.152759Z","level":"info","event":"25/12/28 17:44:43 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.177203Z","level":"info","event":"25/12/28 17:44:43 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.440985Z","level":"info","event":"25/12/28 17:44:43 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 199.2 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.487600Z","level":"info","event":"25/12/28 17:44:43 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.498461Z","level":"info","event":"25/12/28 17:44:43 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on c252dd92c865:44075 (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.506994Z","level":"info","event":"25/12/28 17:44:43 INFO SparkContext: Created broadcast 21 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.525595Z","level":"info","event":"25/12/28 17:44:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.587132Z","level":"info","event":"25/12/28 17:44:43 INFO DAGScheduler: Registering RDD 64 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.598957Z","level":"info","event":"25/12/28 17:44:43 INFO DAGScheduler: Got map stage job 10 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.599141Z","level":"info","event":"25/12/28 17:44:43 INFO DAGScheduler: Final stage: ShuffleMapStage 13 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.599258Z","level":"info","event":"25/12/28 17:44:43 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.608531Z","level":"info","event":"25/12/28 17:44:43 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.611746Z","level":"info","event":"25/12/28 17:44:43 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[64] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.643420Z","level":"info","event":"25/12/28 17:44:43 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 17.8 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.656148Z","level":"info","event":"25/12/28 17:44:43 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.659298Z","level":"info","event":"25/12/28 17:44:43 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on c252dd92c865:44075 (size: 8.7 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.668679Z","level":"info","event":"25/12/28 17:44:43 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.669915Z","level":"info","event":"25/12/28 17:44:43 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[64] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.670786Z","level":"info","event":"25/12/28 17:44:43 INFO TaskSchedulerImpl: Adding task set 13.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.686465Z","level":"info","event":"25/12/28 17:44:43 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 21) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8273 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.688480Z","level":"info","event":"25/12/28 17:44:43 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 22) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8273 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.697338Z","level":"info","event":"25/12/28 17:44:43 INFO Executor: Running task 1.0 in stage 13.0 (TID 22)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.702367Z","level":"info","event":"25/12/28 17:44:43 INFO Executor: Running task 0.0 in stage 13.0 (TID 21)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.765409Z","level":"info","event":"25/12/28 17:44:43 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_order_payments/part-00001-b4069dfd-c683-4904-af70-6ca371afa4a5-c000.csv, range: 0-1547490, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:43.768430Z","level":"info","event":"25/12/28 17:44:43 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_order_payments/part-00000-b4069dfd-c683-4904-af70-6ca371afa4a5-c000.csv, range: 0-4100366, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.404239Z","level":"info","event":"25/12/28 17:44:44 INFO Executor: Finished task 1.0 in stage 13.0 (TID 22). 2014 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.481487Z","level":"info","event":"25/12/28 17:44:44 INFO Executor: Finished task 0.0 in stage 13.0 (TID 21). 2014 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.481624Z","level":"info","event":"25/12/28 17:44:44 INFO BlockManagerInfo: Removed broadcast_15_piece0 on c252dd92c865:44075 in memory (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.481999Z","level":"info","event":"25/12/28 17:44:44 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 22) in 757 ms on c252dd92c865 (executor driver) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.482331Z","level":"info","event":"25/12/28 17:44:44 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 21) in 767 ms on c252dd92c865 (executor driver) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.482662Z","level":"info","event":"25/12/28 17:44:44 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.482857Z","level":"info","event":"25/12/28 17:44:44 INFO DAGScheduler: ShuffleMapStage 13 (count at NativeMethodAccessorImpl.java:0) finished in 0.830 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.483844Z","level":"info","event":"25/12/28 17:44:44 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.484362Z","level":"info","event":"25/12/28 17:44:44 INFO BlockManagerInfo: Removed broadcast_18_piece0 on c252dd92c865:44075 in memory (size: 34.3 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.484588Z","level":"info","event":"25/12/28 17:44:44 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.484815Z","level":"info","event":"25/12/28 17:44:44 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.484958Z","level":"info","event":"25/12/28 17:44:44 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.549587Z","level":"info","event":"25/12/28 17:44:44 INFO BlockManagerInfo: Removed broadcast_20_piece0 on c252dd92c865:44075 in memory (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.597794Z","level":"info","event":"25/12/28 17:44:44 INFO BlockManagerInfo: Removed broadcast_17_piece0 on c252dd92c865:44075 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.653812Z","level":"info","event":"25/12/28 17:44:44 INFO BlockManagerInfo: Removed broadcast_19_piece0 on c252dd92c865:44075 in memory (size: 6.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.724025Z","level":"info","event":"25/12/28 17:44:44 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.731418Z","level":"info","event":"25/12/28 17:44:44 INFO DAGScheduler: Got job 11 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.732094Z","level":"info","event":"25/12/28 17:44:44 INFO DAGScheduler: Final stage: ResultStage 15 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.732312Z","level":"info","event":"25/12/28 17:44:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.732678Z","level":"info","event":"25/12/28 17:44:44 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.733696Z","level":"info","event":"25/12/28 17:44:44 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[67] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.743873Z","level":"info","event":"25/12/28 17:44:44 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 12.5 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.751224Z","level":"info","event":"25/12/28 17:44:44 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.753300Z","level":"info","event":"25/12/28 17:44:44 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on c252dd92c865:44075 (size: 6.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.754924Z","level":"info","event":"25/12/28 17:44:44 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.755238Z","level":"info","event":"25/12/28 17:44:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[67] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.755386Z","level":"info","event":"25/12/28 17:44:44 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.766718Z","level":"info","event":"25/12/28 17:44:44 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 23) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.770756Z","level":"info","event":"25/12/28 17:44:44 INFO Executor: Running task 0.0 in stage 15.0 (TID 23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.833333Z","level":"info","event":"25/12/28 17:44:44 INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.835138Z","level":"info","event":"25/12/28 17:44:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.859997Z","level":"info","event":"25/12/28 17:44:44 INFO Executor: Finished task 0.0 in stage 15.0 (TID 23). 4038 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.877334Z","level":"info","event":"25/12/28 17:44:44 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 23) in 105 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.877706Z","level":"info","event":"25/12/28 17:44:44 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.879648Z","level":"info","event":"25/12/28 17:44:44 INFO DAGScheduler: ResultStage 15 (count at NativeMethodAccessorImpl.java:0) finished in 0.143 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.884368Z","level":"info","event":"25/12/28 17:44:44 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.884684Z","level":"info","event":"25/12/28 17:44:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.891208Z","level":"info","event":"25/12/28 17:44:44 INFO DAGScheduler: Job 11 finished: count at NativeMethodAccessorImpl.java:0, took 0.162422 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.919578Z","level":"info","event":"Loaded olist_order_payments with 103886 records for cleaning.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.945605Z","level":"info","event":"root","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.945843Z","level":"info","event":"|-- order_id: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.945902Z","level":"info","event":"|-- payment_sequential: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.945949Z","level":"info","event":"|-- payment_type: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.945979Z","level":"info","event":"|-- payment_installments: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.946020Z","level":"info","event":"|-- payment_value: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:44.946129Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:45.043350Z","level":"info","event":"25/12/28 17:44:45 INFO InMemoryFileIndex: It took 36 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:45.085500Z","level":"info","event":"25/12/28 17:44:45 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 4 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:46.272486Z","level":"info","event":"25/12/28 17:44:46 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:46.284422Z","level":"info","event":"25/12/28 17:44:46 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#154, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:46.440635Z","level":"info","event":"25/12/28 17:44:46 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 199.3 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:46.499784Z","level":"info","event":"25/12/28 17:44:46 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:46.506525Z","level":"info","event":"25/12/28 17:44:46 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on c252dd92c865:44075 (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:46.517150Z","level":"info","event":"25/12/28 17:44:46 INFO SparkContext: Created broadcast 24 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:46.538432Z","level":"info","event":"25/12/28 17:44:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4393510 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:46.632645Z","level":"info","event":"25/12/28 17:44:46 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:46.655389Z","level":"info","event":"25/12/28 17:44:46 INFO DAGScheduler: Got job 12 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:46.656355Z","level":"info","event":"25/12/28 17:44:46 INFO DAGScheduler: Final stage: ResultStage 16 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:46.657615Z","level":"info","event":"25/12/28 17:44:46 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:46.663140Z","level":"info","event":"25/12/28 17:44:46 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:46.670431Z","level":"info","event":"25/12/28 17:44:46 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[71] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:46.693959Z","level":"info","event":"25/12/28 17:44:46 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 13.5 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:46.710051Z","level":"info","event":"25/12/28 17:44:46 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:46.711054Z","level":"info","event":"25/12/28 17:44:46 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on c252dd92c865:44075 (size: 6.4 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:46.717978Z","level":"info","event":"25/12/28 17:44:46 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:46.723478Z","level":"info","event":"25/12/28 17:44:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[71] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:46.730429Z","level":"info","event":"25/12/28 17:44:46 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:46.764482Z","level":"info","event":"25/12/28 17:44:46 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 24) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8283 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:46.777419Z","level":"info","event":"25/12/28 17:44:46 INFO Executor: Running task 0.0 in stage 16.0 (TID 24)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:46.941356Z","level":"info","event":"25/12/28 17:44:46 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_order_reviews/part-00000-dd17a1ca-61b1-48d7-b6b5-b8af37674063-c000.csv, range: 0-4057043, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:47.027378Z","level":"info","event":"25/12/28 17:44:47 INFO Executor: Finished task 0.0 in stage 16.0 (TID 24). 1696 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:47.043088Z","level":"info","event":"25/12/28 17:44:47 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 24) in 280 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:47.045467Z","level":"info","event":"25/12/28 17:44:47 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:47.055296Z","level":"info","event":"25/12/28 17:44:47 INFO DAGScheduler: ResultStage 16 (csv at NativeMethodAccessorImpl.java:0) finished in 0.374 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:47.055558Z","level":"info","event":"25/12/28 17:44:47 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:47.057757Z","level":"info","event":"25/12/28 17:44:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:47.060735Z","level":"info","event":"25/12/28 17:44:47 INFO DAGScheduler: Job 12 finished: csv at NativeMethodAccessorImpl.java:0, took 0.428901 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:47.214862Z","level":"info","event":"25/12/28 17:44:47 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:47.216140Z","level":"info","event":"25/12/28 17:44:47 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:47.234210Z","level":"info","event":"25/12/28 17:44:47 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 199.3 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:47.257796Z","level":"info","event":"25/12/28 17:44:47 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:47.259647Z","level":"info","event":"25/12/28 17:44:47 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on c252dd92c865:44075 (size: 34.3 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:47.266544Z","level":"info","event":"25/12/28 17:44:47 INFO SparkContext: Created broadcast 26 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:47.270158Z","level":"info","event":"25/12/28 17:44:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4393510 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:47.402578Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:47.523516Z","level":"info","event":"25/12/28 17:44:47 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:47.526559Z","level":"info","event":"25/12/28 17:44:47 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:47.810280Z","level":"info","event":"25/12/28 17:44:47 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 199.2 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:47.906400Z","level":"info","event":"25/12/28 17:44:47 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:47.924893Z","level":"info","event":"25/12/28 17:44:47 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on c252dd92c865:44075 (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:47.940211Z","level":"info","event":"25/12/28 17:44:47 INFO SparkContext: Created broadcast 27 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:47.983980Z","level":"info","event":"25/12/28 17:44:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4393510 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.064274Z","level":"info","event":"25/12/28 17:44:48 INFO DAGScheduler: Registering RDD 81 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.066378Z","level":"info","event":"25/12/28 17:44:48 INFO DAGScheduler: Got map stage job 13 (count at NativeMethodAccessorImpl.java:0) with 4 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.066625Z","level":"info","event":"25/12/28 17:44:48 INFO DAGScheduler: Final stage: ShuffleMapStage 17 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.066794Z","level":"info","event":"25/12/28 17:44:48 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.067880Z","level":"info","event":"25/12/28 17:44:48 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.070049Z","level":"info","event":"25/12/28 17:44:48 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[81] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.093707Z","level":"info","event":"25/12/28 17:44:48 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 17.9 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.202365Z","level":"info","event":"25/12/28 17:44:48 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.208170Z","level":"info","event":"25/12/28 17:44:48 INFO BlockManagerInfo: Removed broadcast_21_piece0 on c252dd92c865:44075 in memory (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.211710Z","level":"info","event":"25/12/28 17:44:48 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on c252dd92c865:44075 (size: 8.8 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.211953Z","level":"info","event":"25/12/28 17:44:48 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.213702Z","level":"info","event":"25/12/28 17:44:48 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[81] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.214200Z","level":"info","event":"25/12/28 17:44:48 INFO TaskSchedulerImpl: Adding task set 17.0 with 4 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.229429Z","level":"info","event":"25/12/28 17:44:48 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 25) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8272 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.232745Z","level":"info","event":"25/12/28 17:44:48 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 26) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8272 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.233196Z","level":"info","event":"25/12/28 17:44:48 INFO BlockManagerInfo: Removed broadcast_25_piece0 on c252dd92c865:44075 in memory (size: 6.4 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.237536Z","level":"info","event":"25/12/28 17:44:48 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 27) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8272 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.241026Z","level":"info","event":"25/12/28 17:44:48 INFO TaskSetManager: Starting task 3.0 in stage 17.0 (TID 28) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8272 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.249953Z","level":"info","event":"25/12/28 17:44:48 INFO Executor: Running task 1.0 in stage 17.0 (TID 26)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.255204Z","level":"info","event":"25/12/28 17:44:48 INFO Executor: Running task 0.0 in stage 17.0 (TID 25)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.258981Z","level":"info","event":"25/12/28 17:44:48 INFO Executor: Running task 3.0 in stage 17.0 (TID 28)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.274509Z","level":"info","event":"25/12/28 17:44:48 INFO Executor: Running task 2.0 in stage 17.0 (TID 27)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.340620Z","level":"info","event":"25/12/28 17:44:48 INFO BlockManagerInfo: Removed broadcast_23_piece0 on c252dd92c865:44075 in memory (size: 6.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.374057Z","level":"info","event":"25/12/28 17:44:48 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_order_reviews/part-00002-dd17a1ca-61b1-48d7-b6b5-b8af37674063-c000.csv, range: 0-4056208, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.385590Z","level":"info","event":"25/12/28 17:44:48 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_order_reviews/part-00001-dd17a1ca-61b1-48d7-b6b5-b8af37674063-c000.csv, range: 0-4056785, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.386191Z","level":"info","event":"25/12/28 17:44:48 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_order_reviews/part-00000-dd17a1ca-61b1-48d7-b6b5-b8af37674063-c000.csv, range: 0-4057043, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.391330Z","level":"info","event":"25/12/28 17:44:48 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_order_reviews/part-00003-dd17a1ca-61b1-48d7-b6b5-b8af37674063-c000.csv, range: 0-1807323, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.430874Z","level":"info","event":"25/12/28 17:44:48 INFO BlockManagerInfo: Removed broadcast_26_piece0 on c252dd92c865:44075 in memory (size: 34.3 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.541666Z","level":"info","event":"25/12/28 17:44:48 INFO BlockManagerInfo: Removed broadcast_22_piece0 on c252dd92c865:44075 in memory (size: 8.7 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.649874Z","level":"info","event":"25/12/28 17:44:48 INFO BlockManagerInfo: Removed broadcast_24_piece0 on c252dd92c865:44075 in memory (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.882776Z","level":"info","event":"25/12/28 17:44:48 INFO Executor: Finished task 2.0 in stage 17.0 (TID 27). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.885125Z","level":"info","event":"25/12/28 17:44:48 INFO Executor: Finished task 3.0 in stage 17.0 (TID 28). 1928 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.915529Z","level":"info","event":"25/12/28 17:44:48 INFO TaskSetManager: Finished task 3.0 in stage 17.0 (TID 28) in 666 ms on c252dd92c865 (executor driver) (1/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.916132Z","level":"info","event":"25/12/28 17:44:48 INFO Executor: Finished task 1.0 in stage 17.0 (TID 26). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.916236Z","level":"info","event":"25/12/28 17:44:48 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 27) in 672 ms on c252dd92c865 (executor driver) (2/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.916282Z","level":"info","event":"25/12/28 17:44:48 INFO Executor: Finished task 0.0 in stage 17.0 (TID 25). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.916314Z","level":"info","event":"25/12/28 17:44:48 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 26) in 681 ms on c252dd92c865 (executor driver) (3/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.916342Z","level":"info","event":"25/12/28 17:44:48 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 25) in 688 ms on c252dd92c865 (executor driver) (4/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.916563Z","level":"info","event":"25/12/28 17:44:48 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.942264Z","level":"info","event":"25/12/28 17:44:48 INFO DAGScheduler: ShuffleMapStage 17 (count at NativeMethodAccessorImpl.java:0) finished in 0.861 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.943503Z","level":"info","event":"25/12/28 17:44:48 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.943593Z","level":"info","event":"25/12/28 17:44:48 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.943638Z","level":"info","event":"25/12/28 17:44:48 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:48.943673Z","level":"info","event":"25/12/28 17:44:48 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.086433Z","level":"info","event":"25/12/28 17:44:49 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.091616Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: Got job 14 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.091976Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: Final stage: ResultStage 19 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.092096Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.092539Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.095629Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[84] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.103791Z","level":"info","event":"25/12/28 17:44:49 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 12.5 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.112943Z","level":"info","event":"25/12/28 17:44:49 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.114238Z","level":"info","event":"25/12/28 17:44:49 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on c252dd92c865:44075 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.120745Z","level":"info","event":"25/12/28 17:44:49 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.121068Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[84] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.121233Z","level":"info","event":"25/12/28 17:44:49 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.122254Z","level":"info","event":"25/12/28 17:44:49 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 29) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.128241Z","level":"info","event":"25/12/28 17:44:49 INFO Executor: Running task 0.0 in stage 19.0 (TID 29)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.172784Z","level":"info","event":"25/12/28 17:44:49 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.173131Z","level":"info","event":"25/12/28 17:44:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.179494Z","level":"info","event":"25/12/28 17:44:49 INFO Executor: Finished task 0.0 in stage 19.0 (TID 29). 3995 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.181335Z","level":"info","event":"25/12/28 17:44:49 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 29) in 61 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.181689Z","level":"info","event":"25/12/28 17:44:49 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.184553Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: ResultStage 19 (count at NativeMethodAccessorImpl.java:0) finished in 0.085 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.184748Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.184829Z","level":"info","event":"25/12/28 17:44:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.185876Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: Job 14 finished: count at NativeMethodAccessorImpl.java:0, took 0.098747 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.190139Z","level":"info","event":"Loaded olist_order_reviews with 104162 records for cleaning.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.192620Z","level":"info","event":"root","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.192842Z","level":"info","event":"|-- review_id: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.192929Z","level":"info","event":"|-- order_id: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.193022Z","level":"info","event":"|-- review_score: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.193114Z","level":"info","event":"|-- review_comment_title: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.193230Z","level":"info","event":"|-- review_comment_message: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.193318Z","level":"info","event":"|-- review_creation_date: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.193404Z","level":"info","event":"|-- review_answer_timestamp: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.195718Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.268345Z","level":"info","event":"25/12/28 17:44:49 INFO InMemoryFileIndex: It took 17 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.294429Z","level":"info","event":"25/12/28 17:44:49 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 5 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.459685Z","level":"info","event":"25/12/28 17:44:49 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.461505Z","level":"info","event":"25/12/28 17:44:49 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#197, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.492807Z","level":"info","event":"25/12/28 17:44:49 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 199.3 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.501623Z","level":"info","event":"25/12/28 17:44:49 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.504143Z","level":"info","event":"25/12/28 17:44:49 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on c252dd92c865:44075 (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.506424Z","level":"info","event":"25/12/28 17:44:49 INFO SparkContext: Created broadcast 30 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.509624Z","level":"info","event":"25/12/28 17:44:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 5482724 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.521306Z","level":"info","event":"25/12/28 17:44:49 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.523122Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: Got job 15 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.523355Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: Final stage: ResultStage 20 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.523518Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.523644Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.524405Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[88] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.529408Z","level":"info","event":"25/12/28 17:44:49 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 13.5 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.534313Z","level":"info","event":"25/12/28 17:44:49 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.536130Z","level":"info","event":"25/12/28 17:44:49 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on c252dd92c865:44075 (size: 6.4 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.539514Z","level":"info","event":"25/12/28 17:44:49 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.539625Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[88] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.539670Z","level":"info","event":"25/12/28 17:44:49 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.542170Z","level":"info","event":"25/12/28 17:44:49 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 30) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8276 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.544688Z","level":"info","event":"25/12/28 17:44:49 INFO Executor: Running task 0.0 in stage 20.0 (TID 30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.550385Z","level":"info","event":"25/12/28 17:44:49 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_orders/part-00002-3020d36e-0bc3-4785-9ade-51814a7fe870-c000.csv, range: 0-4135779, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.597144Z","level":"info","event":"25/12/28 17:44:49 INFO Executor: Finished task 0.0 in stage 20.0 (TID 30). 1772 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.600246Z","level":"info","event":"25/12/28 17:44:49 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 30) in 58 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.600435Z","level":"info","event":"25/12/28 17:44:49 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.603430Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: ResultStage 20 (csv at NativeMethodAccessorImpl.java:0) finished in 0.077 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.604368Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.604512Z","level":"info","event":"25/12/28 17:44:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.604578Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: Job 15 finished: csv at NativeMethodAccessorImpl.java:0, took 0.080813 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.613729Z","level":"info","event":"25/12/28 17:44:49 INFO BlockManagerInfo: Removed broadcast_27_piece0 on c252dd92c865:44075 in memory (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.620925Z","level":"info","event":"25/12/28 17:44:49 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.621279Z","level":"info","event":"25/12/28 17:44:49 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.623205Z","level":"info","event":"25/12/28 17:44:49 INFO BlockManagerInfo: Removed broadcast_28_piece0 on c252dd92c865:44075 in memory (size: 8.8 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.633849Z","level":"info","event":"25/12/28 17:44:49 INFO BlockManagerInfo: Removed broadcast_29_piece0 on c252dd92c865:44075 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.650025Z","level":"info","event":"25/12/28 17:44:49 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 199.3 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.674402Z","level":"info","event":"25/12/28 17:44:49 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.676179Z","level":"info","event":"25/12/28 17:44:49 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on c252dd92c865:44075 (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.681516Z","level":"info","event":"25/12/28 17:44:49 INFO SparkContext: Created broadcast 32 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.686769Z","level":"info","event":"25/12/28 17:44:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 5482724 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.739354Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.801531Z","level":"info","event":"25/12/28 17:44:49 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.801902Z","level":"info","event":"25/12/28 17:44:49 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.855623Z","level":"info","event":"25/12/28 17:44:49 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 199.2 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.885849Z","level":"info","event":"25/12/28 17:44:49 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.893530Z","level":"info","event":"25/12/28 17:44:49 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on c252dd92c865:44075 (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.896716Z","level":"info","event":"25/12/28 17:44:49 INFO SparkContext: Created broadcast 33 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.910252Z","level":"info","event":"25/12/28 17:44:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 5482724 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.936911Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: Registering RDD 98 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 5","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.938701Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: Got map stage job 16 (count at NativeMethodAccessorImpl.java:0) with 5 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.940747Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: Final stage: ShuffleMapStage 21 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.941039Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.941264Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.947695Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[98] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.955244Z","level":"info","event":"25/12/28 17:44:49 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 17.9 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.961681Z","level":"info","event":"25/12/28 17:44:49 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.963570Z","level":"info","event":"25/12/28 17:44:49 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on c252dd92c865:44075 (size: 8.8 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.965932Z","level":"info","event":"25/12/28 17:44:49 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.966211Z","level":"info","event":"25/12/28 17:44:49 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[98] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.966354Z","level":"info","event":"25/12/28 17:44:49 INFO TaskSchedulerImpl: Adding task set 21.0 with 5 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.969492Z","level":"info","event":"25/12/28 17:44:49 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 31) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8265 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.969732Z","level":"info","event":"25/12/28 17:44:49 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 32) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8265 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.970912Z","level":"info","event":"25/12/28 17:44:49 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 33) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8265 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.971830Z","level":"info","event":"25/12/28 17:44:49 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 34) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8265 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.971892Z","level":"info","event":"25/12/28 17:44:49 INFO TaskSetManager: Starting task 4.0 in stage 21.0 (TID 35) (c252dd92c865, executor driver, partition 4, PROCESS_LOCAL, 8265 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.971949Z","level":"info","event":"25/12/28 17:44:49 INFO Executor: Running task 2.0 in stage 21.0 (TID 33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.971997Z","level":"info","event":"25/12/28 17:44:49 INFO Executor: Running task 4.0 in stage 21.0 (TID 35)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.972282Z","level":"info","event":"25/12/28 17:44:49 INFO Executor: Running task 1.0 in stage 21.0 (TID 32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.973159Z","level":"info","event":"25/12/28 17:44:49 INFO Executor: Running task 3.0 in stage 21.0 (TID 34)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.979560Z","level":"info","event":"25/12/28 17:44:49 INFO Executor: Running task 0.0 in stage 21.0 (TID 31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.988516Z","level":"info","event":"25/12/28 17:44:49 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_orders/part-00001-3020d36e-0bc3-4785-9ade-51814a7fe870-c000.csv, range: 0-4135308, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.990257Z","level":"info","event":"25/12/28 17:44:49 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_orders/part-00003-3020d36e-0bc3-4785-9ade-51814a7fe870-c000.csv, range: 0-4135725, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.996805Z","level":"info","event":"25/12/28 17:44:49 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_orders/part-00000-3020d36e-0bc3-4785-9ade-51814a7fe870-c000.csv, range: 0-4135273, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:49.997024Z","level":"info","event":"25/12/28 17:44:49 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_orders/part-00002-3020d36e-0bc3-4785-9ade-51814a7fe870-c000.csv, range: 0-4135779, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.002105Z","level":"info","event":"25/12/28 17:44:50 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_orders/part-00004-3020d36e-0bc3-4785-9ade-51814a7fe870-c000.csv, range: 0-865463, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.169994Z","level":"info","event":"25/12/28 17:44:50 INFO Executor: Finished task 4.0 in stage 21.0 (TID 35). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.172391Z","level":"info","event":"25/12/28 17:44:50 INFO Executor: Finished task 2.0 in stage 21.0 (TID 33). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.183622Z","level":"info","event":"25/12/28 17:44:50 INFO TaskSetManager: Finished task 4.0 in stage 21.0 (TID 35) in 209 ms on c252dd92c865 (executor driver) (1/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.187589Z","level":"info","event":"25/12/28 17:44:50 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 33) in 217 ms on c252dd92c865 (executor driver) (2/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.195309Z","level":"info","event":"25/12/28 17:44:50 INFO Executor: Finished task 0.0 in stage 21.0 (TID 31). 1928 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.195567Z","level":"info","event":"25/12/28 17:44:50 INFO Executor: Finished task 3.0 in stage 21.0 (TID 34). 1928 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.198183Z","level":"info","event":"25/12/28 17:44:50 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 31) in 229 ms on c252dd92c865 (executor driver) (3/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.198821Z","level":"info","event":"25/12/28 17:44:50 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 34) in 229 ms on c252dd92c865 (executor driver) (4/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.221290Z","level":"info","event":"25/12/28 17:44:50 INFO Executor: Finished task 1.0 in stage 21.0 (TID 32). 1928 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.221980Z","level":"info","event":"25/12/28 17:44:50 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 32) in 252 ms on c252dd92c865 (executor driver) (5/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.222221Z","level":"info","event":"25/12/28 17:44:50 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.224268Z","level":"info","event":"25/12/28 17:44:50 INFO DAGScheduler: ShuffleMapStage 21 (count at NativeMethodAccessorImpl.java:0) finished in 0.274 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.224639Z","level":"info","event":"25/12/28 17:44:50 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.224788Z","level":"info","event":"25/12/28 17:44:50 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.224874Z","level":"info","event":"25/12/28 17:44:50 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.224959Z","level":"info","event":"25/12/28 17:44:50 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.326890Z","level":"info","event":"25/12/28 17:44:50 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.333537Z","level":"info","event":"25/12/28 17:44:50 INFO DAGScheduler: Got job 17 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.333680Z","level":"info","event":"25/12/28 17:44:50 INFO DAGScheduler: Final stage: ResultStage 23 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.333726Z","level":"info","event":"25/12/28 17:44:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.334036Z","level":"info","event":"25/12/28 17:44:50 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.334173Z","level":"info","event":"25/12/28 17:44:50 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[101] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.339507Z","level":"info","event":"25/12/28 17:44:50 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 12.5 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.401897Z","level":"info","event":"25/12/28 17:44:50 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.404690Z","level":"info","event":"25/12/28 17:44:50 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on c252dd92c865:44075 (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.406519Z","level":"info","event":"25/12/28 17:44:50 INFO BlockManagerInfo: Removed broadcast_34_piece0 on c252dd92c865:44075 in memory (size: 8.8 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.406644Z","level":"info","event":"25/12/28 17:44:50 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.407972Z","level":"info","event":"25/12/28 17:44:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[101] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.408519Z","level":"info","event":"25/12/28 17:44:50 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.415517Z","level":"info","event":"25/12/28 17:44:50 INFO BlockManagerInfo: Removed broadcast_32_piece0 on c252dd92c865:44075 in memory (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.415972Z","level":"info","event":"25/12/28 17:44:50 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 36) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.420393Z","level":"info","event":"25/12/28 17:44:50 INFO Executor: Running task 0.0 in stage 23.0 (TID 36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.420987Z","level":"info","event":"25/12/28 17:44:50 INFO BlockManagerInfo: Removed broadcast_30_piece0 on c252dd92c865:44075 in memory (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.430508Z","level":"info","event":"25/12/28 17:44:50 INFO BlockManagerInfo: Removed broadcast_31_piece0 on c252dd92c865:44075 in memory (size: 6.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.433938Z","level":"info","event":"25/12/28 17:44:50 INFO ShuffleBlockFetcherIterator: Getting 5 (300.0 B) non-empty blocks including 5 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.434559Z","level":"info","event":"25/12/28 17:44:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.446776Z","level":"info","event":"25/12/28 17:44:50 INFO Executor: Finished task 0.0 in stage 23.0 (TID 36). 3995 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.449119Z","level":"info","event":"25/12/28 17:44:50 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 36) in 35 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.449357Z","level":"info","event":"25/12/28 17:44:50 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.456346Z","level":"info","event":"25/12/28 17:44:50 INFO DAGScheduler: ResultStage 23 (count at NativeMethodAccessorImpl.java:0) finished in 0.119 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.456930Z","level":"info","event":"25/12/28 17:44:50 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.457004Z","level":"info","event":"25/12/28 17:44:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.457043Z","level":"info","event":"25/12/28 17:44:50 INFO DAGScheduler: Job 17 finished: count at NativeMethodAccessorImpl.java:0, took 0.130252 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.464730Z","level":"info","event":"Loaded olist_orders with 99441 records for cleaning.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.469944Z","level":"info","event":"root","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.470168Z","level":"info","event":"|-- order_id: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.471495Z","level":"info","event":"|-- customer_id: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.471928Z","level":"info","event":"|-- order_status: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.472008Z","level":"info","event":"|-- order_purchase_timestamp: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.472090Z","level":"info","event":"|-- order_approved_at: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.472261Z","level":"info","event":"|-- order_delivered_carrier_date: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.472332Z","level":"info","event":"|-- order_delivered_customer_date: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.472412Z","level":"info","event":"|-- order_estimated_delivery_date: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.475370Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.529180Z","level":"info","event":"25/12/28 17:44:50 INFO InMemoryFileIndex: It took 14 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:50.550466Z","level":"info","event":"25/12/28 17:44:50 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:51.390666Z","level":"info","event":"25/12/28 17:44:51 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:51.397025Z","level":"info","event":"25/12/28 17:44:51 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#243, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:51.628546Z","level":"info","event":"25/12/28 17:44:51 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 199.3 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:51.681278Z","level":"info","event":"25/12/28 17:44:51 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:51.694836Z","level":"info","event":"25/12/28 17:44:51 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on c252dd92c865:44075 (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:51.724048Z","level":"info","event":"25/12/28 17:44:51 INFO SparkContext: Created broadcast 36 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:51.751645Z","level":"info","event":"25/12/28 17:44:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:51.803957Z","level":"info","event":"25/12/28 17:44:51 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:51.826056Z","level":"info","event":"25/12/28 17:44:51 INFO DAGScheduler: Got job 18 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:51.826705Z","level":"info","event":"25/12/28 17:44:51 INFO DAGScheduler: Final stage: ResultStage 24 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:51.826879Z","level":"info","event":"25/12/28 17:44:51 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:51.828203Z","level":"info","event":"25/12/28 17:44:51 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:51.829833Z","level":"info","event":"25/12/28 17:44:51 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[105] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:51.848174Z","level":"info","event":"25/12/28 17:44:51 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 13.5 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:51.864402Z","level":"info","event":"25/12/28 17:44:51 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:51.866574Z","level":"info","event":"25/12/28 17:44:51 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on c252dd92c865:44075 (size: 6.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:51.870110Z","level":"info","event":"25/12/28 17:44:51 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:51.872907Z","level":"info","event":"25/12/28 17:44:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[105] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:51.875526Z","level":"info","event":"25/12/28 17:44:51 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:51.886638Z","level":"info","event":"25/12/28 17:44:51 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 37) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8278 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:51.896948Z","level":"info","event":"25/12/28 17:44:51 INFO Executor: Running task 0.0 in stage 24.0 (TID 37)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:51.966927Z","level":"info","event":"25/12/28 17:44:51 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_products/part-00000-b797a264-a23d-4718-af9b-288e54c32325-c000.csv, range: 0-2338292, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:52.042467Z","level":"info","event":"25/12/28 17:44:52 INFO Executor: Finished task 0.0 in stage 24.0 (TID 37). 1676 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:52.054787Z","level":"info","event":"25/12/28 17:44:52 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 37) in 172 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:52.055006Z","level":"info","event":"25/12/28 17:44:52 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:52.062681Z","level":"info","event":"25/12/28 17:44:52 INFO DAGScheduler: ResultStage 24 (csv at NativeMethodAccessorImpl.java:0) finished in 0.224 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:52.063790Z","level":"info","event":"25/12/28 17:44:52 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:52.067283Z","level":"info","event":"25/12/28 17:44:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:52.072339Z","level":"info","event":"25/12/28 17:44:52 INFO DAGScheduler: Job 18 finished: csv at NativeMethodAccessorImpl.java:0, took 0.266908 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:52.281349Z","level":"info","event":"25/12/28 17:44:52 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:52.293688Z","level":"info","event":"25/12/28 17:44:52 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:52.334878Z","level":"info","event":"25/12/28 17:44:52 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 199.3 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:52.374713Z","level":"info","event":"25/12/28 17:44:52 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:52.382760Z","level":"info","event":"25/12/28 17:44:52 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on c252dd92c865:44075 (size: 34.3 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:52.396793Z","level":"info","event":"25/12/28 17:44:52 INFO SparkContext: Created broadcast 38 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:52.408692Z","level":"info","event":"25/12/28 17:44:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:52.596496Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:52.851961Z","level":"info","event":"25/12/28 17:44:52 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:52.878839Z","level":"info","event":"25/12/28 17:44:52 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.080646Z","level":"info","event":"25/12/28 17:44:53 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 199.2 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.112712Z","level":"info","event":"25/12/28 17:44:53 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.115809Z","level":"info","event":"25/12/28 17:44:53 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on c252dd92c865:44075 (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.123520Z","level":"info","event":"25/12/28 17:44:53 INFO SparkContext: Created broadcast 39 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.154960Z","level":"info","event":"25/12/28 17:44:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.185649Z","level":"info","event":"25/12/28 17:44:53 INFO DAGScheduler: Registering RDD 115 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 6","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.196423Z","level":"info","event":"25/12/28 17:44:53 INFO DAGScheduler: Got map stage job 19 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.200549Z","level":"info","event":"25/12/28 17:44:53 INFO DAGScheduler: Final stage: ShuffleMapStage 25 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.200709Z","level":"info","event":"25/12/28 17:44:53 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.201438Z","level":"info","event":"25/12/28 17:44:53 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.215372Z","level":"info","event":"25/12/28 17:44:53 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[115] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.234132Z","level":"info","event":"25/12/28 17:44:53 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 18.0 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.245523Z","level":"info","event":"25/12/28 17:44:53 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.245683Z","level":"info","event":"25/12/28 17:44:53 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on c252dd92c865:44075 (size: 8.8 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.248631Z","level":"info","event":"25/12/28 17:44:53 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.248798Z","level":"info","event":"25/12/28 17:44:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[115] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.248860Z","level":"info","event":"25/12/28 17:44:53 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.283521Z","level":"info","event":"25/12/28 17:44:53 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 38) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8267 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.316663Z","level":"info","event":"25/12/28 17:44:53 INFO Executor: Running task 0.0 in stage 25.0 (TID 38)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.426942Z","level":"info","event":"25/12/28 17:44:53 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_products/part-00000-b797a264-a23d-4718-af9b-288e54c32325-c000.csv, range: 0-2338292, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.521509Z","level":"info","event":"25/12/28 17:44:53 INFO Executor: Finished task 0.0 in stage 25.0 (TID 38). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.529587Z","level":"info","event":"25/12/28 17:44:53 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 38) in 266 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.529942Z","level":"info","event":"25/12/28 17:44:53 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.547537Z","level":"info","event":"25/12/28 17:44:53 INFO DAGScheduler: ShuffleMapStage 25 (count at NativeMethodAccessorImpl.java:0) finished in 0.325 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.547832Z","level":"info","event":"25/12/28 17:44:53 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.548123Z","level":"info","event":"25/12/28 17:44:53 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.548197Z","level":"info","event":"25/12/28 17:44:53 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.548237Z","level":"info","event":"25/12/28 17:44:53 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.680856Z","level":"info","event":"25/12/28 17:44:53 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.696938Z","level":"info","event":"25/12/28 17:44:53 INFO DAGScheduler: Got job 20 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.697621Z","level":"info","event":"25/12/28 17:44:53 INFO DAGScheduler: Final stage: ResultStage 27 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.697718Z","level":"info","event":"25/12/28 17:44:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.698180Z","level":"info","event":"25/12/28 17:44:53 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.706592Z","level":"info","event":"25/12/28 17:44:53 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[118] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.714544Z","level":"info","event":"25/12/28 17:44:53 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 12.5 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.787973Z","level":"info","event":"25/12/28 17:44:53 INFO BlockManagerInfo: Removed broadcast_35_piece0 on c252dd92c865:44075 in memory (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.790002Z","level":"info","event":"25/12/28 17:44:53 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.790067Z","level":"info","event":"25/12/28 17:44:53 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on c252dd92c865:44075 (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.792508Z","level":"info","event":"25/12/28 17:44:53 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.793000Z","level":"info","event":"25/12/28 17:44:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[118] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.793172Z","level":"info","event":"25/12/28 17:44:53 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.805826Z","level":"info","event":"25/12/28 17:44:53 INFO BlockManagerInfo: Removed broadcast_33_piece0 on c252dd92c865:44075 in memory (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.806335Z","level":"info","event":"25/12/28 17:44:53 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 39) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.818272Z","level":"info","event":"25/12/28 17:44:53 INFO Executor: Running task 0.0 in stage 27.0 (TID 39)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.819875Z","level":"info","event":"25/12/28 17:44:53 INFO BlockManagerInfo: Removed broadcast_36_piece0 on c252dd92c865:44075 in memory (size: 34.3 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.825313Z","level":"info","event":"25/12/28 17:44:53 INFO BlockManagerInfo: Removed broadcast_38_piece0 on c252dd92c865:44075 in memory (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.836616Z","level":"info","event":"25/12/28 17:44:53 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.836752Z","level":"info","event":"25/12/28 17:44:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.838728Z","level":"info","event":"25/12/28 17:44:53 INFO BlockManagerInfo: Removed broadcast_40_piece0 on c252dd92c865:44075 in memory (size: 8.8 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.841884Z","level":"info","event":"25/12/28 17:44:53 INFO Executor: Finished task 0.0 in stage 27.0 (TID 39). 3995 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.849940Z","level":"info","event":"25/12/28 17:44:53 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 39) in 43 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.850228Z","level":"info","event":"25/12/28 17:44:53 INFO DAGScheduler: ResultStage 27 (count at NativeMethodAccessorImpl.java:0) finished in 0.138 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.850396Z","level":"info","event":"25/12/28 17:44:53 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.851846Z","level":"info","event":"25/12/28 17:44:53 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.852040Z","level":"info","event":"25/12/28 17:44:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.854159Z","level":"info","event":"25/12/28 17:44:53 INFO BlockManagerInfo: Removed broadcast_37_piece0 on c252dd92c865:44075 in memory (size: 6.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.854381Z","level":"info","event":"25/12/28 17:44:53 INFO DAGScheduler: Job 20 finished: count at NativeMethodAccessorImpl.java:0, took 0.172134 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.875962Z","level":"info","event":"Loaded olist_products with 32951 records for cleaning.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.900305Z","level":"info","event":"root","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.900421Z","level":"info","event":"|-- product_id: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.900458Z","level":"info","event":"|-- product_category_name: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.900479Z","level":"info","event":"|-- product_name_lenght: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.900495Z","level":"info","event":"|-- product_description_lenght: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.900510Z","level":"info","event":"|-- product_photos_qty: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.900535Z","level":"info","event":"|-- product_weight_g: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.900552Z","level":"info","event":"|-- product_length_cm: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.900566Z","level":"info","event":"|-- product_height_cm: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.900597Z","level":"info","event":"|-- product_width_cm: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.900669Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.948951Z","level":"info","event":"25/12/28 17:44:53 INFO InMemoryFileIndex: It took 10 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:53.968559Z","level":"info","event":"25/12/28 17:44:53 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.161626Z","level":"info","event":"25/12/28 17:44:54 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.162043Z","level":"info","event":"25/12/28 17:44:54 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#292, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.190017Z","level":"info","event":"25/12/28 17:44:54 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 199.3 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.206873Z","level":"info","event":"25/12/28 17:44:54 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.208192Z","level":"info","event":"25/12/28 17:44:54 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on c252dd92c865:44075 (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.209486Z","level":"info","event":"25/12/28 17:44:54 INFO SparkContext: Created broadcast 42 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.213321Z","level":"info","event":"25/12/28 17:44:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.237491Z","level":"info","event":"25/12/28 17:44:54 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.241638Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: Got job 21 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.242080Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: Final stage: ResultStage 28 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.242332Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.246790Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.248342Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[122] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.254809Z","level":"info","event":"25/12/28 17:44:54 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 13.5 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.260391Z","level":"info","event":"25/12/28 17:44:54 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.261636Z","level":"info","event":"25/12/28 17:44:54 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on c252dd92c865:44075 (size: 6.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.263276Z","level":"info","event":"25/12/28 17:44:54 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.264283Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[122] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.264509Z","level":"info","event":"25/12/28 17:44:54 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.266726Z","level":"info","event":"25/12/28 17:44:54 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 40) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.268910Z","level":"info","event":"25/12/28 17:44:54 INFO Executor: Running task 0.0 in stage 28.0 (TID 40)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.282410Z","level":"info","event":"25/12/28 17:44:54 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_sellers/part-00000-68fcedb9-9280-417c-81e1-f0a43de0c8c4-c000.csv, range: 0-164617, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.294557Z","level":"info","event":"25/12/28 17:44:54 INFO Executor: Finished task 0.0 in stage 28.0 (TID 40). 1664 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.296551Z","level":"info","event":"25/12/28 17:44:54 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 40) in 30 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.296981Z","level":"info","event":"25/12/28 17:44:54 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.297748Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: ResultStage 28 (csv at NativeMethodAccessorImpl.java:0) finished in 0.046 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.298469Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.298605Z","level":"info","event":"25/12/28 17:44:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.299474Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: Job 21 finished: csv at NativeMethodAccessorImpl.java:0, took 0.061159 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.330600Z","level":"info","event":"25/12/28 17:44:54 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.331057Z","level":"info","event":"25/12/28 17:44:54 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.336967Z","level":"info","event":"25/12/28 17:44:54 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 199.3 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.358699Z","level":"info","event":"25/12/28 17:44:54 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.359907Z","level":"info","event":"25/12/28 17:44:54 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on c252dd92c865:44075 (size: 34.3 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.364406Z","level":"info","event":"25/12/28 17:44:54 INFO SparkContext: Created broadcast 44 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.368260Z","level":"info","event":"25/12/28 17:44:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.410432Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.454614Z","level":"info","event":"25/12/28 17:44:54 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.455012Z","level":"info","event":"25/12/28 17:44:54 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.492632Z","level":"info","event":"25/12/28 17:44:54 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 199.2 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.515404Z","level":"info","event":"25/12/28 17:44:54 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.516305Z","level":"info","event":"25/12/28 17:44:54 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on c252dd92c865:44075 (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.517492Z","level":"info","event":"25/12/28 17:44:54 INFO SparkContext: Created broadcast 45 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.519490Z","level":"info","event":"25/12/28 17:44:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.538259Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: Registering RDD 132 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 7","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.538690Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: Got map stage job 22 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.538886Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: Final stage: ShuffleMapStage 29 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.539055Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.539189Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.539619Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[132] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.552018Z","level":"info","event":"25/12/28 17:44:54 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 17.8 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.557820Z","level":"info","event":"25/12/28 17:44:54 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.558130Z","level":"info","event":"25/12/28 17:44:54 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on c252dd92c865:44075 (size: 8.8 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.560581Z","level":"info","event":"25/12/28 17:44:54 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.561001Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[132] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.561207Z","level":"info","event":"25/12/28 17:44:54 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.565266Z","level":"info","event":"25/12/28 17:44:54 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 41) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8266 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.570588Z","level":"info","event":"25/12/28 17:44:54 INFO Executor: Running task 0.0 in stage 29.0 (TID 41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.607664Z","level":"info","event":"25/12/28 17:44:54 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/olist_sellers/part-00000-68fcedb9-9280-417c-81e1-f0a43de0c8c4-c000.csv, range: 0-164617, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.677237Z","level":"info","event":"25/12/28 17:44:54 INFO Executor: Finished task 0.0 in stage 29.0 (TID 41). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.680928Z","level":"info","event":"25/12/28 17:44:54 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 41) in 117 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.681140Z","level":"info","event":"25/12/28 17:44:54 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.684733Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: ShuffleMapStage 29 (count at NativeMethodAccessorImpl.java:0) finished in 0.142 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.685012Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.685271Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.685388Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.685563Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.782717Z","level":"info","event":"25/12/28 17:44:54 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.785335Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: Got job 23 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.785691Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: Final stage: ResultStage 31 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.785954Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.786007Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.788455Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[135] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.797061Z","level":"info","event":"25/12/28 17:44:54 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 12.5 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.937939Z","level":"info","event":"25/12/28 17:44:54 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.951495Z","level":"info","event":"25/12/28 17:44:54 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on c252dd92c865:44075 (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.954689Z","level":"info","event":"25/12/28 17:44:54 INFO BlockManagerInfo: Removed broadcast_41_piece0 on c252dd92c865:44075 in memory (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.956509Z","level":"info","event":"25/12/28 17:44:54 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.962420Z","level":"info","event":"25/12/28 17:44:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[135] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.962986Z","level":"info","event":"25/12/28 17:44:54 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.978598Z","level":"info","event":"25/12/28 17:44:54 INFO BlockManagerInfo: Removed broadcast_46_piece0 on c252dd92c865:44075 in memory (size: 8.8 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:54.993522Z","level":"info","event":"25/12/28 17:44:54 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 42) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.016299Z","level":"info","event":"25/12/28 17:44:55 INFO Executor: Running task 0.0 in stage 31.0 (TID 42)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.016908Z","level":"info","event":"25/12/28 17:44:55 INFO BlockManagerInfo: Removed broadcast_39_piece0 on c252dd92c865:44075 in memory (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.066521Z","level":"info","event":"25/12/28 17:44:55 INFO BlockManagerInfo: Removed broadcast_42_piece0 on c252dd92c865:44075 in memory (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.076241Z","level":"info","event":"25/12/28 17:44:55 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.077587Z","level":"info","event":"25/12/28 17:44:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.086856Z","level":"info","event":"25/12/28 17:44:55 INFO Executor: Finished task 0.0 in stage 31.0 (TID 42). 3995 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.089348Z","level":"info","event":"25/12/28 17:44:55 INFO BlockManagerInfo: Removed broadcast_43_piece0 on c252dd92c865:44075 in memory (size: 6.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.100646Z","level":"info","event":"25/12/28 17:44:55 INFO BlockManagerInfo: Removed broadcast_44_piece0 on c252dd92c865:44075 in memory (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.101068Z","level":"info","event":"25/12/28 17:44:55 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 42) in 110 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.101409Z","level":"info","event":"25/12/28 17:44:55 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.103528Z","level":"info","event":"25/12/28 17:44:55 INFO DAGScheduler: ResultStage 31 (count at NativeMethodAccessorImpl.java:0) finished in 0.311 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.103728Z","level":"info","event":"25/12/28 17:44:55 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.103796Z","level":"info","event":"25/12/28 17:44:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.104585Z","level":"info","event":"25/12/28 17:44:55 INFO DAGScheduler: Job 23 finished: count at NativeMethodAccessorImpl.java:0, took 0.322074 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.119860Z","level":"info","event":"Loaded olist_sellers with 3095 records for cleaning.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.125945Z","level":"info","event":"root","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.126266Z","level":"info","event":"|-- seller_id: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.126482Z","level":"info","event":"|-- seller_zip_code_prefix: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.126617Z","level":"info","event":"|-- seller_city: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.126731Z","level":"info","event":"|-- seller_state: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.126805Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.211285Z","level":"info","event":"25/12/28 17:44:55 INFO InMemoryFileIndex: It took 30 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.225258Z","level":"info","event":"25/12/28 17:44:55 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.352414Z","level":"info","event":"25/12/28 17:44:55 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.354628Z","level":"info","event":"25/12/28 17:44:55 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#326, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.404242Z","level":"info","event":"25/12/28 17:44:55 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 199.3 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.426250Z","level":"info","event":"25/12/28 17:44:55 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.428180Z","level":"info","event":"25/12/28 17:44:55 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on c252dd92c865:44075 (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.432151Z","level":"info","event":"25/12/28 17:44:55 INFO SparkContext: Created broadcast 48 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.434929Z","level":"info","event":"25/12/28 17:44:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.455308Z","level":"info","event":"25/12/28 17:44:55 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.469006Z","level":"info","event":"25/12/28 17:44:55 INFO DAGScheduler: Got job 24 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.469174Z","level":"info","event":"25/12/28 17:44:55 INFO DAGScheduler: Final stage: ResultStage 32 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.469220Z","level":"info","event":"25/12/28 17:44:55 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.469267Z","level":"info","event":"25/12/28 17:44:55 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.473277Z","level":"info","event":"25/12/28 17:44:55 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[139] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.481255Z","level":"info","event":"25/12/28 17:44:55 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 13.5 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.487262Z","level":"info","event":"25/12/28 17:44:55 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.490414Z","level":"info","event":"25/12/28 17:44:55 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on c252dd92c865:44075 (size: 6.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.491315Z","level":"info","event":"25/12/28 17:44:55 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.491987Z","level":"info","event":"25/12/28 17:44:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[139] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.492280Z","level":"info","event":"25/12/28 17:44:55 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.496506Z","level":"info","event":"25/12/28 17:44:55 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 43) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8297 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.499582Z","level":"info","event":"25/12/28 17:44:55 INFO Executor: Running task 0.0 in stage 32.0 (TID 43)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.522830Z","level":"info","event":"25/12/28 17:44:55 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/product_category_name_translation/part-00000-4a7a1cc1-60c8-4276-85b0-0df8175fc9db-c000.csv, range: 0-2540, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.575498Z","level":"info","event":"25/12/28 17:44:55 INFO Executor: Finished task 0.0 in stage 32.0 (TID 43). 1652 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.586504Z","level":"info","event":"25/12/28 17:44:55 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 43) in 91 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.586825Z","level":"info","event":"25/12/28 17:44:55 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.599640Z","level":"info","event":"25/12/28 17:44:55 INFO DAGScheduler: ResultStage 32 (csv at NativeMethodAccessorImpl.java:0) finished in 0.115 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.614911Z","level":"info","event":"25/12/28 17:44:55 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.615075Z","level":"info","event":"25/12/28 17:44:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.619835Z","level":"info","event":"25/12/28 17:44:55 INFO DAGScheduler: Job 24 finished: csv at NativeMethodAccessorImpl.java:0, took 0.162796 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.707806Z","level":"info","event":"25/12/28 17:44:55 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.713787Z","level":"info","event":"25/12/28 17:44:55 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.744690Z","level":"info","event":"25/12/28 17:44:55 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 199.3 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.795784Z","level":"info","event":"25/12/28 17:44:55 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.850108Z","level":"info","event":"25/12/28 17:44:55 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on c252dd92c865:44075 (size: 34.3 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.863522Z","level":"info","event":"25/12/28 17:44:55 INFO SparkContext: Created broadcast 50 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:55.875842Z","level":"info","event":"25/12/28 17:44:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.105420Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.174609Z","level":"info","event":"25/12/28 17:44:56 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.175798Z","level":"info","event":"25/12/28 17:44:56 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.251966Z","level":"info","event":"25/12/28 17:44:56 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 199.2 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.279984Z","level":"info","event":"25/12/28 17:44:56 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.282275Z","level":"info","event":"25/12/28 17:44:56 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on c252dd92c865:44075 (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.284060Z","level":"info","event":"25/12/28 17:44:56 INFO SparkContext: Created broadcast 51 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.289045Z","level":"info","event":"25/12/28 17:44:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.314562Z","level":"info","event":"25/12/28 17:44:56 INFO DAGScheduler: Registering RDD 149 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 8","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.321354Z","level":"info","event":"25/12/28 17:44:56 INFO DAGScheduler: Got map stage job 25 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.321718Z","level":"info","event":"25/12/28 17:44:56 INFO DAGScheduler: Final stage: ShuffleMapStage 33 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.322059Z","level":"info","event":"25/12/28 17:44:56 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.323374Z","level":"info","event":"25/12/28 17:44:56 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.327705Z","level":"info","event":"25/12/28 17:44:56 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[149] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.342642Z","level":"info","event":"25/12/28 17:44:56 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 17.7 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.344790Z","level":"info","event":"25/12/28 17:44:56 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.345430Z","level":"info","event":"25/12/28 17:44:56 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on c252dd92c865:44075 (size: 8.7 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.346568Z","level":"info","event":"25/12/28 17:44:56 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.347847Z","level":"info","event":"25/12/28 17:44:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[149] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.348243Z","level":"info","event":"25/12/28 17:44:56 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.351261Z","level":"info","event":"25/12/28 17:44:56 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 44) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8286 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.354504Z","level":"info","event":"25/12/28 17:44:56 INFO Executor: Running task 0.0 in stage 33.0 (TID 44)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.372789Z","level":"info","event":"25/12/28 17:44:56 INFO FileScanRDD: Reading File path: file:///opt/airflow/data/raw/product_category_name_translation/part-00000-4a7a1cc1-60c8-4276-85b0-0df8175fc9db-c000.csv, range: 0-2540, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.407600Z","level":"info","event":"25/12/28 17:44:56 INFO Executor: Finished task 0.0 in stage 33.0 (TID 44). 1928 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.412519Z","level":"info","event":"25/12/28 17:44:56 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 44) in 59 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.412899Z","level":"info","event":"25/12/28 17:44:56 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.412945Z","level":"info","event":"25/12/28 17:44:56 INFO DAGScheduler: ShuffleMapStage 33 (count at NativeMethodAccessorImpl.java:0) finished in 0.081 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.412991Z","level":"info","event":"25/12/28 17:44:56 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.413094Z","level":"info","event":"25/12/28 17:44:56 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.413327Z","level":"info","event":"25/12/28 17:44:56 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.413573Z","level":"info","event":"25/12/28 17:44:56 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.451267Z","level":"info","event":"25/12/28 17:44:56 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.456552Z","level":"info","event":"25/12/28 17:44:56 INFO DAGScheduler: Got job 26 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.456992Z","level":"info","event":"25/12/28 17:44:56 INFO DAGScheduler: Final stage: ResultStage 35 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.457124Z","level":"info","event":"25/12/28 17:44:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.457300Z","level":"info","event":"25/12/28 17:44:56 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.457542Z","level":"info","event":"25/12/28 17:44:56 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[152] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.465108Z","level":"info","event":"25/12/28 17:44:56 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 12.5 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.546950Z","level":"info","event":"25/12/28 17:44:56 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.550386Z","level":"info","event":"25/12/28 17:44:56 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on c252dd92c865:44075 (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.555645Z","level":"info","event":"25/12/28 17:44:56 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.561884Z","level":"info","event":"25/12/28 17:44:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[152] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.568602Z","level":"info","event":"25/12/28 17:44:56 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.568894Z","level":"info","event":"25/12/28 17:44:56 INFO BlockManagerInfo: Removed broadcast_47_piece0 on c252dd92c865:44075 in memory (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.583431Z","level":"info","event":"25/12/28 17:44:56 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 45) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.584847Z","level":"info","event":"25/12/28 17:44:56 INFO BlockManagerInfo: Removed broadcast_48_piece0 on c252dd92c865:44075 in memory (size: 34.3 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.592622Z","level":"info","event":"25/12/28 17:44:56 INFO Executor: Running task 0.0 in stage 35.0 (TID 45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.637470Z","level":"info","event":"25/12/28 17:44:56 INFO BlockManagerInfo: Removed broadcast_45_piece0 on c252dd92c865:44075 in memory (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.647820Z","level":"info","event":"25/12/28 17:44:56 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.648180Z","level":"info","event":"25/12/28 17:44:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.648319Z","level":"info","event":"25/12/28 17:44:56 INFO BlockManagerInfo: Removed broadcast_50_piece0 on c252dd92c865:44075 in memory (size: 34.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.761685Z","level":"info","event":"25/12/28 17:44:56 INFO Executor: Finished task 0.0 in stage 35.0 (TID 45). 4038 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.767522Z","level":"info","event":"25/12/28 17:44:56 INFO BlockManagerInfo: Removed broadcast_49_piece0 on c252dd92c865:44075 in memory (size: 6.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.784401Z","level":"info","event":"25/12/28 17:44:56 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 45) in 207 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.795674Z","level":"info","event":"25/12/28 17:44:56 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.796830Z","level":"info","event":"25/12/28 17:44:56 INFO DAGScheduler: ResultStage 35 (count at NativeMethodAccessorImpl.java:0) finished in 0.341 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.801363Z","level":"info","event":"25/12/28 17:44:56 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.801759Z","level":"info","event":"25/12/28 17:44:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.801857Z","level":"info","event":"25/12/28 17:44:56 INFO BlockManagerInfo: Removed broadcast_52_piece0 on c252dd92c865:44075 in memory (size: 8.7 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.821840Z","level":"info","event":"25/12/28 17:44:56 INFO DAGScheduler: Job 26 finished: count at NativeMethodAccessorImpl.java:0, took 0.350728 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.878488Z","level":"info","event":"Loaded product_category_name_translation with 71 records for cleaning.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.891705Z","level":"info","event":"root","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.891981Z","level":"info","event":"|-- product_category_name: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.892205Z","level":"info","event":"|-- product_category_name_english: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.892405Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.892758Z","level":"info","event":"=====================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.892880Z","level":"info","event":"printing cleaned dataframes now...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:56.892987Z","level":"info","event":"=====================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:57.594575Z","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:57.603297Z","level":"info","event":"File \"/opt/airflow/src/cleaning.py\", line 153, in <module>","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:57.604672Z","level":"info","event":"clean_data()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:57.605379Z","level":"info","event":"File \"/opt/airflow/src/cleaning.py\", line 133, in clean_data","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:57.609572Z","level":"info","event":"dfs['olist_order_reviews'] = clean_order_reviews()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:57.609845Z","level":"info","event":"^^^^^^^^^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:57.609974Z","level":"info","event":"File \"/opt/airflow/src/cleaning.py\", line 62, in clean_order_reviews","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:57.618809Z","level":"info","event":"col(\"review_score\").try_cast(\"int\"),","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:57.619210Z","level":"info","event":"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:57.619478Z","level":"info","event":"TypeError: 'Column' object is not callable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:58.232486Z","level":"info","event":"25/12/28 17:44:58 INFO SparkContext: Invoking stop() from shutdown hook","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:58.243203Z","level":"info","event":"25/12/28 17:44:58 INFO SparkContext: SparkContext is stopping with exitCode 0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:58.294565Z","level":"info","event":"25/12/28 17:44:58 INFO SparkUI: Stopped Spark web UI at http://c252dd92c865:4040","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:58.347655Z","level":"info","event":"25/12/28 17:44:58 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:58.401063Z","level":"info","event":"25/12/28 17:44:58 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:58.401255Z","level":"info","event":"25/12/28 17:44:58 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:58.412629Z","level":"info","event":"25/12/28 17:44:58 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:58.434913Z","level":"info","event":"25/12/28 17:44:58 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:58.481544Z","level":"info","event":"25/12/28 17:44:58 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:58.481813Z","level":"info","event":"25/12/28 17:44:58 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:58.482309Z","level":"info","event":"25/12/28 17:44:58 INFO ShutdownHookManager: Deleting directory /tmp/spark-103b82ce-21c0-40ce-8373-0d902d50390f/pyspark-59cebd61-28ea-4cc6-9f7a-8afff1833f72","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:58.491404Z","level":"info","event":"25/12/28 17:44:58 INFO ShutdownHookManager: Deleting directory /tmp/spark-3f787077-cbd6-46c0-9520-87746f1a1c3e","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:58.495977Z","level":"info","event":"25/12/28 17:44:58 INFO ShutdownHookManager: Deleting directory /tmp/spark-103b82ce-21c0-40ce-8373-0d902d50390f","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:58.660007Z","level":"error","event":"Task failed with exception","logger":"task","filename":"task_runner.py","lineno":986,"error_detail":[{"exc_type":"AirflowException","exc_value":"Cannot execute: spark-submit --master local[*] --name arrow-spark --verbose --deploy-mode client /opt/airflow/src/cleaning.py. Error code is: 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":934,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1320,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":417,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py","lineno":197,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py","lineno":566,"name":"submit"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2025-12-28T17:44:59.150096Z","level":"info","event":"Task instance in failure state","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:44:59.174208Z","level":"info","event":"Task start","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:44:59.174843Z","level":"info","event":"Task:<Task(SparkSubmitOperator): clean_data>","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:44:59.175016Z","level":"info","event":"Failure caused by Cannot execute: spark-submit --master local[*] --name arrow-spark --verbose --deploy-mode client /opt/airflow/src/cleaning.py. Error code is: 1.","logger":"task.stdout"}
