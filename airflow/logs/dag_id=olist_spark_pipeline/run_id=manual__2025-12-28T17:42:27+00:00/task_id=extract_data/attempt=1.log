{"timestamp":"2025-12-28T17:42:35.138601Z","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2025-12-28T17:42:35.141425Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/ecom_pipeline.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2025-12-28T17:42:35.351116Z","level":"warning","event":"The `airflow.hooks.base.BaseHook` attribute is deprecated. Please use `'airflow.sdk.bases.hook.BaseHook'`.","category":"DeprecatedImportWarning","filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py","lineno":35,"logger":"py.warnings"}
{"timestamp":"2025-12-28T17:42:35.397781Z","level":"info","event":"Task instance is in running state","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:42:35.398537Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:42:35.398663Z","level":"info","event":"Current task name:extract_data","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:42:35.398740Z","level":"info","event":"Dag name:olist_spark_pipeline","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:42:35.422446Z","level":"info","event":"Spark-Submit cmd: spark-submit --master local[*] --name arrow-spark --verbose --deploy-mode client /opt/airflow/src/extract.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":474}
{"timestamp":"2025-12-28T17:42:37.056200Z","level":"info","event":"Using properties file: null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.192761Z","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.192946Z","level":"info","event":"master                  local[*]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193018Z","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193061Z","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193082Z","level":"info","event":"executorMemory          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193117Z","level":"info","event":"executorCores           null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193154Z","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193188Z","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193222Z","level":"info","event":"driverMemory            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193263Z","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193298Z","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193327Z","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193361Z","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193398Z","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193422Z","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193489Z","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193533Z","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193570Z","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193605Z","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193639Z","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193671Z","level":"info","event":"primaryResource         file:/opt/airflow/src/extract.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193716Z","level":"info","event":"name                    arrow-spark","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193751Z","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193766Z","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193780Z","level":"info","event":"packages                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193794Z","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193807Z","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193847Z","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193891Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193924Z","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193946Z","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.193990Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.194010Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.194037Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.509078Z","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.509552Z","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.509688Z","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.509782Z","level":"info","event":"file:/opt/airflow/src/extract.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.510009Z","level":"info","event":"null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.512922Z","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.513129Z","level":"info","event":"(spark.app.name,arrow-spark)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.513210Z","level":"info","event":"(spark.app.submitTime,1766943757485)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.513278Z","level":"info","event":"(spark.master,local[*])","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.513330Z","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.513392Z","level":"info","event":"(spark.submit.pyFiles,)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.513505Z","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.513582Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.513646Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:37.513705Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:39.996913Z","level":"info","event":"Downloading from https://www.kaggle.com/api/v1/datasets/download/olistbr/brazilian-ecommerce?dataset_version_number=2...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:40.005539Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:41.213183Z","level":"info","event":"0%|          | 0.00/42.6M [00:00<?, ?B/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:41.398779Z","level":"info","event":"2%|▏         | 1.00M/42.6M [00:01<00:49, 877kB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:41.529163Z","level":"info","event":"5%|▍         | 2.00M/42.6M [00:01<00:24, 1.72MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:41.672219Z","level":"info","event":"7%|▋         | 3.00M/42.6M [00:01<00:15, 2.69MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:41.800986Z","level":"info","event":"9%|▉         | 4.00M/42.6M [00:01<00:11, 3.58MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:41.915865Z","level":"info","event":"12%|█▏        | 5.00M/42.6M [00:01<00:08, 4.49MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:42.018381Z","level":"info","event":"14%|█▍        | 6.00M/42.6M [00:01<00:07, 5.43MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:42.120988Z","level":"info","event":"16%|█▋        | 7.00M/42.6M [00:02<00:05, 6.41MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:42.222770Z","level":"info","event":"19%|█▉        | 8.00M/42.6M [00:02<00:04, 7.27MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:42.378958Z","level":"info","event":"21%|██        | 9.00M/42.6M [00:02<00:04, 8.01MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:42.474612Z","level":"info","event":"23%|██▎       | 10.0M/42.6M [00:02<00:04, 7.63MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:42.575914Z","level":"info","event":"26%|██▌       | 11.0M/42.6M [00:02<00:03, 8.32MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:42.681004Z","level":"info","event":"28%|██▊       | 12.0M/42.6M [00:02<00:03, 8.85MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:42.785067Z","level":"info","event":"30%|███       | 13.0M/42.6M [00:02<00:03, 9.16MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:42.888877Z","level":"info","event":"33%|███▎      | 14.0M/42.6M [00:02<00:03, 9.42MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:42.999468Z","level":"info","event":"35%|███▌      | 15.0M/42.6M [00:02<00:03, 9.62MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:43.106689Z","level":"info","event":"38%|███▊      | 16.0M/42.6M [00:02<00:02, 9.57MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:43.233833Z","level":"info","event":"40%|███▉      | 17.0M/42.6M [00:03<00:02, 9.64MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:43.343731Z","level":"info","event":"42%|████▏     | 18.0M/42.6M [00:03<00:02, 9.18MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:43.465627Z","level":"info","event":"45%|████▍     | 19.0M/42.6M [00:03<00:02, 9.28MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:43.573399Z","level":"info","event":"47%|████▋     | 20.0M/42.6M [00:03<00:02, 9.07MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:43.681627Z","level":"info","event":"49%|████▉     | 21.0M/42.6M [00:03<00:02, 9.25MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:43.812389Z","level":"info","event":"52%|█████▏    | 22.0M/42.6M [00:03<00:02, 9.38MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:43.945318Z","level":"info","event":"54%|█████▍    | 23.0M/42.6M [00:03<00:02, 8.93MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:44.060832Z","level":"info","event":"56%|█████▋    | 24.0M/42.6M [00:03<00:02, 8.63MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:44.187519Z","level":"info","event":"59%|█████▊    | 25.0M/42.6M [00:04<00:02, 8.74MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:44.289711Z","level":"info","event":"61%|██████    | 26.0M/42.6M [00:04<00:02, 8.58MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:44.405017Z","level":"info","event":"63%|██████▎   | 27.0M/42.6M [00:04<00:01, 9.01MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:44.517168Z","level":"info","event":"66%|██████▌   | 28.0M/42.6M [00:04<00:01, 9.03MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:44.625961Z","level":"info","event":"68%|██████▊   | 29.0M/42.6M [00:04<00:01, 9.13MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:44.735643Z","level":"info","event":"70%|███████   | 30.0M/42.6M [00:04<00:01, 9.28MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:44.849232Z","level":"info","event":"73%|███████▎  | 31.0M/42.6M [00:04<00:01, 9.37MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:44.983841Z","level":"info","event":"75%|███████▌  | 32.0M/42.6M [00:04<00:01, 9.32MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:45.096350Z","level":"info","event":"77%|███████▋  | 33.0M/42.6M [00:04<00:01, 8.80MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:45.209160Z","level":"info","event":"80%|███████▉  | 34.0M/42.6M [00:05<00:01, 8.95MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:45.342724Z","level":"info","event":"82%|████████▏ | 35.0M/42.6M [00:05<00:00, 9.05MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:45.475325Z","level":"info","event":"84%|████████▍ | 36.0M/42.6M [00:05<00:00, 8.68MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:45.628506Z","level":"info","event":"87%|████████▋ | 37.0M/42.6M [00:05<00:00, 8.41MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:45.772266Z","level":"info","event":"89%|████████▉ | 38.0M/42.6M [00:05<00:00, 7.87MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:45.892615Z","level":"info","event":"91%|█████████▏| 39.0M/42.6M [00:05<00:00, 7.69MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:46.028705Z","level":"info","event":"94%|█████████▍| 40.0M/42.6M [00:05<00:00, 7.97MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:46.169199Z","level":"info","event":"96%|█████████▌| 41.0M/42.6M [00:06<00:00, 7.89MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:46.258337Z","level":"info","event":"98%|█████████▊| 42.0M/42.6M [00:06<00:00, 7.76MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:46.258590Z","level":"info","event":"100%|██████████| 42.6M/42.6M [00:06<00:00, 7.15MB/s]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:46.277967Z","level":"info","event":"Extracting files...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.065386Z","level":"info","event":"Path to dataset files: /home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.196135Z","level":"info","event":"25/12/28 17:42:47 INFO SparkContext: Running Spark version 3.5.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.197942Z","level":"info","event":"25/12/28 17:42:47 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, aarch64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.198071Z","level":"info","event":"25/12/28 17:42:47 INFO SparkContext: Java version 17.0.17","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.251868Z","level":"info","event":"25/12/28 17:42:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.318341Z","level":"info","event":"25/12/28 17:42:47 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.318519Z","level":"info","event":"25/12/28 17:42:47 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.318728Z","level":"info","event":"25/12/28 17:42:47 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.319152Z","level":"info","event":"25/12/28 17:42:47 INFO SparkContext: Submitted application: Data Extraction","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.333067Z","level":"info","event":"25/12/28 17:42:47 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.337994Z","level":"info","event":"25/12/28 17:42:47 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.338307Z","level":"info","event":"25/12/28 17:42:47 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.386102Z","level":"info","event":"25/12/28 17:42:47 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.386283Z","level":"info","event":"25/12/28 17:42:47 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.386658Z","level":"info","event":"25/12/28 17:42:47 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.386859Z","level":"info","event":"25/12/28 17:42:47 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.387101Z","level":"info","event":"25/12/28 17:42:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.583674Z","level":"info","event":"25/12/28 17:42:47 INFO Utils: Successfully started service 'sparkDriver' on port 45537.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.623444Z","level":"info","event":"25/12/28 17:42:47 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.660382Z","level":"info","event":"25/12/28 17:42:47 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.684056Z","level":"info","event":"25/12/28 17:42:47 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.684555Z","level":"info","event":"25/12/28 17:42:47 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.689352Z","level":"info","event":"25/12/28 17:42:47 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.711695Z","level":"info","event":"25/12/28 17:42:47 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2145a47c-bbb4-4844-ab2a-74c90ed1ffe8","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.720261Z","level":"info","event":"25/12/28 17:42:47 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.730425Z","level":"info","event":"25/12/28 17:42:47 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.831385Z","level":"info","event":"25/12/28 17:42:47 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.863742Z","level":"info","event":"25/12/28 17:42:47 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.959341Z","level":"info","event":"25/12/28 17:42:47 INFO Executor: Starting executor ID driver on host c252dd92c865","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.959542Z","level":"info","event":"25/12/28 17:42:47 INFO Executor: OS info Linux, 6.10.14-linuxkit, aarch64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.959739Z","level":"info","event":"25/12/28 17:42:47 INFO Executor: Java version 17.0.17","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.963895Z","level":"info","event":"25/12/28 17:42:47 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.964280Z","level":"info","event":"25/12/28 17:42:47 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@526134fd for default.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.978946Z","level":"info","event":"25/12/28 17:42:47 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35057.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.979044Z","level":"info","event":"25/12/28 17:42:47 INFO NettyBlockTransferService: Server created on c252dd92c865:35057","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.980096Z","level":"info","event":"25/12/28 17:42:47 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.983386Z","level":"info","event":"25/12/28 17:42:47 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, c252dd92c865, 35057, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.985092Z","level":"info","event":"25/12/28 17:42:47 INFO BlockManagerMasterEndpoint: Registering block manager c252dd92c865:35057 with 434.4 MiB RAM, BlockManagerId(driver, c252dd92c865, 35057, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.986376Z","level":"info","event":"25/12/28 17:42:47 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, c252dd92c865, 35057, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:47.988464Z","level":"info","event":"25/12/28 17:42:47 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, c252dd92c865, 35057, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:48.269908Z","level":"info","event":"25/12/28 17:42:48 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:48.274121Z","level":"info","event":"25/12/28 17:42:48 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:48.920931Z","level":"info","event":"25/12/28 17:42:48 INFO InMemoryFileIndex: It took 38 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:48.967148Z","level":"info","event":"25/12/28 17:42:48 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:50.642977Z","level":"info","event":"25/12/28 17:42:50 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:50.644523Z","level":"info","event":"25/12/28 17:42:50 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:50.909511Z","level":"info","event":"25/12/28 17:42:50 INFO CodeGenerator: Code generated in 102.250208 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:50.961264Z","level":"info","event":"25/12/28 17:42:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 199.3 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.048302Z","level":"info","event":"25/12/28 17:42:51 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.050783Z","level":"info","event":"25/12/28 17:42:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on c252dd92c865:35057 (size: 34.2 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.056571Z","level":"info","event":"25/12/28 17:42:51 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.064180Z","level":"info","event":"25/12/28 17:42:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.136926Z","level":"info","event":"25/12/28 17:42:51 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.146875Z","level":"info","event":"25/12/28 17:42:51 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.146997Z","level":"info","event":"25/12/28 17:42:51 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.147119Z","level":"info","event":"25/12/28 17:42:51 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.147801Z","level":"info","event":"25/12/28 17:42:51 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.149439Z","level":"info","event":"25/12/28 17:42:51 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.186868Z","level":"info","event":"25/12/28 17:42:51 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 13.5 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.191238Z","level":"info","event":"25/12/28 17:42:51 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.191786Z","level":"info","event":"25/12/28 17:42:51 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on c252dd92c865:35057 (size: 6.4 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.192264Z","level":"info","event":"25/12/28 17:42:51 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.200956Z","level":"info","event":"25/12/28 17:42:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.201873Z","level":"info","event":"25/12/28 17:42:51 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.225996Z","level":"info","event":"25/12/28 17:42:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8291 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.233956Z","level":"info","event":"25/12/28 17:42:51 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.290360Z","level":"info","event":"25/12/28 17:42:51 INFO CodeGenerator: Code generated in 6.999583 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.293188Z","level":"info","event":"25/12/28 17:42:51 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.306600Z","level":"info","event":"25/12/28 17:42:51 INFO CodeGenerator: Code generated in 8.896333 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.492462Z","level":"info","event":"25/12/28 17:42:51 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1715 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.498247Z","level":"info","event":"25/12/28 17:42:51 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 276 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.499169Z","level":"info","event":"25/12/28 17:42:51 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.502426Z","level":"info","event":"25/12/28 17:42:51 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 0.346 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.504040Z","level":"info","event":"25/12/28 17:42:51 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.504242Z","level":"info","event":"25/12/28 17:42:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.505365Z","level":"info","event":"25/12/28 17:42:51 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 0.368196 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.516207Z","level":"info","event":"25/12/28 17:42:51 INFO CodeGenerator: Code generated in 5.077625 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.596267Z","level":"info","event":"25/12/28 17:42:51 INFO BlockManagerInfo: Removed broadcast_1_piece0 on c252dd92c865:35057 in memory (size: 6.4 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.617651Z","level":"info","event":"25/12/28 17:42:51 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.617927Z","level":"info","event":"25/12/28 17:42:51 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.625712Z","level":"info","event":"25/12/28 17:42:51 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 199.3 KiB, free 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.643372Z","level":"info","event":"25/12/28 17:42:51 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.643937Z","level":"info","event":"25/12/28 17:42:51 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on c252dd92c865:35057 (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.645754Z","level":"info","event":"25/12/28 17:42:51 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.649036Z","level":"info","event":"25/12/28 17:42:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.671469Z","level":"info","event":"25/12/28 17:42:51 INFO BlockManagerInfo: Removed broadcast_0_piece0 on c252dd92c865:35057 in memory (size: 34.2 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.716760Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.821700Z","level":"info","event":"25/12/28 17:42:51 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.821955Z","level":"info","event":"25/12/28 17:42:51 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.908427Z","level":"info","event":"25/12/28 17:42:51 INFO CodeGenerator: Code generated in 7.539917 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.913065Z","level":"info","event":"25/12/28 17:42:51 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 199.2 KiB, free 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.943680Z","level":"info","event":"25/12/28 17:42:51 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.945840Z","level":"info","event":"25/12/28 17:42:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.949938Z","level":"info","event":"25/12/28 17:42:51 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:51.959596Z","level":"info","event":"25/12/28 17:42:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.003240Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.006064Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 3 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.006443Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.006745Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.007134Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.009268Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.027234Z","level":"info","event":"25/12/28 17:42:52 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 17.8 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.033908Z","level":"info","event":"25/12/28 17:42:52 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.035473Z","level":"info","event":"25/12/28 17:42:52 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on c252dd92c865:35057 (size: 8.7 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.035764Z","level":"info","event":"25/12/28 17:42:52 INFO BlockManagerInfo: Removed broadcast_2_piece0 on c252dd92c865:35057 in memory (size: 34.2 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.038090Z","level":"info","event":"25/12/28 17:42:52 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.040021Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.040231Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSchedulerImpl: Adding task set 1.0 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.043180Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.043383Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.043611Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.045542Z","level":"info","event":"25/12/28 17:42:52 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.045626Z","level":"info","event":"25/12/28 17:42:52 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.046254Z","level":"info","event":"25/12/28 17:42:52 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.087679Z","level":"info","event":"25/12/28 17:42:52 INFO CodeGenerator: Code generated in 11.900542 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.095029Z","level":"info","event":"25/12/28 17:42:52 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.095719Z","level":"info","event":"25/12/28 17:42:52 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.097805Z","level":"info","event":"25/12/28 17:42:52 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 8388608-9033957, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.104654Z","level":"info","event":"25/12/28 17:42:52 INFO CodeGenerator: Code generated in 8.029959 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.232638Z","level":"info","event":"25/12/28 17:42:52 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 2014 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.236258Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 192 ms on c252dd92c865 (executor driver) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.236378Z","level":"info","event":"25/12/28 17:42:52 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.242961Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 200 ms on c252dd92c865 (executor driver) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.262503Z","level":"info","event":"25/12/28 17:42:52 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 2014 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.264939Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 221 ms on c252dd92c865 (executor driver) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.265102Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.265665Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.256 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.266120Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.266275Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.267216Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.267720Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.314176Z","level":"info","event":"25/12/28 17:42:52 INFO CodeGenerator: Code generated in 18.980208 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.349396Z","level":"info","event":"25/12/28 17:42:52 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.352101Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Got job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.352351Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Final stage: ResultStage 3 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.352432Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.352873Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.353544Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.363104Z","level":"info","event":"25/12/28 17:42:52 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.370881Z","level":"info","event":"25/12/28 17:42:52 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.373856Z","level":"info","event":"25/12/28 17:42:52 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.374390Z","level":"info","event":"25/12/28 17:42:52 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.374832Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.374980Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.375472Z","level":"info","event":"25/12/28 17:42:52 INFO BlockManagerInfo: Removed broadcast_4_piece0 on c252dd92c865:35057 in memory (size: 8.7 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.379603Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.381823Z","level":"info","event":"25/12/28 17:42:52 INFO Executor: Running task 0.0 in stage 3.0 (TID 4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.419004Z","level":"info","event":"25/12/28 17:42:52 INFO ShuffleBlockFetcherIterator: Getting 3 (180.0 B) non-empty blocks including 3 (180.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.422177Z","level":"info","event":"25/12/28 17:42:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.435073Z","level":"info","event":"25/12/28 17:42:52 INFO CodeGenerator: Code generated in 8.355125 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.455138Z","level":"info","event":"25/12/28 17:42:52 INFO Executor: Finished task 0.0 in stage 3.0 (TID 4). 4081 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.457748Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 80 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.457976Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.461991Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: ResultStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.099 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.462315Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.462419Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.462678Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Job 2 finished: count at NativeMethodAccessorImpl.java:0, took 0.114522 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.465856Z","level":"info","event":"Loaded olist_customers with 99441 records.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.534795Z","level":"info","event":"25/12/28 17:42:52 INFO FileSourceStrategy: Pushed Filters: IsNull(customer_id)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.535199Z","level":"info","event":"25/12/28 17:42:52 INFO FileSourceStrategy: Post-Scan Filters: isnull(customer_id#17)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.567866Z","level":"info","event":"25/12/28 17:42:52 INFO CodeGenerator: Code generated in 7.829666 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.569271Z","level":"info","event":"25/12/28 17:42:52 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 199.2 KiB, free 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.581516Z","level":"info","event":"25/12/28 17:42:52 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.586430Z","level":"info","event":"25/12/28 17:42:52 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.586646Z","level":"info","event":"25/12/28 17:42:52 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.587415Z","level":"info","event":"25/12/28 17:42:52 INFO BlockManagerInfo: Removed broadcast_3_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.590253Z","level":"info","event":"25/12/28 17:42:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.593322Z","level":"info","event":"25/12/28 17:42:52 INFO BlockManagerInfo: Removed broadcast_5_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.596703Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.596895Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 3 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.596957Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.597010Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.597080Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.597263Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.604822Z","level":"info","event":"25/12/28 17:42:52 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 18.4 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.616589Z","level":"info","event":"25/12/28 17:42:52 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.618017Z","level":"info","event":"25/12/28 17:42:52 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.618666Z","level":"info","event":"25/12/28 17:42:52 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.619265Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.619340Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSchedulerImpl: Adding task set 4.0 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.622426Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 5) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.622550Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 6) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.622578Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 7) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.623072Z","level":"info","event":"25/12/28 17:42:52 INFO Executor: Running task 0.0 in stage 4.0 (TID 5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.623742Z","level":"info","event":"25/12/28 17:42:52 INFO Executor: Running task 1.0 in stage 4.0 (TID 6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.626150Z","level":"info","event":"25/12/28 17:42:52 INFO Executor: Running task 2.0 in stage 4.0 (TID 7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.636736Z","level":"info","event":"25/12/28 17:42:52 INFO CodeGenerator: Code generated in 7.588042 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.638087Z","level":"info","event":"25/12/28 17:42:52 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.638170Z","level":"info","event":"25/12/28 17:42:52 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 8388608-9033957, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.639017Z","level":"info","event":"25/12/28 17:42:52 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.655533Z","level":"info","event":"25/12/28 17:42:52 INFO CodeGenerator: Code generated in 3.290292 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.747169Z","level":"info","event":"25/12/28 17:42:52 INFO Executor: Finished task 2.0 in stage 4.0 (TID 7). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.749268Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 7) in 127 ms on c252dd92c865 (executor driver) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.811315Z","level":"info","event":"25/12/28 17:42:52 INFO Executor: Finished task 0.0 in stage 4.0 (TID 5). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.813962Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 5) in 192 ms on c252dd92c865 (executor driver) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.817360Z","level":"info","event":"25/12/28 17:42:52 INFO Executor: Finished task 1.0 in stage 4.0 (TID 6). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.820419Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 6) in 200 ms on c252dd92c865 (executor driver) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.821259Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.822089Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.224 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.822451Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.822529Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.822574Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.822736Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.838719Z","level":"info","event":"25/12/28 17:42:52 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.839546Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.839754Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.839815Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.839848Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.840075Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.842443Z","level":"info","event":"25/12/28 17:42:52 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.844571Z","level":"info","event":"25/12/28 17:42:52 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.846057Z","level":"info","event":"25/12/28 17:42:52 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.847545Z","level":"info","event":"25/12/28 17:42:52 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.848390Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.848694Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.851503Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.851593Z","level":"info","event":"25/12/28 17:42:52 INFO Executor: Running task 0.0 in stage 6.0 (TID 8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.853982Z","level":"info","event":"25/12/28 17:42:52 INFO ShuffleBlockFetcherIterator: Getting 3 (180.0 B) non-empty blocks including 3 (180.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.854184Z","level":"info","event":"25/12/28 17:42:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.860890Z","level":"info","event":"25/12/28 17:42:52 INFO Executor: Finished task 0.0 in stage 6.0 (TID 8). 4031 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.862259Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 12 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.862502Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.862989Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.022 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.863132Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.863219Z","level":"info","event":"25/12/28 17:42:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.866345Z","level":"info","event":"25/12/28 17:42:52 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.025437 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.945866Z","level":"info","event":"25/12/28 17:42:52 INFO FileSourceStrategy: Pushed Filters: IsNull(customer_unique_id)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:52.947654Z","level":"info","event":"25/12/28 17:42:52 INFO FileSourceStrategy: Post-Scan Filters: isnull(customer_unique_id#18)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.007006Z","level":"info","event":"25/12/28 17:42:53 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 199.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.023353Z","level":"info","event":"25/12/28 17:42:53 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.025191Z","level":"info","event":"25/12/28 17:42:53 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.029403Z","level":"info","event":"25/12/28 17:42:53 INFO SparkContext: Created broadcast 9 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.029646Z","level":"info","event":"25/12/28 17:42:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.039318Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Registering RDD 27 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.039578Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Got map stage job 5 (count at NativeMethodAccessorImpl.java:0) with 3 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.039683Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.039769Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.039865Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.041405Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.049086Z","level":"info","event":"25/12/28 17:42:53 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 18.4 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.051822Z","level":"info","event":"25/12/28 17:42:53 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.054783Z","level":"info","event":"25/12/28 17:42:53 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.057362Z","level":"info","event":"25/12/28 17:42:53 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.058544Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.059746Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSchedulerImpl: Adding task set 7.0 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.062839Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 9) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.066112Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 10) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.066443Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 11) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.067143Z","level":"info","event":"25/12/28 17:42:53 INFO Executor: Running task 2.0 in stage 7.0 (TID 11)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.067611Z","level":"info","event":"25/12/28 17:42:53 INFO Executor: Running task 1.0 in stage 7.0 (TID 10)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.070186Z","level":"info","event":"25/12/28 17:42:53 INFO Executor: Running task 0.0 in stage 7.0 (TID 9)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.084453Z","level":"info","event":"25/12/28 17:42:53 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.092435Z","level":"info","event":"25/12/28 17:42:53 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 8388608-9033957, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.092985Z","level":"info","event":"25/12/28 17:42:53 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.149403Z","level":"info","event":"25/12/28 17:42:53 INFO Executor: Finished task 2.0 in stage 7.0 (TID 11). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.153371Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 11) in 86 ms on c252dd92c865 (executor driver) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.253767Z","level":"info","event":"25/12/28 17:42:53 INFO Executor: Finished task 1.0 in stage 7.0 (TID 10). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.257361Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 10) in 194 ms on c252dd92c865 (executor driver) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.281008Z","level":"info","event":"25/12/28 17:42:53 INFO Executor: Finished task 0.0 in stage 7.0 (TID 9). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.285814Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 9) in 223 ms on c252dd92c865 (executor driver) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.286077Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.302867Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.253 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.303077Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.303130Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.303154Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.306433Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.346399Z","level":"info","event":"25/12/28 17:42:53 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.349362Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Got job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.349624Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Final stage: ResultStage 9 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.349733Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.349870Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.356924Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.365834Z","level":"info","event":"25/12/28 17:42:53 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 12.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.368770Z","level":"info","event":"25/12/28 17:42:53 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.369694Z","level":"info","event":"25/12/28 17:42:53 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.372491Z","level":"info","event":"25/12/28 17:42:53 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.372939Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.373269Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.374774Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 12) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.377348Z","level":"info","event":"25/12/28 17:42:53 INFO Executor: Running task 0.0 in stage 9.0 (TID 12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.382567Z","level":"info","event":"25/12/28 17:42:53 INFO ShuffleBlockFetcherIterator: Getting 3 (180.0 B) non-empty blocks including 3 (180.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.383392Z","level":"info","event":"25/12/28 17:42:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.387045Z","level":"info","event":"25/12/28 17:42:53 INFO Executor: Finished task 0.0 in stage 9.0 (TID 12). 3988 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.389584Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 12) in 14 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.389670Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.389963Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: ResultStage 9 (count at NativeMethodAccessorImpl.java:0) finished in 0.032 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.390273Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.390316Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.391645Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Job 6 finished: count at NativeMethodAccessorImpl.java:0, took 0.044975 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.443334Z","level":"info","event":"25/12/28 17:42:53 INFO FileSourceStrategy: Pushed Filters: IsNull(customer_zip_code_prefix)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.443617Z","level":"info","event":"25/12/28 17:42:53 INFO FileSourceStrategy: Post-Scan Filters: isnull(customer_zip_code_prefix#19)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.474180Z","level":"info","event":"25/12/28 17:42:53 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.492743Z","level":"info","event":"25/12/28 17:42:53 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.493274Z","level":"info","event":"25/12/28 17:42:53 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.495185Z","level":"info","event":"25/12/28 17:42:53 INFO SparkContext: Created broadcast 12 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.498250Z","level":"info","event":"25/12/28 17:42:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.516589Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Registering RDD 34 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.516817Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Got map stage job 7 (count at NativeMethodAccessorImpl.java:0) with 3 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.516898Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.516981Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.517100Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.517200Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.521740Z","level":"info","event":"25/12/28 17:42:53 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 18.4 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.527766Z","level":"info","event":"25/12/28 17:42:53 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.531132Z","level":"info","event":"25/12/28 17:42:53 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.534004Z","level":"info","event":"25/12/28 17:42:53 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.535434Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.537759Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSchedulerImpl: Adding task set 10.0 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.549035Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 13) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.549142Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 14) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.549166Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 15) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.549199Z","level":"info","event":"25/12/28 17:42:53 INFO Executor: Running task 2.0 in stage 10.0 (TID 15)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.549507Z","level":"info","event":"25/12/28 17:42:53 INFO Executor: Running task 0.0 in stage 10.0 (TID 13)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.553438Z","level":"info","event":"25/12/28 17:42:53 INFO Executor: Running task 1.0 in stage 10.0 (TID 14)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.558396Z","level":"info","event":"25/12/28 17:42:53 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.563242Z","level":"info","event":"25/12/28 17:42:53 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.565527Z","level":"info","event":"25/12/28 17:42:53 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 8388608-9033957, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.615898Z","level":"info","event":"25/12/28 17:42:53 INFO BlockManagerInfo: Removed broadcast_6_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.631983Z","level":"info","event":"25/12/28 17:42:53 INFO Executor: Finished task 2.0 in stage 10.0 (TID 15). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.633073Z","level":"info","event":"25/12/28 17:42:53 INFO BlockManagerInfo: Removed broadcast_8_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.637431Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 15) in 89 ms on c252dd92c865 (executor driver) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.646379Z","level":"info","event":"25/12/28 17:42:53 INFO BlockManagerInfo: Removed broadcast_11_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.657394Z","level":"info","event":"25/12/28 17:42:53 INFO BlockManagerInfo: Removed broadcast_10_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.663745Z","level":"info","event":"25/12/28 17:42:53 INFO BlockManagerInfo: Removed broadcast_9_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.679362Z","level":"info","event":"25/12/28 17:42:53 INFO BlockManagerInfo: Removed broadcast_7_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.681260Z","level":"info","event":"25/12/28 17:42:53 INFO Executor: Finished task 1.0 in stage 10.0 (TID 14). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.684366Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 14) in 136 ms on c252dd92c865 (executor driver) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.701927Z","level":"info","event":"25/12/28 17:42:53 INFO Executor: Finished task 0.0 in stage 10.0 (TID 13). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.704402Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 13) in 165 ms on c252dd92c865 (executor driver) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.704698Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.705167Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: ShuffleMapStage 10 (count at NativeMethodAccessorImpl.java:0) finished in 0.186 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.706996Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.707215Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.707322Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.707392Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.742475Z","level":"info","event":"25/12/28 17:42:53 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.743846Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Got job 8 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.744051Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Final stage: ResultStage 12 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.744130Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.744200Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.745944Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[37] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.756386Z","level":"info","event":"25/12/28 17:42:53 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.764601Z","level":"info","event":"25/12/28 17:42:53 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.766092Z","level":"info","event":"25/12/28 17:42:53 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.767675Z","level":"info","event":"25/12/28 17:42:53 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.768564Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[37] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.768775Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.772492Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 16) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.773988Z","level":"info","event":"25/12/28 17:42:53 INFO Executor: Running task 0.0 in stage 12.0 (TID 16)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.778563Z","level":"info","event":"25/12/28 17:42:53 INFO ShuffleBlockFetcherIterator: Getting 3 (180.0 B) non-empty blocks including 3 (180.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.778865Z","level":"info","event":"25/12/28 17:42:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.781492Z","level":"info","event":"25/12/28 17:42:53 INFO Executor: Finished task 0.0 in stage 12.0 (TID 16). 3988 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.782397Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 16) in 11 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.782479Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.783933Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: ResultStage 12 (count at NativeMethodAccessorImpl.java:0) finished in 0.036 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.784140Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.784281Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.784544Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Job 8 finished: count at NativeMethodAccessorImpl.java:0, took 0.041923 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.840503Z","level":"info","event":"25/12/28 17:42:53 INFO FileSourceStrategy: Pushed Filters: IsNull(customer_city)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.840769Z","level":"info","event":"25/12/28 17:42:53 INFO FileSourceStrategy: Post-Scan Filters: isnull(customer_city#20)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.890525Z","level":"info","event":"25/12/28 17:42:53 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 199.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.903021Z","level":"info","event":"25/12/28 17:42:53 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.904268Z","level":"info","event":"25/12/28 17:42:53 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.906062Z","level":"info","event":"25/12/28 17:42:53 INFO SparkContext: Created broadcast 15 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.909404Z","level":"info","event":"25/12/28 17:42:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.915912Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Registering RDD 41 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.916790Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Got map stage job 9 (count at NativeMethodAccessorImpl.java:0) with 3 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.916952Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Final stage: ShuffleMapStage 13 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.917193Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.920923Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.922122Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[41] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.925424Z","level":"info","event":"25/12/28 17:42:53 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 18.4 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.928315Z","level":"info","event":"25/12/28 17:42:53 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.929624Z","level":"info","event":"25/12/28 17:42:53 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.930241Z","level":"info","event":"25/12/28 17:42:53 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.931729Z","level":"info","event":"25/12/28 17:42:53 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[41] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.932519Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSchedulerImpl: Adding task set 13.0 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.936964Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 17) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.937238Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 18) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.937630Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 19) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.939920Z","level":"info","event":"25/12/28 17:42:53 INFO Executor: Running task 1.0 in stage 13.0 (TID 18)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.940117Z","level":"info","event":"25/12/28 17:42:53 INFO Executor: Running task 0.0 in stage 13.0 (TID 17)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.940191Z","level":"info","event":"25/12/28 17:42:53 INFO Executor: Running task 2.0 in stage 13.0 (TID 19)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.946429Z","level":"info","event":"25/12/28 17:42:53 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.947853Z","level":"info","event":"25/12/28 17:42:53 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.953421Z","level":"info","event":"25/12/28 17:42:53 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 8388608-9033957, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.978266Z","level":"info","event":"25/12/28 17:42:53 INFO Executor: Finished task 2.0 in stage 13.0 (TID 19). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:53.983401Z","level":"info","event":"25/12/28 17:42:53 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 19) in 46 ms on c252dd92c865 (executor driver) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.020355Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Finished task 0.0 in stage 13.0 (TID 17). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.021306Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 17) in 87 ms on c252dd92c865 (executor driver) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.023163Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Finished task 1.0 in stage 13.0 (TID 18). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.023978Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 18) in 87 ms on c252dd92c865 (executor driver) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.024079Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.028648Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: ShuffleMapStage 13 (count at NativeMethodAccessorImpl.java:0) finished in 0.102 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.028840Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.028907Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.028966Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.028997Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.049029Z","level":"info","event":"25/12/28 17:42:54 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.050185Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Got job 10 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.050240Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Final stage: ResultStage 15 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.050261Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.050558Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.053491Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[44] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.054581Z","level":"info","event":"25/12/28 17:42:54 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 12.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.056322Z","level":"info","event":"25/12/28 17:42:54 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.058262Z","level":"info","event":"25/12/28 17:42:54 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.058382Z","level":"info","event":"25/12/28 17:42:54 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.058408Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[44] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.058425Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.059268Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 20) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.059565Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Running task 0.0 in stage 15.0 (TID 20)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.062272Z","level":"info","event":"25/12/28 17:42:54 INFO ShuffleBlockFetcherIterator: Getting 3 (180.0 B) non-empty blocks including 3 (180.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.062538Z","level":"info","event":"25/12/28 17:42:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.064361Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Finished task 0.0 in stage 15.0 (TID 20). 3988 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.065082Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 20) in 6 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.065158Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.067334Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: ResultStage 15 (count at NativeMethodAccessorImpl.java:0) finished in 0.015 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.067503Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.067622Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.067699Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Job 10 finished: count at NativeMethodAccessorImpl.java:0, took 0.018612 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.113556Z","level":"info","event":"25/12/28 17:42:54 INFO FileSourceStrategy: Pushed Filters: IsNull(customer_state)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.114433Z","level":"info","event":"25/12/28 17:42:54 INFO FileSourceStrategy: Post-Scan Filters: isnull(customer_state#21)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.148884Z","level":"info","event":"25/12/28 17:42:54 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.158845Z","level":"info","event":"25/12/28 17:42:54 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.161616Z","level":"info","event":"25/12/28 17:42:54 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.163472Z","level":"info","event":"25/12/28 17:42:54 INFO SparkContext: Created broadcast 18 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.166482Z","level":"info","event":"25/12/28 17:42:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.172254Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Registering RDD 48 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 5","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.172561Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Got map stage job 11 (count at NativeMethodAccessorImpl.java:0) with 3 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.172634Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Final stage: ShuffleMapStage 16 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.172733Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.172824Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.175516Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[48] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.177904Z","level":"info","event":"25/12/28 17:42:54 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 18.4 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.180472Z","level":"info","event":"25/12/28 17:42:54 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.181097Z","level":"info","event":"25/12/28 17:42:54 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.181716Z","level":"info","event":"25/12/28 17:42:54 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.182101Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[48] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.182206Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSchedulerImpl: Adding task set 16.0 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.187750Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 21) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.188050Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 22) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.188190Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 23) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8280 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.188791Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Running task 0.0 in stage 16.0 (TID 21)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.192320Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Running task 1.0 in stage 16.0 (TID 22)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.192439Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Running task 2.0 in stage 16.0 (TID 23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.195202Z","level":"info","event":"25/12/28 17:42:54 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.198823Z","level":"info","event":"25/12/28 17:42:54 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 8388608-9033957, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.199115Z","level":"info","event":"25/12/28 17:42:54 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.234641Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Finished task 2.0 in stage 16.0 (TID 23). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.239267Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 23) in 52 ms on c252dd92c865 (executor driver) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.251648Z","level":"info","event":"25/12/28 17:42:54 INFO BlockManagerInfo: Removed broadcast_17_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.257691Z","level":"info","event":"25/12/28 17:42:54 INFO BlockManagerInfo: Removed broadcast_14_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.275306Z","level":"info","event":"25/12/28 17:42:54 INFO BlockManagerInfo: Removed broadcast_15_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.281190Z","level":"info","event":"25/12/28 17:42:54 INFO BlockManagerInfo: Removed broadcast_13_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.288436Z","level":"info","event":"25/12/28 17:42:54 INFO BlockManagerInfo: Removed broadcast_12_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.292448Z","level":"info","event":"25/12/28 17:42:54 INFO BlockManagerInfo: Removed broadcast_16_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.296985Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Finished task 1.0 in stage 16.0 (TID 22). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.298768Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 22) in 114 ms on c252dd92c865 (executor driver) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.310796Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Finished task 0.0 in stage 16.0 (TID 21). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.311578Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 21) in 128 ms on c252dd92c865 (executor driver) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.311644Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.312465Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: ShuffleMapStage 16 (count at NativeMethodAccessorImpl.java:0) finished in 0.136 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.312597Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.312674Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.312747Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.312823Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.326107Z","level":"info","event":"25/12/28 17:42:54 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.327415Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Got job 12 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.327591Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Final stage: ResultStage 18 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.327654Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.327713Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.327870Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[51] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.333454Z","level":"info","event":"25/12/28 17:42:54 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.335594Z","level":"info","event":"25/12/28 17:42:54 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.336526Z","level":"info","event":"25/12/28 17:42:54 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.337085Z","level":"info","event":"25/12/28 17:42:54 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.337571Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[51] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.337794Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.339388Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 24) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.340461Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Running task 0.0 in stage 18.0 (TID 24)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.347306Z","level":"info","event":"25/12/28 17:42:54 INFO ShuffleBlockFetcherIterator: Getting 3 (180.0 B) non-empty blocks including 3 (180.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.347603Z","level":"info","event":"25/12/28 17:42:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.352275Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Finished task 0.0 in stage 18.0 (TID 24). 3988 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.353422Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 24) in 15 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.355160Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: ResultStage 18 (count at NativeMethodAccessorImpl.java:0) finished in 0.026 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.355370Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.355615Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.358054Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.359640Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Job 12 finished: count at NativeMethodAccessorImpl.java:0, took 0.032240 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.384727Z","level":"info","event":"25/12/28 17:42:54 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.392480Z","level":"info","event":"25/12/28 17:42:54 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.452146Z","level":"info","event":"25/12/28 17:42:54 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.452516Z","level":"info","event":"25/12/28 17:42:54 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#93, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.459465Z","level":"info","event":"25/12/28 17:42:54 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 199.3 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.464660Z","level":"info","event":"25/12/28 17:42:54 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.465089Z","level":"info","event":"25/12/28 17:42:54 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on c252dd92c865:35057 (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.467200Z","level":"info","event":"25/12/28 17:42:54 INFO SparkContext: Created broadcast 21 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.467320Z","level":"info","event":"25/12/28 17:42:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 9352598 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.472271Z","level":"info","event":"25/12/28 17:42:54 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.474093Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Got job 13 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.474316Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Final stage: ResultStage 19 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.474395Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.474454Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.474517Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[55] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.475233Z","level":"info","event":"25/12/28 17:42:54 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 13.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.480821Z","level":"info","event":"25/12/28 17:42:54 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.484105Z","level":"info","event":"25/12/28 17:42:54 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on c252dd92c865:35057 (size: 6.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.484385Z","level":"info","event":"25/12/28 17:42:54 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.484523Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[55] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.484639Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.484771Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 25) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8293 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.484860Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Running task 0.0 in stage 19.0 (TID 25)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.491006Z","level":"info","event":"25/12/28 17:42:54 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 0-9352598, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.496114Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Finished task 0.0 in stage 19.0 (TID 25). 1626 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.498465Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 25) in 15 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.500271Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.500403Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: ResultStage 19 (csv at NativeMethodAccessorImpl.java:0) finished in 0.026 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.500426Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.500443Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.500581Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Job 13 finished: csv at NativeMethodAccessorImpl.java:0, took 0.028089 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.511881Z","level":"info","event":"25/12/28 17:42:54 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.512094Z","level":"info","event":"25/12/28 17:42:54 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.515794Z","level":"info","event":"25/12/28 17:42:54 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 199.3 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.523186Z","level":"info","event":"25/12/28 17:42:54 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.526558Z","level":"info","event":"25/12/28 17:42:54 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on c252dd92c865:35057 (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.528046Z","level":"info","event":"25/12/28 17:42:54 INFO SparkContext: Created broadcast 23 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.529504Z","level":"info","event":"25/12/28 17:42:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 9352598 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.544885Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.567564Z","level":"info","event":"25/12/28 17:42:54 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.568057Z","level":"info","event":"25/12/28 17:42:54 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.580178Z","level":"info","event":"25/12/28 17:42:54 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 199.2 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.585772Z","level":"info","event":"25/12/28 17:42:54 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.586380Z","level":"info","event":"25/12/28 17:42:54 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.587641Z","level":"info","event":"25/12/28 17:42:54 INFO SparkContext: Created broadcast 24 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.588864Z","level":"info","event":"25/12/28 17:42:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 9352598 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.593146Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Registering RDD 65 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 6","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.593368Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Got map stage job 14 (count at NativeMethodAccessorImpl.java:0) with 7 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.593431Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Final stage: ShuffleMapStage 20 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.593626Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.593744Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.594116Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[65] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.595719Z","level":"info","event":"25/12/28 17:42:54 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 17.8 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.596454Z","level":"info","event":"25/12/28 17:42:54 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.596740Z","level":"info","event":"25/12/28 17:42:54 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on c252dd92c865:35057 (size: 8.7 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.597048Z","level":"info","event":"25/12/28 17:42:54 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.597390Z","level":"info","event":"25/12/28 17:42:54 INFO DAGScheduler: Submitting 7 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[65] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.597477Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSchedulerImpl: Adding task set 20.0 with 7 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.598196Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 26) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.598327Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 27) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.598654Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 28) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.598763Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Starting task 3.0 in stage 20.0 (TID 29) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.599157Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Starting task 4.0 in stage 20.0 (TID 30) (c252dd92c865, executor driver, partition 4, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.599285Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Starting task 5.0 in stage 20.0 (TID 31) (c252dd92c865, executor driver, partition 5, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.599863Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Starting task 6.0 in stage 20.0 (TID 32) (c252dd92c865, executor driver, partition 6, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.600479Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Running task 2.0 in stage 20.0 (TID 28)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.600600Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Running task 0.0 in stage 20.0 (TID 26)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.601491Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Running task 4.0 in stage 20.0 (TID 30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.601813Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Running task 3.0 in stage 20.0 (TID 29)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.603669Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Running task 1.0 in stage 20.0 (TID 27)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.603891Z","level":"info","event":"25/12/28 17:42:54 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 37410392-46762990, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.604138Z","level":"info","event":"25/12/28 17:42:54 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 9352598-18705196, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.605370Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Running task 5.0 in stage 20.0 (TID 31)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.605570Z","level":"info","event":"25/12/28 17:42:54 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 0-9352598, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.607980Z","level":"info","event":"25/12/28 17:42:54 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 28057794-37410392, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.608067Z","level":"info","event":"25/12/28 17:42:54 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 46762990-56115588, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.608085Z","level":"info","event":"25/12/28 17:42:54 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 18705196-28057794, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.608248Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Running task 6.0 in stage 20.0 (TID 32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.619379Z","level":"info","event":"25/12/28 17:42:54 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 56115588-61273883, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.769666Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Finished task 6.0 in stage 20.0 (TID 32). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.785505Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Finished task 6.0 in stage 20.0 (TID 32) in 184 ms on c252dd92c865 (executor driver) (1/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.846617Z","level":"info","event":"25/12/28 17:42:54 INFO BlockManagerInfo: Removed broadcast_23_piece0 on c252dd92c865:35057 in memory (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.886817Z","level":"info","event":"25/12/28 17:42:54 INFO BlockManagerInfo: Removed broadcast_21_piece0 on c252dd92c865:35057 in memory (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.917050Z","level":"info","event":"25/12/28 17:42:54 INFO BlockManagerInfo: Removed broadcast_20_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.934481Z","level":"info","event":"25/12/28 17:42:54 INFO BlockManagerInfo: Removed broadcast_19_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.944530Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Finished task 3.0 in stage 20.0 (TID 29). 2014 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.956643Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Finished task 3.0 in stage 20.0 (TID 29) in 347 ms on c252dd92c865 (executor driver) (2/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.968232Z","level":"info","event":"25/12/28 17:42:54 INFO BlockManagerInfo: Removed broadcast_22_piece0 on c252dd92c865:35057 in memory (size: 6.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.974142Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Finished task 4.0 in stage 20.0 (TID 30). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.978194Z","level":"info","event":"25/12/28 17:42:54 INFO Executor: Finished task 2.0 in stage 20.0 (TID 28). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.983028Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Finished task 4.0 in stage 20.0 (TID 30) in 383 ms on c252dd92c865 (executor driver) (3/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.992714Z","level":"info","event":"25/12/28 17:42:54 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 28) in 394 ms on c252dd92c865 (executor driver) (4/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:54.996861Z","level":"info","event":"25/12/28 17:42:54 INFO BlockManagerInfo: Removed broadcast_18_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.063564Z","level":"info","event":"25/12/28 17:42:55 INFO Executor: Finished task 0.0 in stage 20.0 (TID 26). 2014 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.064091Z","level":"info","event":"25/12/28 17:42:55 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 26) in 466 ms on c252dd92c865 (executor driver) (5/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.084183Z","level":"info","event":"25/12/28 17:42:55 INFO Executor: Finished task 5.0 in stage 20.0 (TID 31). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.094966Z","level":"info","event":"25/12/28 17:42:55 INFO TaskSetManager: Finished task 5.0 in stage 20.0 (TID 31) in 494 ms on c252dd92c865 (executor driver) (6/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.124936Z","level":"info","event":"25/12/28 17:42:55 INFO Executor: Finished task 1.0 in stage 20.0 (TID 27). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.128393Z","level":"info","event":"25/12/28 17:42:55 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 27) in 529 ms on c252dd92c865 (executor driver) (7/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.130557Z","level":"info","event":"25/12/28 17:42:55 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.133751Z","level":"info","event":"25/12/28 17:42:55 INFO DAGScheduler: ShuffleMapStage 20 (count at NativeMethodAccessorImpl.java:0) finished in 0.539 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.134103Z","level":"info","event":"25/12/28 17:42:55 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.134205Z","level":"info","event":"25/12/28 17:42:55 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.134329Z","level":"info","event":"25/12/28 17:42:55 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.134419Z","level":"info","event":"25/12/28 17:42:55 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.351150Z","level":"info","event":"25/12/28 17:42:55 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.354116Z","level":"info","event":"25/12/28 17:42:55 INFO DAGScheduler: Got job 15 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.354444Z","level":"info","event":"25/12/28 17:42:55 INFO DAGScheduler: Final stage: ResultStage 22 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.354780Z","level":"info","event":"25/12/28 17:42:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.357905Z","level":"info","event":"25/12/28 17:42:55 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.365370Z","level":"info","event":"25/12/28 17:42:55 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[68] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.385454Z","level":"info","event":"25/12/28 17:42:55 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.401818Z","level":"info","event":"25/12/28 17:42:55 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.405527Z","level":"info","event":"25/12/28 17:42:55 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.405839Z","level":"info","event":"25/12/28 17:42:55 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.407794Z","level":"info","event":"25/12/28 17:42:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[68] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.408136Z","level":"info","event":"25/12/28 17:42:55 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.412425Z","level":"info","event":"25/12/28 17:42:55 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 33) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.416384Z","level":"info","event":"25/12/28 17:42:55 INFO Executor: Running task 0.0 in stage 22.0 (TID 33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.443528Z","level":"info","event":"25/12/28 17:42:55 INFO ShuffleBlockFetcherIterator: Getting 7 (420.0 B) non-empty blocks including 7 (420.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.444020Z","level":"info","event":"25/12/28 17:42:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.457092Z","level":"info","event":"25/12/28 17:42:55 INFO Executor: Finished task 0.0 in stage 22.0 (TID 33). 3995 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.459546Z","level":"info","event":"25/12/28 17:42:55 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 33) in 48 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.459900Z","level":"info","event":"25/12/28 17:42:55 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.460564Z","level":"info","event":"25/12/28 17:42:55 INFO DAGScheduler: ResultStage 22 (count at NativeMethodAccessorImpl.java:0) finished in 0.094 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.461414Z","level":"info","event":"25/12/28 17:42:55 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.461584Z","level":"info","event":"25/12/28 17:42:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.461735Z","level":"info","event":"25/12/28 17:42:55 INFO DAGScheduler: Job 15 finished: count at NativeMethodAccessorImpl.java:0, took 0.113158 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.465113Z","level":"info","event":"Loaded olist_geolocation with 1000163 records.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.566248Z","level":"info","event":"25/12/28 17:42:55 INFO FileSourceStrategy: Pushed Filters: IsNull(geolocation_zip_code_prefix)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.566439Z","level":"info","event":"25/12/28 17:42:55 INFO FileSourceStrategy: Post-Scan Filters: isnull(geolocation_zip_code_prefix#110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.590595Z","level":"info","event":"25/12/28 17:42:55 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 199.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.608703Z","level":"info","event":"25/12/28 17:42:55 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.609697Z","level":"info","event":"25/12/28 17:42:55 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.610583Z","level":"info","event":"25/12/28 17:42:55 INFO SparkContext: Created broadcast 27 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.615329Z","level":"info","event":"25/12/28 17:42:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 9352598 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.623081Z","level":"info","event":"25/12/28 17:42:55 INFO DAGScheduler: Registering RDD 72 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 7","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.623343Z","level":"info","event":"25/12/28 17:42:55 INFO DAGScheduler: Got map stage job 16 (count at NativeMethodAccessorImpl.java:0) with 7 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.623431Z","level":"info","event":"25/12/28 17:42:55 INFO DAGScheduler: Final stage: ShuffleMapStage 23 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.623521Z","level":"info","event":"25/12/28 17:42:55 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.623595Z","level":"info","event":"25/12/28 17:42:55 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.623712Z","level":"info","event":"25/12/28 17:42:55 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[72] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.626567Z","level":"info","event":"25/12/28 17:42:55 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 18.4 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.628114Z","level":"info","event":"25/12/28 17:42:55 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.628608Z","level":"info","event":"25/12/28 17:42:55 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.629090Z","level":"info","event":"25/12/28 17:42:55 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.630377Z","level":"info","event":"25/12/28 17:42:55 INFO DAGScheduler: Submitting 7 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[72] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.630804Z","level":"info","event":"25/12/28 17:42:55 INFO TaskSchedulerImpl: Adding task set 23.0 with 7 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.637606Z","level":"info","event":"25/12/28 17:42:55 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 34) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.638386Z","level":"info","event":"25/12/28 17:42:55 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 35) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.638675Z","level":"info","event":"25/12/28 17:42:55 INFO TaskSetManager: Starting task 2.0 in stage 23.0 (TID 36) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.638803Z","level":"info","event":"25/12/28 17:42:55 INFO TaskSetManager: Starting task 3.0 in stage 23.0 (TID 37) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.638992Z","level":"info","event":"25/12/28 17:42:55 INFO TaskSetManager: Starting task 4.0 in stage 23.0 (TID 38) (c252dd92c865, executor driver, partition 4, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.639202Z","level":"info","event":"25/12/28 17:42:55 INFO TaskSetManager: Starting task 5.0 in stage 23.0 (TID 39) (c252dd92c865, executor driver, partition 5, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.639601Z","level":"info","event":"25/12/28 17:42:55 INFO TaskSetManager: Starting task 6.0 in stage 23.0 (TID 40) (c252dd92c865, executor driver, partition 6, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.640511Z","level":"info","event":"25/12/28 17:42:55 INFO Executor: Running task 6.0 in stage 23.0 (TID 40)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.640680Z","level":"info","event":"25/12/28 17:42:55 INFO Executor: Running task 1.0 in stage 23.0 (TID 35)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.640836Z","level":"info","event":"25/12/28 17:42:55 INFO Executor: Running task 4.0 in stage 23.0 (TID 38)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.642745Z","level":"info","event":"25/12/28 17:42:55 INFO Executor: Running task 5.0 in stage 23.0 (TID 39)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.642982Z","level":"info","event":"25/12/28 17:42:55 INFO Executor: Running task 2.0 in stage 23.0 (TID 36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.643255Z","level":"info","event":"25/12/28 17:42:55 INFO Executor: Running task 0.0 in stage 23.0 (TID 34)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.646465Z","level":"info","event":"25/12/28 17:42:55 INFO Executor: Running task 3.0 in stage 23.0 (TID 37)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.646810Z","level":"info","event":"25/12/28 17:42:55 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 56115588-61273883, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.647994Z","level":"info","event":"25/12/28 17:42:55 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 28057794-37410392, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.648855Z","level":"info","event":"25/12/28 17:42:55 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 37410392-46762990, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.651816Z","level":"info","event":"25/12/28 17:42:55 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 46762990-56115588, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.651950Z","level":"info","event":"25/12/28 17:42:55 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 18705196-28057794, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.651996Z","level":"info","event":"25/12/28 17:42:55 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 0-9352598, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.654701Z","level":"info","event":"25/12/28 17:42:55 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 9352598-18705196, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.805885Z","level":"info","event":"25/12/28 17:42:55 INFO BlockManagerInfo: Removed broadcast_26_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.832649Z","level":"info","event":"25/12/28 17:42:55 INFO BlockManagerInfo: Removed broadcast_25_piece0 on c252dd92c865:35057 in memory (size: 8.7 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:55.870882Z","level":"info","event":"25/12/28 17:42:55 INFO BlockManagerInfo: Removed broadcast_24_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.023558Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Finished task 4.0 in stage 23.0 (TID 38). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.024931Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Finished task 6.0 in stage 23.0 (TID 40). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.032955Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Finished task 3.0 in stage 23.0 (TID 37). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.033358Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Finished task 4.0 in stage 23.0 (TID 38) in 394 ms on c252dd92c865 (executor driver) (1/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.048146Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Finished task 3.0 in stage 23.0 (TID 37) in 406 ms on c252dd92c865 (executor driver) (2/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.049274Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Finished task 6.0 in stage 23.0 (TID 40) in 410 ms on c252dd92c865 (executor driver) (3/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.049574Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Finished task 2.0 in stage 23.0 (TID 36). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.054810Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Finished task 2.0 in stage 23.0 (TID 36) in 416 ms on c252dd92c865 (executor driver) (4/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.063329Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Finished task 5.0 in stage 23.0 (TID 39). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.064869Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Finished task 5.0 in stage 23.0 (TID 39) in 426 ms on c252dd92c865 (executor driver) (5/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.104385Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Finished task 1.0 in stage 23.0 (TID 35). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.105954Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 35) in 468 ms on c252dd92c865 (executor driver) (6/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.112351Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Finished task 0.0 in stage 23.0 (TID 34). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.113006Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 34) in 476 ms on c252dd92c865 (executor driver) (7/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.113061Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.113639Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: ShuffleMapStage 23 (count at NativeMethodAccessorImpl.java:0) finished in 0.489 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.113752Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.113786Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.113808Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.113839Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.150365Z","level":"info","event":"25/12/28 17:42:56 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.153577Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Got job 17 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.153846Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Final stage: ResultStage 25 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.154043Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.154181Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.159174Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[75] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.165447Z","level":"info","event":"25/12/28 17:42:56 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.165958Z","level":"info","event":"25/12/28 17:42:56 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.166660Z","level":"info","event":"25/12/28 17:42:56 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.167676Z","level":"info","event":"25/12/28 17:42:56 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.168352Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[75] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.168539Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.170626Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 41) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.171568Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Running task 0.0 in stage 25.0 (TID 41)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.176256Z","level":"info","event":"25/12/28 17:42:56 INFO ShuffleBlockFetcherIterator: Getting 7 (420.0 B) non-empty blocks including 7 (420.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.176578Z","level":"info","event":"25/12/28 17:42:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.180373Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Finished task 0.0 in stage 25.0 (TID 41). 3988 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.181285Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 41) in 11 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.181462Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.184124Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: ResultStage 25 (count at NativeMethodAccessorImpl.java:0) finished in 0.022 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.185271Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.185381Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.186025Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Job 17 finished: count at NativeMethodAccessorImpl.java:0, took 0.035235 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.210573Z","level":"info","event":"25/12/28 17:42:56 INFO FileSourceStrategy: Pushed Filters: IsNull(geolocation_lat)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.211083Z","level":"info","event":"25/12/28 17:42:56 INFO FileSourceStrategy: Post-Scan Filters: isnull(geolocation_lat#111)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.224724Z","level":"info","event":"25/12/28 17:42:56 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 199.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.231707Z","level":"info","event":"25/12/28 17:42:56 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.232221Z","level":"info","event":"25/12/28 17:42:56 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.233782Z","level":"info","event":"25/12/28 17:42:56 INFO SparkContext: Created broadcast 30 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.234921Z","level":"info","event":"25/12/28 17:42:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 9352598 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.238038Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Registering RDD 79 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 8","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.238226Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Got map stage job 18 (count at NativeMethodAccessorImpl.java:0) with 7 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.238325Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Final stage: ShuffleMapStage 26 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.238388Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.238440Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.238501Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[79] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.239499Z","level":"info","event":"25/12/28 17:42:56 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 18.4 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.240043Z","level":"info","event":"25/12/28 17:42:56 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.240487Z","level":"info","event":"25/12/28 17:42:56 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.241227Z","level":"info","event":"25/12/28 17:42:56 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.241484Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Submitting 7 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[79] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.241559Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSchedulerImpl: Adding task set 26.0 with 7 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.242389Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 42) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.242495Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 43) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.242595Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Starting task 2.0 in stage 26.0 (TID 44) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.242966Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Starting task 3.0 in stage 26.0 (TID 45) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.244215Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Starting task 4.0 in stage 26.0 (TID 46) (c252dd92c865, executor driver, partition 4, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.244880Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Starting task 5.0 in stage 26.0 (TID 47) (c252dd92c865, executor driver, partition 5, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.244973Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Starting task 6.0 in stage 26.0 (TID 48) (c252dd92c865, executor driver, partition 6, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.245125Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Running task 1.0 in stage 26.0 (TID 43)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.245259Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Running task 3.0 in stage 26.0 (TID 45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.245603Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Running task 5.0 in stage 26.0 (TID 47)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.245689Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Running task 6.0 in stage 26.0 (TID 48)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.245724Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Running task 0.0 in stage 26.0 (TID 42)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.247050Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Running task 4.0 in stage 26.0 (TID 46)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.248550Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Running task 2.0 in stage 26.0 (TID 44)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.253713Z","level":"info","event":"25/12/28 17:42:56 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 9352598-18705196, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.254155Z","level":"info","event":"25/12/28 17:42:56 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 0-9352598, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.254255Z","level":"info","event":"25/12/28 17:42:56 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 37410392-46762990, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.255218Z","level":"info","event":"25/12/28 17:42:56 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 28057794-37410392, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.257834Z","level":"info","event":"25/12/28 17:42:56 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 56115588-61273883, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.258062Z","level":"info","event":"25/12/28 17:42:56 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 18705196-28057794, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.263356Z","level":"info","event":"25/12/28 17:42:56 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 46762990-56115588, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.343468Z","level":"info","event":"25/12/28 17:42:56 INFO BlockManagerInfo: Removed broadcast_29_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.414125Z","level":"info","event":"25/12/28 17:42:56 INFO BlockManagerInfo: Removed broadcast_28_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.458203Z","level":"info","event":"25/12/28 17:42:56 INFO BlockManagerInfo: Removed broadcast_27_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.497963Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Finished task 6.0 in stage 26.0 (TID 48). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.498342Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Finished task 6.0 in stage 26.0 (TID 48) in 250 ms on c252dd92c865 (executor driver) (1/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.521482Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Finished task 1.0 in stage 26.0 (TID 43). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.522510Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 43) in 280 ms on c252dd92c865 (executor driver) (2/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.565363Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Finished task 4.0 in stage 26.0 (TID 46). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.576805Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Finished task 4.0 in stage 26.0 (TID 46) in 333 ms on c252dd92c865 (executor driver) (3/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.591483Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Finished task 0.0 in stage 26.0 (TID 42). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.604469Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 42) in 359 ms on c252dd92c865 (executor driver) (4/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.624113Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Finished task 3.0 in stage 26.0 (TID 45). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.624515Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Finished task 5.0 in stage 26.0 (TID 47). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.628882Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Finished task 5.0 in stage 26.0 (TID 47) in 385 ms on c252dd92c865 (executor driver) (5/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.630566Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Finished task 3.0 in stage 26.0 (TID 45) in 387 ms on c252dd92c865 (executor driver) (6/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.637610Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Finished task 2.0 in stage 26.0 (TID 44). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.642053Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Finished task 2.0 in stage 26.0 (TID 44) in 399 ms on c252dd92c865 (executor driver) (7/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.642916Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.643972Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: ShuffleMapStage 26 (count at NativeMethodAccessorImpl.java:0) finished in 0.405 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.644942Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.644998Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.645025Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.645064Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.681629Z","level":"info","event":"25/12/28 17:42:56 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.685781Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Got job 19 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.685988Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Final stage: ResultStage 28 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.689423Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.689496Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.689701Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[82] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.692132Z","level":"info","event":"25/12/28 17:42:56 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.694579Z","level":"info","event":"25/12/28 17:42:56 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.696940Z","level":"info","event":"25/12/28 17:42:56 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.698522Z","level":"info","event":"25/12/28 17:42:56 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.699303Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[82] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.699454Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.700687Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 49) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.701481Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Running task 0.0 in stage 28.0 (TID 49)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.705120Z","level":"info","event":"25/12/28 17:42:56 INFO ShuffleBlockFetcherIterator: Getting 7 (420.0 B) non-empty blocks including 7 (420.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.705357Z","level":"info","event":"25/12/28 17:42:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.708633Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Finished task 0.0 in stage 28.0 (TID 49). 3988 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.710626Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 49) in 10 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.711591Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.712099Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: ResultStage 28 (count at NativeMethodAccessorImpl.java:0) finished in 0.021 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.712889Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.713111Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.713279Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Job 19 finished: count at NativeMethodAccessorImpl.java:0, took 0.031583 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.763216Z","level":"info","event":"25/12/28 17:42:56 INFO FileSourceStrategy: Pushed Filters: IsNull(geolocation_lng)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.763475Z","level":"info","event":"25/12/28 17:42:56 INFO FileSourceStrategy: Post-Scan Filters: isnull(geolocation_lng#112)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.787093Z","level":"info","event":"25/12/28 17:42:56 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 199.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.799759Z","level":"info","event":"25/12/28 17:42:56 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.800841Z","level":"info","event":"25/12/28 17:42:56 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.801998Z","level":"info","event":"25/12/28 17:42:56 INFO SparkContext: Created broadcast 33 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.803844Z","level":"info","event":"25/12/28 17:42:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 9352598 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.808843Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Registering RDD 86 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 9","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.808949Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Got map stage job 20 (count at NativeMethodAccessorImpl.java:0) with 7 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.808982Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Final stage: ShuffleMapStage 29 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.809007Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.809207Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.809251Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[86] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.812572Z","level":"info","event":"25/12/28 17:42:56 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 18.4 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.814049Z","level":"info","event":"25/12/28 17:42:56 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.814231Z","level":"info","event":"25/12/28 17:42:56 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.816913Z","level":"info","event":"25/12/28 17:42:56 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.817001Z","level":"info","event":"25/12/28 17:42:56 INFO DAGScheduler: Submitting 7 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[86] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.817028Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSchedulerImpl: Adding task set 29.0 with 7 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.817051Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 50) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.817081Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 51) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.817110Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 52) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.817132Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 53) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.817147Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Starting task 4.0 in stage 29.0 (TID 54) (c252dd92c865, executor driver, partition 4, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.817161Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Starting task 5.0 in stage 29.0 (TID 55) (c252dd92c865, executor driver, partition 5, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.817175Z","level":"info","event":"25/12/28 17:42:56 INFO TaskSetManager: Starting task 6.0 in stage 29.0 (TID 56) (c252dd92c865, executor driver, partition 6, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.817194Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Running task 3.0 in stage 29.0 (TID 53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.817209Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Running task 1.0 in stage 29.0 (TID 51)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.817223Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Running task 5.0 in stage 29.0 (TID 55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.817351Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Running task 4.0 in stage 29.0 (TID 54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.817478Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Running task 0.0 in stage 29.0 (TID 50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.817505Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Running task 2.0 in stage 29.0 (TID 52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.817644Z","level":"info","event":"25/12/28 17:42:56 INFO Executor: Running task 6.0 in stage 29.0 (TID 56)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.830682Z","level":"info","event":"25/12/28 17:42:56 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 0-9352598, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.830793Z","level":"info","event":"25/12/28 17:42:56 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 28057794-37410392, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.830814Z","level":"info","event":"25/12/28 17:42:56 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 56115588-61273883, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.830842Z","level":"info","event":"25/12/28 17:42:56 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 18705196-28057794, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.830867Z","level":"info","event":"25/12/28 17:42:56 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 37410392-46762990, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.835147Z","level":"info","event":"25/12/28 17:42:56 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 9352598-18705196, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.850405Z","level":"info","event":"25/12/28 17:42:56 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 46762990-56115588, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.905750Z","level":"info","event":"25/12/28 17:42:56 INFO BlockManagerInfo: Removed broadcast_31_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.944269Z","level":"info","event":"25/12/28 17:42:56 INFO BlockManagerInfo: Removed broadcast_30_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:56.991882Z","level":"info","event":"25/12/28 17:42:56 INFO BlockManagerInfo: Removed broadcast_32_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.225143Z","level":"info","event":"25/12/28 17:42:57 INFO Executor: Finished task 3.0 in stage 29.0 (TID 53). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.230656Z","level":"info","event":"25/12/28 17:42:57 INFO Executor: Finished task 6.0 in stage 29.0 (TID 56). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.233263Z","level":"info","event":"25/12/28 17:42:57 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 53) in 416 ms on c252dd92c865 (executor driver) (1/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.253666Z","level":"info","event":"25/12/28 17:42:57 INFO TaskSetManager: Finished task 6.0 in stage 29.0 (TID 56) in 436 ms on c252dd92c865 (executor driver) (2/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.253934Z","level":"info","event":"25/12/28 17:42:57 INFO Executor: Finished task 0.0 in stage 29.0 (TID 50). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.254611Z","level":"info","event":"25/12/28 17:42:57 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 50) in 439 ms on c252dd92c865 (executor driver) (3/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.415498Z","level":"info","event":"25/12/28 17:42:57 INFO Executor: Finished task 2.0 in stage 29.0 (TID 52). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.415708Z","level":"info","event":"25/12/28 17:42:57 INFO Executor: Finished task 4.0 in stage 29.0 (TID 54). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.419413Z","level":"info","event":"25/12/28 17:42:57 INFO TaskSetManager: Finished task 4.0 in stage 29.0 (TID 54) in 601 ms on c252dd92c865 (executor driver) (4/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.420412Z","level":"info","event":"25/12/28 17:42:57 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 52) in 604 ms on c252dd92c865 (executor driver) (5/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.451053Z","level":"info","event":"25/12/28 17:42:57 INFO Executor: Finished task 1.0 in stage 29.0 (TID 51). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.454472Z","level":"info","event":"25/12/28 17:42:57 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 51) in 639 ms on c252dd92c865 (executor driver) (6/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.458872Z","level":"info","event":"25/12/28 17:42:57 INFO Executor: Finished task 5.0 in stage 29.0 (TID 55). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.460351Z","level":"info","event":"25/12/28 17:42:57 INFO TaskSetManager: Finished task 5.0 in stage 29.0 (TID 55) in 644 ms on c252dd92c865 (executor driver) (7/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.460720Z","level":"info","event":"25/12/28 17:42:57 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.463855Z","level":"info","event":"25/12/28 17:42:57 INFO DAGScheduler: ShuffleMapStage 29 (count at NativeMethodAccessorImpl.java:0) finished in 0.650 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.464367Z","level":"info","event":"25/12/28 17:42:57 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.464839Z","level":"info","event":"25/12/28 17:42:57 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.464933Z","level":"info","event":"25/12/28 17:42:57 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.465019Z","level":"info","event":"25/12/28 17:42:57 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.550090Z","level":"info","event":"25/12/28 17:42:57 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.553874Z","level":"info","event":"25/12/28 17:42:57 INFO DAGScheduler: Got job 21 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.554006Z","level":"info","event":"25/12/28 17:42:57 INFO DAGScheduler: Final stage: ResultStage 31 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.554049Z","level":"info","event":"25/12/28 17:42:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.554102Z","level":"info","event":"25/12/28 17:42:57 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.554560Z","level":"info","event":"25/12/28 17:42:57 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[89] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.557322Z","level":"info","event":"25/12/28 17:42:57 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.558919Z","level":"info","event":"25/12/28 17:42:57 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.559728Z","level":"info","event":"25/12/28 17:42:57 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.560208Z","level":"info","event":"25/12/28 17:42:57 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.560543Z","level":"info","event":"25/12/28 17:42:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[89] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.560602Z","level":"info","event":"25/12/28 17:42:57 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.561990Z","level":"info","event":"25/12/28 17:42:57 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 57) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.562583Z","level":"info","event":"25/12/28 17:42:57 INFO Executor: Running task 0.0 in stage 31.0 (TID 57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.567982Z","level":"info","event":"25/12/28 17:42:57 INFO ShuffleBlockFetcherIterator: Getting 7 (420.0 B) non-empty blocks including 7 (420.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.568253Z","level":"info","event":"25/12/28 17:42:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.571417Z","level":"info","event":"25/12/28 17:42:57 INFO Executor: Finished task 0.0 in stage 31.0 (TID 57). 3988 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.572146Z","level":"info","event":"25/12/28 17:42:57 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 57) in 11 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.572203Z","level":"info","event":"25/12/28 17:42:57 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.572581Z","level":"info","event":"25/12/28 17:42:57 INFO DAGScheduler: ResultStage 31 (count at NativeMethodAccessorImpl.java:0) finished in 0.017 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.572742Z","level":"info","event":"25/12/28 17:42:57 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.572794Z","level":"info","event":"25/12/28 17:42:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.573157Z","level":"info","event":"25/12/28 17:42:57 INFO DAGScheduler: Job 21 finished: count at NativeMethodAccessorImpl.java:0, took 0.022367 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.622805Z","level":"info","event":"25/12/28 17:42:57 INFO FileSourceStrategy: Pushed Filters: IsNull(geolocation_city)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.622950Z","level":"info","event":"25/12/28 17:42:57 INFO FileSourceStrategy: Post-Scan Filters: isnull(geolocation_city#113)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.641865Z","level":"info","event":"25/12/28 17:42:57 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 199.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.654313Z","level":"info","event":"25/12/28 17:42:57 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.654785Z","level":"info","event":"25/12/28 17:42:57 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.655584Z","level":"info","event":"25/12/28 17:42:57 INFO SparkContext: Created broadcast 36 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.657406Z","level":"info","event":"25/12/28 17:42:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 9352598 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.661411Z","level":"info","event":"25/12/28 17:42:57 INFO DAGScheduler: Registering RDD 93 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 10","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.661523Z","level":"info","event":"25/12/28 17:42:57 INFO DAGScheduler: Got map stage job 22 (count at NativeMethodAccessorImpl.java:0) with 7 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.661559Z","level":"info","event":"25/12/28 17:42:57 INFO DAGScheduler: Final stage: ShuffleMapStage 32 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.661592Z","level":"info","event":"25/12/28 17:42:57 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.661628Z","level":"info","event":"25/12/28 17:42:57 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.661903Z","level":"info","event":"25/12/28 17:42:57 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[93] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.663599Z","level":"info","event":"25/12/28 17:42:57 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 18.4 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.666469Z","level":"info","event":"25/12/28 17:42:57 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.667206Z","level":"info","event":"25/12/28 17:42:57 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.668208Z","level":"info","event":"25/12/28 17:42:57 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.669659Z","level":"info","event":"25/12/28 17:42:57 INFO DAGScheduler: Submitting 7 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[93] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.669907Z","level":"info","event":"25/12/28 17:42:57 INFO TaskSchedulerImpl: Adding task set 32.0 with 7 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.672484Z","level":"info","event":"25/12/28 17:42:57 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 58) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.673315Z","level":"info","event":"25/12/28 17:42:57 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 59) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.673517Z","level":"info","event":"25/12/28 17:42:57 INFO TaskSetManager: Starting task 2.0 in stage 32.0 (TID 60) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.674144Z","level":"info","event":"25/12/28 17:42:57 INFO TaskSetManager: Starting task 3.0 in stage 32.0 (TID 61) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.674887Z","level":"info","event":"25/12/28 17:42:57 INFO TaskSetManager: Starting task 4.0 in stage 32.0 (TID 62) (c252dd92c865, executor driver, partition 4, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.678579Z","level":"info","event":"25/12/28 17:42:57 INFO TaskSetManager: Starting task 5.0 in stage 32.0 (TID 63) (c252dd92c865, executor driver, partition 5, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.678694Z","level":"info","event":"25/12/28 17:42:57 INFO TaskSetManager: Starting task 6.0 in stage 32.0 (TID 64) (c252dd92c865, executor driver, partition 6, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.678726Z","level":"info","event":"25/12/28 17:42:57 INFO Executor: Running task 6.0 in stage 32.0 (TID 64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.678742Z","level":"info","event":"25/12/28 17:42:57 INFO Executor: Running task 5.0 in stage 32.0 (TID 63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.678757Z","level":"info","event":"25/12/28 17:42:57 INFO Executor: Running task 3.0 in stage 32.0 (TID 61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.678786Z","level":"info","event":"25/12/28 17:42:57 INFO Executor: Running task 4.0 in stage 32.0 (TID 62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.678815Z","level":"info","event":"25/12/28 17:42:57 INFO Executor: Running task 2.0 in stage 32.0 (TID 60)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.678856Z","level":"info","event":"25/12/28 17:42:57 INFO Executor: Running task 1.0 in stage 32.0 (TID 59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.684524Z","level":"info","event":"25/12/28 17:42:57 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 37410392-46762990, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.684607Z","level":"info","event":"25/12/28 17:42:57 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 56115588-61273883, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.684635Z","level":"info","event":"25/12/28 17:42:57 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 46762990-56115588, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.687640Z","level":"info","event":"25/12/28 17:42:57 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 9352598-18705196, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.693873Z","level":"info","event":"25/12/28 17:42:57 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 28057794-37410392, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.694006Z","level":"info","event":"25/12/28 17:42:57 INFO Executor: Running task 0.0 in stage 32.0 (TID 58)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.694041Z","level":"info","event":"25/12/28 17:42:57 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 18705196-28057794, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.701793Z","level":"info","event":"25/12/28 17:42:57 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 0-9352598, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.742728Z","level":"info","event":"25/12/28 17:42:57 INFO BlockManagerInfo: Removed broadcast_34_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.753773Z","level":"info","event":"25/12/28 17:42:57 INFO BlockManagerInfo: Removed broadcast_33_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.791375Z","level":"info","event":"25/12/28 17:42:57 INFO BlockManagerInfo: Removed broadcast_35_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.901591Z","level":"info","event":"25/12/28 17:42:57 INFO Executor: Finished task 6.0 in stage 32.0 (TID 64). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:57.915377Z","level":"info","event":"25/12/28 17:42:57 INFO TaskSetManager: Finished task 6.0 in stage 32.0 (TID 64) in 231 ms on c252dd92c865 (executor driver) (1/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.087039Z","level":"info","event":"25/12/28 17:42:58 INFO Executor: Finished task 0.0 in stage 32.0 (TID 58). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.103987Z","level":"info","event":"25/12/28 17:42:58 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 58) in 432 ms on c252dd92c865 (executor driver) (2/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.128090Z","level":"info","event":"25/12/28 17:42:58 INFO Executor: Finished task 2.0 in stage 32.0 (TID 60). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.131613Z","level":"info","event":"25/12/28 17:42:58 INFO TaskSetManager: Finished task 2.0 in stage 32.0 (TID 60) in 457 ms on c252dd92c865 (executor driver) (3/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.149019Z","level":"info","event":"25/12/28 17:42:58 INFO Executor: Finished task 4.0 in stage 32.0 (TID 62). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.154557Z","level":"info","event":"25/12/28 17:42:58 INFO TaskSetManager: Finished task 4.0 in stage 32.0 (TID 62) in 477 ms on c252dd92c865 (executor driver) (4/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.175674Z","level":"info","event":"25/12/28 17:42:58 INFO Executor: Finished task 1.0 in stage 32.0 (TID 59). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.180419Z","level":"info","event":"25/12/28 17:42:58 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 59) in 507 ms on c252dd92c865 (executor driver) (5/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.189548Z","level":"info","event":"25/12/28 17:42:58 INFO Executor: Finished task 5.0 in stage 32.0 (TID 63). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.190419Z","level":"info","event":"25/12/28 17:42:58 INFO Executor: Finished task 3.0 in stage 32.0 (TID 61). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.190788Z","level":"info","event":"25/12/28 17:42:58 INFO TaskSetManager: Finished task 5.0 in stage 32.0 (TID 63) in 516 ms on c252dd92c865 (executor driver) (6/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.191779Z","level":"info","event":"25/12/28 17:42:58 INFO TaskSetManager: Finished task 3.0 in stage 32.0 (TID 61) in 518 ms on c252dd92c865 (executor driver) (7/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.191860Z","level":"info","event":"25/12/28 17:42:58 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.194350Z","level":"info","event":"25/12/28 17:42:58 INFO DAGScheduler: ShuffleMapStage 32 (count at NativeMethodAccessorImpl.java:0) finished in 0.530 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.194653Z","level":"info","event":"25/12/28 17:42:58 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.197416Z","level":"info","event":"25/12/28 17:42:58 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.197731Z","level":"info","event":"25/12/28 17:42:58 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.197986Z","level":"info","event":"25/12/28 17:42:58 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.302493Z","level":"info","event":"25/12/28 17:42:58 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.314873Z","level":"info","event":"25/12/28 17:42:58 INFO DAGScheduler: Got job 23 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.315459Z","level":"info","event":"25/12/28 17:42:58 INFO DAGScheduler: Final stage: ResultStage 34 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.315560Z","level":"info","event":"25/12/28 17:42:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.318144Z","level":"info","event":"25/12/28 17:42:58 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.318935Z","level":"info","event":"25/12/28 17:42:58 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[96] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.325896Z","level":"info","event":"25/12/28 17:42:58 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.334649Z","level":"info","event":"25/12/28 17:42:58 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.347596Z","level":"info","event":"25/12/28 17:42:58 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.349385Z","level":"info","event":"25/12/28 17:42:58 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.349711Z","level":"info","event":"25/12/28 17:42:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[96] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.349877Z","level":"info","event":"25/12/28 17:42:58 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.356332Z","level":"info","event":"25/12/28 17:42:58 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 65) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.357644Z","level":"info","event":"25/12/28 17:42:58 INFO Executor: Running task 0.0 in stage 34.0 (TID 65)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.372041Z","level":"info","event":"25/12/28 17:42:58 INFO ShuffleBlockFetcherIterator: Getting 7 (420.0 B) non-empty blocks including 7 (420.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.372461Z","level":"info","event":"25/12/28 17:42:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.377265Z","level":"info","event":"25/12/28 17:42:58 INFO Executor: Finished task 0.0 in stage 34.0 (TID 65). 3988 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.379762Z","level":"info","event":"25/12/28 17:42:58 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 65) in 25 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.380135Z","level":"info","event":"25/12/28 17:42:58 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.381267Z","level":"info","event":"25/12/28 17:42:58 INFO DAGScheduler: ResultStage 34 (count at NativeMethodAccessorImpl.java:0) finished in 0.062 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.382063Z","level":"info","event":"25/12/28 17:42:58 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.382234Z","level":"info","event":"25/12/28 17:42:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.382351Z","level":"info","event":"25/12/28 17:42:58 INFO DAGScheduler: Job 23 finished: count at NativeMethodAccessorImpl.java:0, took 0.075250 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.662408Z","level":"info","event":"25/12/28 17:42:58 INFO FileSourceStrategy: Pushed Filters: IsNull(geolocation_state)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.663013Z","level":"info","event":"25/12/28 17:42:58 INFO FileSourceStrategy: Post-Scan Filters: isnull(geolocation_state#114)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.706889Z","level":"info","event":"25/12/28 17:42:58 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 199.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.753759Z","level":"info","event":"25/12/28 17:42:58 INFO BlockManagerInfo: Removed broadcast_36_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.761515Z","level":"info","event":"25/12/28 17:42:58 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.761866Z","level":"info","event":"25/12/28 17:42:58 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.764072Z","level":"info","event":"25/12/28 17:42:58 INFO SparkContext: Created broadcast 39 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.765139Z","level":"info","event":"25/12/28 17:42:58 INFO BlockManagerInfo: Removed broadcast_37_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.771612Z","level":"info","event":"25/12/28 17:42:58 INFO FileSourceScanExec: Planning scan with bin packing, max size: 9352598 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.775548Z","level":"info","event":"25/12/28 17:42:58 INFO BlockManagerInfo: Removed broadcast_38_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.791674Z","level":"info","event":"25/12/28 17:42:58 INFO DAGScheduler: Registering RDD 100 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 11","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.791914Z","level":"info","event":"25/12/28 17:42:58 INFO DAGScheduler: Got map stage job 24 (count at NativeMethodAccessorImpl.java:0) with 7 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.791974Z","level":"info","event":"25/12/28 17:42:58 INFO DAGScheduler: Final stage: ShuffleMapStage 35 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.792015Z","level":"info","event":"25/12/28 17:42:58 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.792047Z","level":"info","event":"25/12/28 17:42:58 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.792081Z","level":"info","event":"25/12/28 17:42:58 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[100] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.818147Z","level":"info","event":"25/12/28 17:42:58 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 18.4 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.830009Z","level":"info","event":"25/12/28 17:42:58 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.830189Z","level":"info","event":"25/12/28 17:42:58 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.834185Z","level":"info","event":"25/12/28 17:42:58 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.837989Z","level":"info","event":"25/12/28 17:42:58 INFO DAGScheduler: Submitting 7 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[100] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.838259Z","level":"info","event":"25/12/28 17:42:58 INFO TaskSchedulerImpl: Adding task set 35.0 with 7 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.840990Z","level":"info","event":"25/12/28 17:42:58 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 66) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.841383Z","level":"info","event":"25/12/28 17:42:58 INFO TaskSetManager: Starting task 1.0 in stage 35.0 (TID 67) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.841918Z","level":"info","event":"25/12/28 17:42:58 INFO TaskSetManager: Starting task 2.0 in stage 35.0 (TID 68) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.842208Z","level":"info","event":"25/12/28 17:42:58 INFO TaskSetManager: Starting task 3.0 in stage 35.0 (TID 69) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.842942Z","level":"info","event":"25/12/28 17:42:58 INFO TaskSetManager: Starting task 4.0 in stage 35.0 (TID 70) (c252dd92c865, executor driver, partition 4, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.842980Z","level":"info","event":"25/12/28 17:42:58 INFO TaskSetManager: Starting task 5.0 in stage 35.0 (TID 71) (c252dd92c865, executor driver, partition 5, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.843007Z","level":"info","event":"25/12/28 17:42:58 INFO TaskSetManager: Starting task 6.0 in stage 35.0 (TID 72) (c252dd92c865, executor driver, partition 6, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.843674Z","level":"info","event":"25/12/28 17:42:58 INFO Executor: Running task 0.0 in stage 35.0 (TID 66)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.844703Z","level":"info","event":"25/12/28 17:42:58 INFO Executor: Running task 3.0 in stage 35.0 (TID 69)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.850457Z","level":"info","event":"25/12/28 17:42:58 INFO Executor: Running task 6.0 in stage 35.0 (TID 72)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.850697Z","level":"info","event":"25/12/28 17:42:58 INFO Executor: Running task 1.0 in stage 35.0 (TID 67)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.850775Z","level":"info","event":"25/12/28 17:42:58 INFO Executor: Running task 2.0 in stage 35.0 (TID 68)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.850810Z","level":"info","event":"25/12/28 17:42:58 INFO Executor: Running task 5.0 in stage 35.0 (TID 71)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.850936Z","level":"info","event":"25/12/28 17:42:58 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 9352598-18705196, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.851123Z","level":"info","event":"25/12/28 17:42:58 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 56115588-61273883, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.851968Z","level":"info","event":"25/12/28 17:42:58 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 28057794-37410392, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.856457Z","level":"info","event":"25/12/28 17:42:58 INFO Executor: Running task 4.0 in stage 35.0 (TID 70)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.856668Z","level":"info","event":"25/12/28 17:42:58 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 18705196-28057794, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.856856Z","level":"info","event":"25/12/28 17:42:58 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 37410392-46762990, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.859702Z","level":"info","event":"25/12/28 17:42:58 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 0-9352598, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:58.864009Z","level":"info","event":"25/12/28 17:42:58 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 46762990-56115588, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:59.831805Z","level":"info","event":"25/12/28 17:42:59 INFO Executor: Finished task 2.0 in stage 35.0 (TID 68). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:59.838809Z","level":"info","event":"25/12/28 17:42:59 INFO Executor: Finished task 0.0 in stage 35.0 (TID 66). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:59.838987Z","level":"info","event":"25/12/28 17:42:59 INFO Executor: Finished task 6.0 in stage 35.0 (TID 72). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:59.839243Z","level":"info","event":"25/12/28 17:42:59 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 66) in 982 ms on c252dd92c865 (executor driver) (1/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:59.839662Z","level":"info","event":"25/12/28 17:42:59 INFO TaskSetManager: Finished task 6.0 in stage 35.0 (TID 72) in 980 ms on c252dd92c865 (executor driver) (2/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:59.839858Z","level":"info","event":"25/12/28 17:42:59 INFO TaskSetManager: Finished task 2.0 in stage 35.0 (TID 68) in 982 ms on c252dd92c865 (executor driver) (3/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:59.839932Z","level":"info","event":"25/12/28 17:42:59 INFO Executor: Finished task 1.0 in stage 35.0 (TID 67). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:59.839979Z","level":"info","event":"25/12/28 17:42:59 INFO TaskSetManager: Finished task 1.0 in stage 35.0 (TID 67) in 991 ms on c252dd92c865 (executor driver) (4/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:59.956547Z","level":"info","event":"25/12/28 17:42:59 INFO Executor: Finished task 4.0 in stage 35.0 (TID 70). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:42:59.958524Z","level":"info","event":"25/12/28 17:42:59 INFO TaskSetManager: Finished task 4.0 in stage 35.0 (TID 70) in 1116 ms on c252dd92c865 (executor driver) (5/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.314799Z","level":"info","event":"25/12/28 17:43:00 INFO Executor: Finished task 5.0 in stage 35.0 (TID 71). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.327882Z","level":"info","event":"25/12/28 17:43:00 INFO Executor: Finished task 3.0 in stage 35.0 (TID 69). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.329777Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSetManager: Finished task 5.0 in stage 35.0 (TID 71) in 1485 ms on c252dd92c865 (executor driver) (6/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.330166Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSetManager: Finished task 3.0 in stage 35.0 (TID 69) in 1487 ms on c252dd92c865 (executor driver) (7/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.330357Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.334888Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: ShuffleMapStage 35 (count at NativeMethodAccessorImpl.java:0) finished in 1.531 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.335244Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.335429Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.335542Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.335631Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.433802Z","level":"info","event":"25/12/28 17:43:00 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.437013Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Got job 25 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.437245Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Final stage: ResultStage 37 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.437394Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.437588Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.438824Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[103] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.444821Z","level":"info","event":"25/12/28 17:43:00 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.457803Z","level":"info","event":"25/12/28 17:43:00 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.460722Z","level":"info","event":"25/12/28 17:43:00 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.462782Z","level":"info","event":"25/12/28 17:43:00 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.464269Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[103] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.464598Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.467674Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 73) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.468388Z","level":"info","event":"25/12/28 17:43:00 INFO Executor: Running task 0.0 in stage 37.0 (TID 73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.483603Z","level":"info","event":"25/12/28 17:43:00 INFO ShuffleBlockFetcherIterator: Getting 7 (420.0 B) non-empty blocks including 7 (420.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.483898Z","level":"info","event":"25/12/28 17:43:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.488195Z","level":"info","event":"25/12/28 17:43:00 INFO Executor: Finished task 0.0 in stage 37.0 (TID 73). 3988 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.489261Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 73) in 22 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.489426Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.489909Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: ResultStage 37 (count at NativeMethodAccessorImpl.java:0) finished in 0.049 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.490251Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.490524Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.490724Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Job 25 finished: count at NativeMethodAccessorImpl.java:0, took 0.056711 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.524330Z","level":"info","event":"25/12/28 17:43:00 INFO InMemoryFileIndex: It took 9 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.535618Z","level":"info","event":"25/12/28 17:43:00 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.665697Z","level":"info","event":"25/12/28 17:43:00 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.666953Z","level":"info","event":"25/12/28 17:43:00 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#186, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.680422Z","level":"info","event":"25/12/28 17:43:00 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 199.3 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.693266Z","level":"info","event":"25/12/28 17:43:00 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.693649Z","level":"info","event":"25/12/28 17:43:00 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on c252dd92c865:35057 (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.694245Z","level":"info","event":"25/12/28 17:43:00 INFO SparkContext: Created broadcast 42 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.695181Z","level":"info","event":"25/12/28 17:43:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.708662Z","level":"info","event":"25/12/28 17:43:00 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.709317Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Got job 26 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.709374Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Final stage: ResultStage 38 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.710344Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.710427Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.710467Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[107] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.713729Z","level":"info","event":"25/12/28 17:43:00 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 13.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.716731Z","level":"info","event":"25/12/28 17:43:00 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.723643Z","level":"info","event":"25/12/28 17:43:00 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on c252dd92c865:35057 (size: 6.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.724082Z","level":"info","event":"25/12/28 17:43:00 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.724278Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[107] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.724343Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.725768Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 74) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8293 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.727354Z","level":"info","event":"25/12/28 17:43:00 INFO Executor: Running task 0.0 in stage 38.0 (TID 74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.733136Z","level":"info","event":"25/12/28 17:43:00 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.739776Z","level":"info","event":"25/12/28 17:43:00 INFO Executor: Finished task 0.0 in stage 38.0 (TID 74). 1656 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.741498Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 74) in 16 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.741643Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.743742Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: ResultStage 38 (csv at NativeMethodAccessorImpl.java:0) finished in 0.032 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.743962Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.744038Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.744513Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Job 26 finished: csv at NativeMethodAccessorImpl.java:0, took 0.035715 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.759052Z","level":"info","event":"25/12/28 17:43:00 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.759159Z","level":"info","event":"25/12/28 17:43:00 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.765653Z","level":"info","event":"25/12/28 17:43:00 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 199.3 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.775728Z","level":"info","event":"25/12/28 17:43:00 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.776949Z","level":"info","event":"25/12/28 17:43:00 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on c252dd92c865:35057 (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.778142Z","level":"info","event":"25/12/28 17:43:00 INFO SparkContext: Created broadcast 44 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.778718Z","level":"info","event":"25/12/28 17:43:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.795156Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.805610Z","level":"info","event":"25/12/28 17:43:00 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.805881Z","level":"info","event":"25/12/28 17:43:00 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.813585Z","level":"info","event":"25/12/28 17:43:00 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 199.2 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.826692Z","level":"info","event":"25/12/28 17:43:00 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.827216Z","level":"info","event":"25/12/28 17:43:00 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.828234Z","level":"info","event":"25/12/28 17:43:00 INFO SparkContext: Created broadcast 45 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.829697Z","level":"info","event":"25/12/28 17:43:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.835587Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Registering RDD 117 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 12","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.835823Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Got map stage job 27 (count at NativeMethodAccessorImpl.java:0) with 4 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.835904Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Final stage: ShuffleMapStage 39 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.835990Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.836068Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.836137Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[117] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.838260Z","level":"info","event":"25/12/28 17:43:00 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 17.8 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.839647Z","level":"info","event":"25/12/28 17:43:00 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.840309Z","level":"info","event":"25/12/28 17:43:00 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on c252dd92c865:35057 (size: 8.8 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.840811Z","level":"info","event":"25/12/28 17:43:00 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.841142Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[117] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.841184Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSchedulerImpl: Adding task set 39.0 with 4 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.842066Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 75) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.842336Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 76) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.842477Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSetManager: Starting task 2.0 in stage 39.0 (TID 77) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.842564Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSetManager: Starting task 3.0 in stage 39.0 (TID 78) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.842860Z","level":"info","event":"25/12/28 17:43:00 INFO Executor: Running task 0.0 in stage 39.0 (TID 75)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.843196Z","level":"info","event":"25/12/28 17:43:00 INFO Executor: Running task 2.0 in stage 39.0 (TID 77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.843755Z","level":"info","event":"25/12/28 17:43:00 INFO Executor: Running task 3.0 in stage 39.0 (TID 78)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.843876Z","level":"info","event":"25/12/28 17:43:00 INFO Executor: Running task 1.0 in stage 39.0 (TID 76)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.846051Z","level":"info","event":"25/12/28 17:43:00 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.846500Z","level":"info","event":"25/12/28 17:43:00 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 12582912-15438671, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.851353Z","level":"info","event":"25/12/28 17:43:00 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.851462Z","level":"info","event":"25/12/28 17:43:00 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.883223Z","level":"info","event":"25/12/28 17:43:00 INFO Executor: Finished task 0.0 in stage 39.0 (TID 75). 1928 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.884152Z","level":"info","event":"25/12/28 17:43:00 INFO Executor: Finished task 3.0 in stage 39.0 (TID 78). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.885260Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 75) in 44 ms on c252dd92c865 (executor driver) (1/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.888248Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSetManager: Finished task 3.0 in stage 39.0 (TID 78) in 43 ms on c252dd92c865 (executor driver) (2/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.888391Z","level":"info","event":"25/12/28 17:43:00 INFO Executor: Finished task 1.0 in stage 39.0 (TID 76). 1928 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.888434Z","level":"info","event":"25/12/28 17:43:00 INFO Executor: Finished task 2.0 in stage 39.0 (TID 77). 1928 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.889539Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 76) in 47 ms on c252dd92c865 (executor driver) (3/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.889843Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSetManager: Finished task 2.0 in stage 39.0 (TID 77) in 47 ms on c252dd92c865 (executor driver) (4/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.889880Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.890438Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: ShuffleMapStage 39 (count at NativeMethodAccessorImpl.java:0) finished in 0.054 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.890529Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.890561Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.890582Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.890762Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.907931Z","level":"info","event":"25/12/28 17:43:00 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.908636Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Got job 28 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.908765Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Final stage: ResultStage 41 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.908840Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 40)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.908920Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.909033Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[120] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.912860Z","level":"info","event":"25/12/28 17:43:00 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 12.5 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.924509Z","level":"info","event":"25/12/28 17:43:00 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.925207Z","level":"info","event":"25/12/28 17:43:00 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.925653Z","level":"info","event":"25/12/28 17:43:00 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.926649Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[120] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.927127Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.928705Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 79) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.929641Z","level":"info","event":"25/12/28 17:43:00 INFO Executor: Running task 0.0 in stage 41.0 (TID 79)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.938178Z","level":"info","event":"25/12/28 17:43:00 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.940231Z","level":"info","event":"25/12/28 17:43:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.959542Z","level":"info","event":"25/12/28 17:43:00 INFO Executor: Finished task 0.0 in stage 41.0 (TID 79). 4038 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.975253Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 79) in 46 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:00.981721Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.010416Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: ResultStage 41 (count at NativeMethodAccessorImpl.java:0) finished in 0.073 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.010601Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.010634Z","level":"info","event":"25/12/28 17:43:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.010691Z","level":"info","event":"25/12/28 17:43:00 INFO DAGScheduler: Job 28 finished: count at NativeMethodAccessorImpl.java:0, took 0.075650 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.010725Z","level":"info","event":"Loaded olist_order_items with 112650 records.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.142948Z","level":"info","event":"25/12/28 17:43:01 INFO FileSourceStrategy: Pushed Filters: IsNull(order_id)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.145474Z","level":"info","event":"25/12/28 17:43:01 INFO FileSourceStrategy: Post-Scan Filters: isnull(order_id#203)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.167686Z","level":"info","event":"25/12/28 17:43:01 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 199.2 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.181002Z","level":"info","event":"25/12/28 17:43:01 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.181879Z","level":"info","event":"25/12/28 17:43:01 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.183014Z","level":"info","event":"25/12/28 17:43:01 INFO SparkContext: Created broadcast 48 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.184634Z","level":"info","event":"25/12/28 17:43:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.189797Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Registering RDD 124 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 13","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.190027Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Got map stage job 29 (count at NativeMethodAccessorImpl.java:0) with 4 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.190112Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Final stage: ShuffleMapStage 42 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.190197Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.190316Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.190410Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[124] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.192082Z","level":"info","event":"25/12/28 17:43:01 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 18.4 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.194314Z","level":"info","event":"25/12/28 17:43:01 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.194623Z","level":"info","event":"25/12/28 17:43:01 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.194944Z","level":"info","event":"25/12/28 17:43:01 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.195273Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[124] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.195341Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSchedulerImpl: Adding task set 42.0 with 4 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.196552Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 80) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.196711Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSetManager: Starting task 1.0 in stage 42.0 (TID 81) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.196793Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSetManager: Starting task 2.0 in stage 42.0 (TID 82) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.196875Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSetManager: Starting task 3.0 in stage 42.0 (TID 83) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.197831Z","level":"info","event":"25/12/28 17:43:01 INFO Executor: Running task 3.0 in stage 42.0 (TID 83)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.197905Z","level":"info","event":"25/12/28 17:43:01 INFO Executor: Running task 2.0 in stage 42.0 (TID 82)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.197953Z","level":"info","event":"25/12/28 17:43:01 INFO Executor: Running task 0.0 in stage 42.0 (TID 80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.197984Z","level":"info","event":"25/12/28 17:43:01 INFO Executor: Running task 1.0 in stage 42.0 (TID 81)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.202998Z","level":"info","event":"25/12/28 17:43:01 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.203210Z","level":"info","event":"25/12/28 17:43:01 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.203328Z","level":"info","event":"25/12/28 17:43:01 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.204353Z","level":"info","event":"25/12/28 17:43:01 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 12582912-15438671, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.440699Z","level":"info","event":"25/12/28 17:43:01 INFO Executor: Finished task 3.0 in stage 42.0 (TID 83). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.461601Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSetManager: Finished task 3.0 in stage 42.0 (TID 83) in 261 ms on c252dd92c865 (executor driver) (1/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.462865Z","level":"info","event":"25/12/28 17:43:01 INFO Executor: Finished task 1.0 in stage 42.0 (TID 81). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.466604Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSetManager: Finished task 1.0 in stage 42.0 (TID 81) in 270 ms on c252dd92c865 (executor driver) (2/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.487161Z","level":"info","event":"25/12/28 17:43:01 INFO Executor: Finished task 2.0 in stage 42.0 (TID 82). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.487577Z","level":"info","event":"25/12/28 17:43:01 INFO Executor: Finished task 0.0 in stage 42.0 (TID 80). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.489391Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSetManager: Finished task 2.0 in stage 42.0 (TID 82) in 293 ms on c252dd92c865 (executor driver) (3/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.489939Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 80) in 293 ms on c252dd92c865 (executor driver) (4/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.490222Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.493712Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: ShuffleMapStage 42 (count at NativeMethodAccessorImpl.java:0) finished in 0.301 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.494474Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.494607Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.494694Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.494723Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.545210Z","level":"info","event":"25/12/28 17:43:01 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.546442Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Got job 30 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.546589Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Final stage: ResultStage 44 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.546670Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.546712Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.548028Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[127] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.554019Z","level":"info","event":"25/12/28 17:43:01 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 12.5 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.559118Z","level":"info","event":"25/12/28 17:43:01 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.559604Z","level":"info","event":"25/12/28 17:43:01 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.560093Z","level":"info","event":"25/12/28 17:43:01 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.560400Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[127] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.560463Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.562068Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 84) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.563122Z","level":"info","event":"25/12/28 17:43:01 INFO Executor: Running task 0.0 in stage 44.0 (TID 84)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.567593Z","level":"info","event":"25/12/28 17:43:01 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.567878Z","level":"info","event":"25/12/28 17:43:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.572633Z","level":"info","event":"25/12/28 17:43:01 INFO Executor: Finished task 0.0 in stage 44.0 (TID 84). 3988 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.573369Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 84) in 12 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.573491Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.574160Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: ResultStage 44 (count at NativeMethodAccessorImpl.java:0) finished in 0.023 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.574446Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.574887Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.576452Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Job 30 finished: count at NativeMethodAccessorImpl.java:0, took 0.030609 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.631033Z","level":"info","event":"25/12/28 17:43:01 INFO FileSourceStrategy: Pushed Filters: IsNull(order_item_id)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.631362Z","level":"info","event":"25/12/28 17:43:01 INFO FileSourceStrategy: Post-Scan Filters: isnull(order_item_id#204)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.658597Z","level":"info","event":"25/12/28 17:43:01 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 199.2 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.666531Z","level":"info","event":"25/12/28 17:43:01 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.667234Z","level":"info","event":"25/12/28 17:43:01 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.668149Z","level":"info","event":"25/12/28 17:43:01 INFO SparkContext: Created broadcast 51 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.670917Z","level":"info","event":"25/12/28 17:43:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.693892Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Registering RDD 131 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 14","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.694221Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Got map stage job 31 (count at NativeMethodAccessorImpl.java:0) with 4 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.694381Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Final stage: ShuffleMapStage 45 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.694516Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.694605Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.694848Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[131] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.698430Z","level":"info","event":"25/12/28 17:43:01 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 18.4 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.701059Z","level":"info","event":"25/12/28 17:43:01 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.701434Z","level":"info","event":"25/12/28 17:43:01 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.702003Z","level":"info","event":"25/12/28 17:43:01 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.702926Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[131] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.703195Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSchedulerImpl: Adding task set 45.0 with 4 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.705379Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 85) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.706081Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 86) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.707097Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSetManager: Starting task 2.0 in stage 45.0 (TID 87) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.707967Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSetManager: Starting task 3.0 in stage 45.0 (TID 88) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.711420Z","level":"info","event":"25/12/28 17:43:01 INFO Executor: Running task 1.0 in stage 45.0 (TID 86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.711513Z","level":"info","event":"25/12/28 17:43:01 INFO Executor: Running task 2.0 in stage 45.0 (TID 87)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.711545Z","level":"info","event":"25/12/28 17:43:01 INFO Executor: Running task 0.0 in stage 45.0 (TID 85)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.711581Z","level":"info","event":"25/12/28 17:43:01 INFO Executor: Running task 3.0 in stage 45.0 (TID 88)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.718005Z","level":"info","event":"25/12/28 17:43:01 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.718808Z","level":"info","event":"25/12/28 17:43:01 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.721108Z","level":"info","event":"25/12/28 17:43:01 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 12582912-15438671, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.722213Z","level":"info","event":"25/12/28 17:43:01 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.847789Z","level":"info","event":"25/12/28 17:43:01 INFO BlockManagerInfo: Removed broadcast_47_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.851325Z","level":"info","event":"25/12/28 17:43:01 INFO BlockManagerInfo: Removed broadcast_50_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.860793Z","level":"info","event":"25/12/28 17:43:01 INFO Executor: Finished task 3.0 in stage 45.0 (TID 88). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.862836Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSetManager: Finished task 3.0 in stage 45.0 (TID 88) in 155 ms on c252dd92c865 (executor driver) (1/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.866611Z","level":"info","event":"25/12/28 17:43:01 INFO BlockManagerInfo: Removed broadcast_41_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.873746Z","level":"info","event":"25/12/28 17:43:01 INFO Executor: Finished task 1.0 in stage 45.0 (TID 86). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.873878Z","level":"info","event":"25/12/28 17:43:01 INFO Executor: Finished task 0.0 in stage 45.0 (TID 85). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.873909Z","level":"info","event":"25/12/28 17:43:01 INFO BlockManagerInfo: Removed broadcast_39_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.874551Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 86) in 169 ms on c252dd92c865 (executor driver) (2/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.875486Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 85) in 171 ms on c252dd92c865 (executor driver) (3/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.875679Z","level":"info","event":"25/12/28 17:43:01 INFO BlockManagerInfo: Removed broadcast_44_piece0 on c252dd92c865:35057 in memory (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.876214Z","level":"info","event":"25/12/28 17:43:01 INFO Executor: Finished task 2.0 in stage 45.0 (TID 87). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.877166Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSetManager: Finished task 2.0 in stage 45.0 (TID 87) in 171 ms on c252dd92c865 (executor driver) (4/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.877220Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.877512Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: ShuffleMapStage 45 (count at NativeMethodAccessorImpl.java:0) finished in 0.181 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.877547Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.877573Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.877609Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.877628Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.877853Z","level":"info","event":"25/12/28 17:43:01 INFO BlockManagerInfo: Removed broadcast_43_piece0 on c252dd92c865:35057 in memory (size: 6.4 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.882190Z","level":"info","event":"25/12/28 17:43:01 INFO BlockManagerInfo: Removed broadcast_46_piece0 on c252dd92c865:35057 in memory (size: 8.8 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.885696Z","level":"info","event":"25/12/28 17:43:01 INFO BlockManagerInfo: Removed broadcast_49_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.891072Z","level":"info","event":"25/12/28 17:43:01 INFO BlockManagerInfo: Removed broadcast_42_piece0 on c252dd92c865:35057 in memory (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.895369Z","level":"info","event":"25/12/28 17:43:01 INFO BlockManagerInfo: Removed broadcast_45_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.898121Z","level":"info","event":"25/12/28 17:43:01 INFO BlockManagerInfo: Removed broadcast_40_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.902048Z","level":"info","event":"25/12/28 17:43:01 INFO BlockManagerInfo: Removed broadcast_48_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.904892Z","level":"info","event":"25/12/28 17:43:01 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.905615Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Got job 32 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.905678Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Final stage: ResultStage 47 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.905707Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.906002Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.906239Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[134] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.907477Z","level":"info","event":"25/12/28 17:43:01 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.908919Z","level":"info","event":"25/12/28 17:43:01 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.909175Z","level":"info","event":"25/12/28 17:43:01 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.910008Z","level":"info","event":"25/12/28 17:43:01 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.910366Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[134] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.910423Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.911499Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 89) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.912066Z","level":"info","event":"25/12/28 17:43:01 INFO Executor: Running task 0.0 in stage 47.0 (TID 89)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.916244Z","level":"info","event":"25/12/28 17:43:01 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.916405Z","level":"info","event":"25/12/28 17:43:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.921616Z","level":"info","event":"25/12/28 17:43:01 INFO Executor: Finished task 0.0 in stage 47.0 (TID 89). 4031 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.923439Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 89) in 12 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.923563Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.924062Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: ResultStage 47 (count at NativeMethodAccessorImpl.java:0) finished in 0.017 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.924217Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.924347Z","level":"info","event":"25/12/28 17:43:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:01.924399Z","level":"info","event":"25/12/28 17:43:01 INFO DAGScheduler: Job 32 finished: count at NativeMethodAccessorImpl.java:0, took 0.019339 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.072238Z","level":"info","event":"25/12/28 17:43:02 INFO FileSourceStrategy: Pushed Filters: IsNull(product_id)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.074050Z","level":"info","event":"25/12/28 17:43:02 INFO FileSourceStrategy: Post-Scan Filters: isnull(product_id#205)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.109858Z","level":"info","event":"25/12/28 17:43:02 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 199.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.120513Z","level":"info","event":"25/12/28 17:43:02 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.121259Z","level":"info","event":"25/12/28 17:43:02 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.123783Z","level":"info","event":"25/12/28 17:43:02 INFO SparkContext: Created broadcast 54 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.126676Z","level":"info","event":"25/12/28 17:43:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.134669Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Registering RDD 138 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 15","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.135000Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Got map stage job 33 (count at NativeMethodAccessorImpl.java:0) with 4 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.135155Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Final stage: ShuffleMapStage 48 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.135207Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.135246Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.135445Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Submitting ShuffleMapStage 48 (MapPartitionsRDD[138] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.142110Z","level":"info","event":"25/12/28 17:43:02 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 18.4 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.144097Z","level":"info","event":"25/12/28 17:43:02 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.145278Z","level":"info","event":"25/12/28 17:43:02 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.147154Z","level":"info","event":"25/12/28 17:43:02 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.149187Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[138] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.149268Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSchedulerImpl: Adding task set 48.0 with 4 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.151390Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 90) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.153517Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSetManager: Starting task 1.0 in stage 48.0 (TID 91) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.153745Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSetManager: Starting task 2.0 in stage 48.0 (TID 92) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.153848Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSetManager: Starting task 3.0 in stage 48.0 (TID 93) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.154894Z","level":"info","event":"25/12/28 17:43:02 INFO Executor: Running task 0.0 in stage 48.0 (TID 90)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.157075Z","level":"info","event":"25/12/28 17:43:02 INFO Executor: Running task 3.0 in stage 48.0 (TID 93)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.157342Z","level":"info","event":"25/12/28 17:43:02 INFO Executor: Running task 2.0 in stage 48.0 (TID 92)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.159065Z","level":"info","event":"25/12/28 17:43:02 INFO Executor: Running task 1.0 in stage 48.0 (TID 91)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.159449Z","level":"info","event":"25/12/28 17:43:02 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.159616Z","level":"info","event":"25/12/28 17:43:02 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 12582912-15438671, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.160020Z","level":"info","event":"25/12/28 17:43:02 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.169240Z","level":"info","event":"25/12/28 17:43:02 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.242140Z","level":"info","event":"25/12/28 17:43:02 INFO Executor: Finished task 3.0 in stage 48.0 (TID 93). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.247213Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSetManager: Finished task 3.0 in stage 48.0 (TID 93) in 93 ms on c252dd92c865 (executor driver) (1/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.259676Z","level":"info","event":"25/12/28 17:43:02 INFO Executor: Finished task 2.0 in stage 48.0 (TID 92). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.263906Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSetManager: Finished task 2.0 in stage 48.0 (TID 92) in 110 ms on c252dd92c865 (executor driver) (2/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.265167Z","level":"info","event":"25/12/28 17:43:02 INFO Executor: Finished task 1.0 in stage 48.0 (TID 91). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.266430Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSetManager: Finished task 1.0 in stage 48.0 (TID 91) in 113 ms on c252dd92c865 (executor driver) (3/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.273336Z","level":"info","event":"25/12/28 17:43:02 INFO Executor: Finished task 0.0 in stage 48.0 (TID 90). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.273987Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 90) in 123 ms on c252dd92c865 (executor driver) (4/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.274047Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.274518Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: ShuffleMapStage 48 (count at NativeMethodAccessorImpl.java:0) finished in 0.135 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.274687Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.274808Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.274873Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.274918Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.303851Z","level":"info","event":"25/12/28 17:43:02 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.305001Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Got job 34 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.305083Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Final stage: ResultStage 50 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.305159Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 49)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.305349Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.305816Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[141] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.311892Z","level":"info","event":"25/12/28 17:43:02 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 12.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.314088Z","level":"info","event":"25/12/28 17:43:02 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.314647Z","level":"info","event":"25/12/28 17:43:02 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.315141Z","level":"info","event":"25/12/28 17:43:02 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.315303Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[141] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.315376Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.316504Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 94) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.316966Z","level":"info","event":"25/12/28 17:43:02 INFO Executor: Running task 0.0 in stage 50.0 (TID 94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.320971Z","level":"info","event":"25/12/28 17:43:02 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.321321Z","level":"info","event":"25/12/28 17:43:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.329112Z","level":"info","event":"25/12/28 17:43:02 INFO Executor: Finished task 0.0 in stage 50.0 (TID 94). 4031 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.330030Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 94) in 13 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.330095Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.332040Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: ResultStage 50 (count at NativeMethodAccessorImpl.java:0) finished in 0.020 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.332132Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.332158Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 50: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.332185Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Job 34 finished: count at NativeMethodAccessorImpl.java:0, took 0.027710 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.357109Z","level":"info","event":"25/12/28 17:43:02 INFO FileSourceStrategy: Pushed Filters: IsNull(seller_id)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.357279Z","level":"info","event":"25/12/28 17:43:02 INFO FileSourceStrategy: Post-Scan Filters: isnull(seller_id#206)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.370148Z","level":"info","event":"25/12/28 17:43:02 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.377320Z","level":"info","event":"25/12/28 17:43:02 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.377883Z","level":"info","event":"25/12/28 17:43:02 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.379132Z","level":"info","event":"25/12/28 17:43:02 INFO SparkContext: Created broadcast 57 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.380478Z","level":"info","event":"25/12/28 17:43:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.397487Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Registering RDD 145 (count at <unknown>:0) as input to shuffle 16","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.397646Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Got map stage job 35 (count at <unknown>:0) with 4 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.397676Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Final stage: ShuffleMapStage 51 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.397902Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.397949Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.399847Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Submitting ShuffleMapStage 51 (MapPartitionsRDD[145] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.403284Z","level":"info","event":"25/12/28 17:43:02 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 18.4 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.415570Z","level":"info","event":"25/12/28 17:43:02 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.417520Z","level":"info","event":"25/12/28 17:43:02 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.421410Z","level":"info","event":"25/12/28 17:43:02 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.422187Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[145] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.423038Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSchedulerImpl: Adding task set 51.0 with 4 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.426039Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 95) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.426493Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 96) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.426846Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSetManager: Starting task 2.0 in stage 51.0 (TID 97) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.427632Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSetManager: Starting task 3.0 in stage 51.0 (TID 98) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.428270Z","level":"info","event":"25/12/28 17:43:02 INFO Executor: Running task 3.0 in stage 51.0 (TID 98)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.428553Z","level":"info","event":"25/12/28 17:43:02 INFO Executor: Running task 2.0 in stage 51.0 (TID 97)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.428688Z","level":"info","event":"25/12/28 17:43:02 INFO Executor: Running task 0.0 in stage 51.0 (TID 95)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.429025Z","level":"info","event":"25/12/28 17:43:02 INFO Executor: Running task 1.0 in stage 51.0 (TID 96)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.439071Z","level":"info","event":"25/12/28 17:43:02 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 12582912-15438671, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.439217Z","level":"info","event":"25/12/28 17:43:02 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.440542Z","level":"info","event":"25/12/28 17:43:02 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.441377Z","level":"info","event":"25/12/28 17:43:02 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.502995Z","level":"info","event":"25/12/28 17:43:02 INFO Executor: Finished task 3.0 in stage 51.0 (TID 98). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.508157Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSetManager: Finished task 3.0 in stage 51.0 (TID 98) in 79 ms on c252dd92c865 (executor driver) (1/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.692086Z","level":"info","event":"25/12/28 17:43:02 INFO Executor: Finished task 2.0 in stage 51.0 (TID 97). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.693818Z","level":"info","event":"25/12/28 17:43:02 INFO Executor: Finished task 1.0 in stage 51.0 (TID 96). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.697134Z","level":"info","event":"25/12/28 17:43:02 INFO Executor: Finished task 0.0 in stage 51.0 (TID 95). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.699115Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 96) in 272 ms on c252dd92c865 (executor driver) (2/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.700875Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 95) in 276 ms on c252dd92c865 (executor driver) (3/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.707960Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSetManager: Finished task 2.0 in stage 51.0 (TID 97) in 275 ms on c252dd92c865 (executor driver) (4/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.708659Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.716521Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: ShuffleMapStage 51 (count at <unknown>:0) finished in 0.313 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.716899Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.717027Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.717163Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.717246Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.780618Z","level":"info","event":"25/12/28 17:43:02 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.783142Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Got job 36 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.783365Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Final stage: ResultStage 53 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.783417Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.783454Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.783559Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[148] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.787568Z","level":"info","event":"25/12/28 17:43:02 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 12.5 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.791823Z","level":"info","event":"25/12/28 17:43:02 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.793900Z","level":"info","event":"25/12/28 17:43:02 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.795891Z","level":"info","event":"25/12/28 17:43:02 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.797378Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[148] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.797771Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.800400Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 99) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.801365Z","level":"info","event":"25/12/28 17:43:02 INFO Executor: Running task 0.0 in stage 53.0 (TID 99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.808975Z","level":"info","event":"25/12/28 17:43:02 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.809134Z","level":"info","event":"25/12/28 17:43:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.824526Z","level":"info","event":"25/12/28 17:43:02 INFO Executor: Finished task 0.0 in stage 53.0 (TID 99). 4031 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.826236Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 99) in 26 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.826605Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.827308Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: ResultStage 53 (count at <unknown>:0) finished in 0.042 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.828173Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.828279Z","level":"info","event":"25/12/28 17:43:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.830871Z","level":"info","event":"25/12/28 17:43:02 INFO DAGScheduler: Job 36 finished: count at <unknown>:0, took 0.048036 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.907108Z","level":"info","event":"25/12/28 17:43:02 INFO FileSourceStrategy: Pushed Filters: IsNull(shipping_limit_date)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.907457Z","level":"info","event":"25/12/28 17:43:02 INFO FileSourceStrategy: Post-Scan Filters: isnull(shipping_limit_date#207)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:02.978124Z","level":"info","event":"25/12/28 17:43:02 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 199.2 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.039370Z","level":"info","event":"25/12/28 17:43:03 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.074364Z","level":"info","event":"25/12/28 17:43:03 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.075187Z","level":"info","event":"25/12/28 17:43:03 INFO SparkContext: Created broadcast 60 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.078182Z","level":"info","event":"25/12/28 17:43:03 INFO BlockManagerInfo: Removed broadcast_58_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.078454Z","level":"info","event":"25/12/28 17:43:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.083185Z","level":"info","event":"25/12/28 17:43:03 INFO BlockManagerInfo: Removed broadcast_59_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.091720Z","level":"info","event":"25/12/28 17:43:03 INFO BlockManagerInfo: Removed broadcast_53_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.091836Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Registering RDD 152 (count at <unknown>:0) as input to shuffle 17","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.091874Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Got map stage job 37 (count at <unknown>:0) with 4 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.091898Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Final stage: ShuffleMapStage 54 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.091917Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.091933Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.091959Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[152] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.093132Z","level":"info","event":"25/12/28 17:43:03 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 18.4 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.094955Z","level":"info","event":"25/12/28 17:43:03 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.095361Z","level":"info","event":"25/12/28 17:43:03 INFO BlockManagerInfo: Removed broadcast_55_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.095700Z","level":"info","event":"25/12/28 17:43:03 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.098535Z","level":"info","event":"25/12/28 17:43:03 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.099067Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[152] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.099190Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSchedulerImpl: Adding task set 54.0 with 4 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.100877Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 100) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.101041Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 101) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.101723Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSetManager: Starting task 2.0 in stage 54.0 (TID 102) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.101775Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSetManager: Starting task 3.0 in stage 54.0 (TID 103) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.101849Z","level":"info","event":"25/12/28 17:43:03 INFO BlockManagerInfo: Removed broadcast_56_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.102027Z","level":"info","event":"25/12/28 17:43:03 INFO Executor: Running task 0.0 in stage 54.0 (TID 100)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.102404Z","level":"info","event":"25/12/28 17:43:03 INFO Executor: Running task 1.0 in stage 54.0 (TID 101)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.113506Z","level":"info","event":"25/12/28 17:43:03 INFO Executor: Running task 3.0 in stage 54.0 (TID 103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.115386Z","level":"info","event":"25/12/28 17:43:03 INFO Executor: Running task 2.0 in stage 54.0 (TID 102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.115685Z","level":"info","event":"25/12/28 17:43:03 INFO BlockManagerInfo: Removed broadcast_57_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.135113Z","level":"info","event":"25/12/28 17:43:03 INFO BlockManagerInfo: Removed broadcast_52_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.135488Z","level":"info","event":"25/12/28 17:43:03 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.140937Z","level":"info","event":"25/12/28 17:43:03 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.144445Z","level":"info","event":"25/12/28 17:43:03 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.144581Z","level":"info","event":"25/12/28 17:43:03 INFO BlockManagerInfo: Removed broadcast_54_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.148776Z","level":"info","event":"25/12/28 17:43:03 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 12582912-15438671, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.153885Z","level":"info","event":"25/12/28 17:43:03 INFO BlockManagerInfo: Removed broadcast_51_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.224389Z","level":"info","event":"25/12/28 17:43:03 INFO Executor: Finished task 3.0 in stage 54.0 (TID 103). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.238704Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSetManager: Finished task 3.0 in stage 54.0 (TID 103) in 133 ms on c252dd92c865 (executor driver) (1/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.258378Z","level":"info","event":"25/12/28 17:43:03 INFO Executor: Finished task 1.0 in stage 54.0 (TID 101). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.258704Z","level":"info","event":"25/12/28 17:43:03 INFO Executor: Finished task 0.0 in stage 54.0 (TID 100). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.259162Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 101) in 159 ms on c252dd92c865 (executor driver) (2/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.260682Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 100) in 159 ms on c252dd92c865 (executor driver) (3/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.274447Z","level":"info","event":"25/12/28 17:43:03 INFO Executor: Finished task 2.0 in stage 54.0 (TID 102). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.276452Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSetManager: Finished task 2.0 in stage 54.0 (TID 102) in 175 ms on c252dd92c865 (executor driver) (4/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.276564Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.278312Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: ShuffleMapStage 54 (count at <unknown>:0) finished in 0.186 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.278433Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.278495Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.278827Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.279038Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.356764Z","level":"info","event":"25/12/28 17:43:03 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.358463Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Got job 38 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.358655Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Final stage: ResultStage 56 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.358735Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.358938Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.359426Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[155] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.363607Z","level":"info","event":"25/12/28 17:43:03 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.371756Z","level":"info","event":"25/12/28 17:43:03 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.372812Z","level":"info","event":"25/12/28 17:43:03 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.373954Z","level":"info","event":"25/12/28 17:43:03 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.375146Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[155] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.376063Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.381478Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 104) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.386166Z","level":"info","event":"25/12/28 17:43:03 INFO Executor: Running task 0.0 in stage 56.0 (TID 104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.401676Z","level":"info","event":"25/12/28 17:43:03 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.403307Z","level":"info","event":"25/12/28 17:43:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.417503Z","level":"info","event":"25/12/28 17:43:03 INFO Executor: Finished task 0.0 in stage 56.0 (TID 104). 3988 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.424312Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 104) in 43 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.426423Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.429845Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: ResultStage 56 (count at <unknown>:0) finished in 0.068 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.430579Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.430736Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.432380Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Job 38 finished: count at <unknown>:0, took 0.077548 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.572898Z","level":"info","event":"25/12/28 17:43:03 INFO FileSourceStrategy: Pushed Filters: IsNull(price)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.573350Z","level":"info","event":"25/12/28 17:43:03 INFO FileSourceStrategy: Post-Scan Filters: isnull(price#208)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.602045Z","level":"info","event":"25/12/28 17:43:03 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 199.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.615673Z","level":"info","event":"25/12/28 17:43:03 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.616084Z","level":"info","event":"25/12/28 17:43:03 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.616756Z","level":"info","event":"25/12/28 17:43:03 INFO SparkContext: Created broadcast 63 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.621335Z","level":"info","event":"25/12/28 17:43:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.626268Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Registering RDD 159 (count at <unknown>:0) as input to shuffle 18","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.626426Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Got map stage job 39 (count at <unknown>:0) with 4 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.626470Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Final stage: ShuffleMapStage 57 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.626507Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.626547Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.628201Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Submitting ShuffleMapStage 57 (MapPartitionsRDD[159] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.630271Z","level":"info","event":"25/12/28 17:43:03 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 18.4 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.634137Z","level":"info","event":"25/12/28 17:43:03 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.634375Z","level":"info","event":"25/12/28 17:43:03 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.634415Z","level":"info","event":"25/12/28 17:43:03 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.635370Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 57 (MapPartitionsRDD[159] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.635503Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSchedulerImpl: Adding task set 57.0 with 4 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.638914Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 105) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.639010Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 106) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.639048Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSetManager: Starting task 2.0 in stage 57.0 (TID 107) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.639077Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSetManager: Starting task 3.0 in stage 57.0 (TID 108) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.643039Z","level":"info","event":"25/12/28 17:43:03 INFO Executor: Running task 0.0 in stage 57.0 (TID 105)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.643173Z","level":"info","event":"25/12/28 17:43:03 INFO Executor: Running task 1.0 in stage 57.0 (TID 106)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.646697Z","level":"info","event":"25/12/28 17:43:03 INFO Executor: Running task 3.0 in stage 57.0 (TID 108)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.648441Z","level":"info","event":"25/12/28 17:43:03 INFO Executor: Running task 2.0 in stage 57.0 (TID 107)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.649262Z","level":"info","event":"25/12/28 17:43:03 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.649748Z","level":"info","event":"25/12/28 17:43:03 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.652520Z","level":"info","event":"25/12/28 17:43:03 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.658403Z","level":"info","event":"25/12/28 17:43:03 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 12582912-15438671, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.771237Z","level":"info","event":"25/12/28 17:43:03 INFO Executor: Finished task 2.0 in stage 57.0 (TID 107). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.783479Z","level":"info","event":"25/12/28 17:43:03 INFO Executor: Finished task 3.0 in stage 57.0 (TID 108). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.788960Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSetManager: Finished task 2.0 in stage 57.0 (TID 107) in 151 ms on c252dd92c865 (executor driver) (1/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.791663Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSetManager: Finished task 3.0 in stage 57.0 (TID 108) in 154 ms on c252dd92c865 (executor driver) (2/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.794370Z","level":"info","event":"25/12/28 17:43:03 INFO Executor: Finished task 0.0 in stage 57.0 (TID 105). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.806792Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 105) in 170 ms on c252dd92c865 (executor driver) (3/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.823469Z","level":"info","event":"25/12/28 17:43:03 INFO Executor: Finished task 1.0 in stage 57.0 (TID 106). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.826663Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSetManager: Finished task 1.0 in stage 57.0 (TID 106) in 189 ms on c252dd92c865 (executor driver) (4/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.826792Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.829724Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: ShuffleMapStage 57 (count at <unknown>:0) finished in 0.201 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.829990Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.830221Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.830422Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.830564Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.903837Z","level":"info","event":"25/12/28 17:43:03 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.909365Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Got job 40 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.909600Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Final stage: ResultStage 59 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.909891Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.909931Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.914415Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[162] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.930483Z","level":"info","event":"25/12/28 17:43:03 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 12.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.939613Z","level":"info","event":"25/12/28 17:43:03 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.941942Z","level":"info","event":"25/12/28 17:43:03 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.945035Z","level":"info","event":"25/12/28 17:43:03 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.945393Z","level":"info","event":"25/12/28 17:43:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[162] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.945510Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.963141Z","level":"info","event":"25/12/28 17:43:03 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 109) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:03.966482Z","level":"info","event":"25/12/28 17:43:03 INFO Executor: Running task 0.0 in stage 59.0 (TID 109)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.032860Z","level":"info","event":"25/12/28 17:43:04 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.033156Z","level":"info","event":"25/12/28 17:43:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.064244Z","level":"info","event":"25/12/28 17:43:04 INFO Executor: Finished task 0.0 in stage 59.0 (TID 109). 4031 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.069771Z","level":"info","event":"25/12/28 17:43:04 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 109) in 107 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.070061Z","level":"info","event":"25/12/28 17:43:04 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.070639Z","level":"info","event":"25/12/28 17:43:04 INFO DAGScheduler: ResultStage 59 (count at <unknown>:0) finished in 0.152 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.070974Z","level":"info","event":"25/12/28 17:43:04 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.071181Z","level":"info","event":"25/12/28 17:43:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.071441Z","level":"info","event":"25/12/28 17:43:04 INFO DAGScheduler: Job 40 finished: count at <unknown>:0, took 0.166690 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.159607Z","level":"info","event":"25/12/28 17:43:04 INFO FileSourceStrategy: Pushed Filters: IsNull(freight_value)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.159868Z","level":"info","event":"25/12/28 17:43:04 INFO FileSourceStrategy: Post-Scan Filters: isnull(freight_value#209)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.177399Z","level":"info","event":"25/12/28 17:43:04 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.190430Z","level":"info","event":"25/12/28 17:43:04 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.192761Z","level":"info","event":"25/12/28 17:43:04 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.193520Z","level":"info","event":"25/12/28 17:43:04 INFO SparkContext: Created broadcast 66 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.195910Z","level":"info","event":"25/12/28 17:43:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.204704Z","level":"info","event":"25/12/28 17:43:04 INFO DAGScheduler: Registering RDD 166 (count at <unknown>:0) as input to shuffle 19","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.205435Z","level":"info","event":"25/12/28 17:43:04 INFO DAGScheduler: Got map stage job 41 (count at <unknown>:0) with 4 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.205518Z","level":"info","event":"25/12/28 17:43:04 INFO DAGScheduler: Final stage: ShuffleMapStage 60 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.205556Z","level":"info","event":"25/12/28 17:43:04 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.206068Z","level":"info","event":"25/12/28 17:43:04 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.207096Z","level":"info","event":"25/12/28 17:43:04 INFO DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[166] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.215808Z","level":"info","event":"25/12/28 17:43:04 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 18.4 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.219114Z","level":"info","event":"25/12/28 17:43:04 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.220137Z","level":"info","event":"25/12/28 17:43:04 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.221618Z","level":"info","event":"25/12/28 17:43:04 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.223111Z","level":"info","event":"25/12/28 17:43:04 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[166] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.224200Z","level":"info","event":"25/12/28 17:43:04 INFO TaskSchedulerImpl: Adding task set 60.0 with 4 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.229023Z","level":"info","event":"25/12/28 17:43:04 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 110) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.229699Z","level":"info","event":"25/12/28 17:43:04 INFO TaskSetManager: Starting task 1.0 in stage 60.0 (TID 111) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.229847Z","level":"info","event":"25/12/28 17:43:04 INFO TaskSetManager: Starting task 2.0 in stage 60.0 (TID 112) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.229900Z","level":"info","event":"25/12/28 17:43:04 INFO TaskSetManager: Starting task 3.0 in stage 60.0 (TID 113) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8282 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.229932Z","level":"info","event":"25/12/28 17:43:04 INFO Executor: Running task 2.0 in stage 60.0 (TID 112)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.230089Z","level":"info","event":"25/12/28 17:43:04 INFO Executor: Running task 1.0 in stage 60.0 (TID 111)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.230124Z","level":"info","event":"25/12/28 17:43:04 INFO Executor: Running task 3.0 in stage 60.0 (TID 113)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.230160Z","level":"info","event":"25/12/28 17:43:04 INFO Executor: Running task 0.0 in stage 60.0 (TID 110)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.247663Z","level":"info","event":"25/12/28 17:43:04 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.247996Z","level":"info","event":"25/12/28 17:43:04 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 12582912-15438671, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.248113Z","level":"info","event":"25/12/28 17:43:04 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.249769Z","level":"info","event":"25/12/28 17:43:04 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.348229Z","level":"info","event":"25/12/28 17:43:04 INFO BlockManagerInfo: Removed broadcast_65_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.352630Z","level":"info","event":"25/12/28 17:43:04 INFO BlockManagerInfo: Removed broadcast_64_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.357228Z","level":"info","event":"25/12/28 17:43:04 INFO Executor: Finished task 3.0 in stage 60.0 (TID 113). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.360441Z","level":"info","event":"25/12/28 17:43:04 INFO BlockManagerInfo: Removed broadcast_62_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.361793Z","level":"info","event":"25/12/28 17:43:04 INFO TaskSetManager: Finished task 3.0 in stage 60.0 (TID 113) in 135 ms on c252dd92c865 (executor driver) (1/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.367140Z","level":"info","event":"25/12/28 17:43:04 INFO BlockManagerInfo: Removed broadcast_63_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.369368Z","level":"info","event":"25/12/28 17:43:04 INFO BlockManagerInfo: Removed broadcast_61_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.372368Z","level":"info","event":"25/12/28 17:43:04 INFO BlockManagerInfo: Removed broadcast_60_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.378652Z","level":"info","event":"25/12/28 17:43:04 INFO Executor: Finished task 2.0 in stage 60.0 (TID 112). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.382051Z","level":"info","event":"25/12/28 17:43:04 INFO TaskSetManager: Finished task 2.0 in stage 60.0 (TID 112) in 155 ms on c252dd92c865 (executor driver) (2/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.408380Z","level":"info","event":"25/12/28 17:43:04 INFO Executor: Finished task 0.0 in stage 60.0 (TID 110). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.424855Z","level":"info","event":"25/12/28 17:43:04 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 110) in 198 ms on c252dd92c865 (executor driver) (3/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.438386Z","level":"info","event":"25/12/28 17:43:04 INFO Executor: Finished task 1.0 in stage 60.0 (TID 111). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.459218Z","level":"info","event":"25/12/28 17:43:04 INFO TaskSetManager: Finished task 1.0 in stage 60.0 (TID 111) in 231 ms on c252dd92c865 (executor driver) (4/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.511841Z","level":"info","event":"25/12/28 17:43:04 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.523817Z","level":"info","event":"25/12/28 17:43:04 INFO DAGScheduler: ShuffleMapStage 60 (count at <unknown>:0) finished in 0.308 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.524037Z","level":"info","event":"25/12/28 17:43:04 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.524108Z","level":"info","event":"25/12/28 17:43:04 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.524140Z","level":"info","event":"25/12/28 17:43:04 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.524312Z","level":"info","event":"25/12/28 17:43:04 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.792053Z","level":"info","event":"25/12/28 17:43:04 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.806045Z","level":"info","event":"25/12/28 17:43:04 INFO DAGScheduler: Got job 42 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.806341Z","level":"info","event":"25/12/28 17:43:04 INFO DAGScheduler: Final stage: ResultStage 62 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.808743Z","level":"info","event":"25/12/28 17:43:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.809024Z","level":"info","event":"25/12/28 17:43:04 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.811368Z","level":"info","event":"25/12/28 17:43:04 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[169] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.840391Z","level":"info","event":"25/12/28 17:43:04 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.886092Z","level":"info","event":"25/12/28 17:43:04 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.890599Z","level":"info","event":"25/12/28 17:43:04 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.893876Z","level":"info","event":"25/12/28 17:43:04 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.894845Z","level":"info","event":"25/12/28 17:43:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[169] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.895062Z","level":"info","event":"25/12/28 17:43:04 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.909004Z","level":"info","event":"25/12/28 17:43:04 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 114) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.914992Z","level":"info","event":"25/12/28 17:43:04 INFO Executor: Running task 0.0 in stage 62.0 (TID 114)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.966159Z","level":"info","event":"25/12/28 17:43:04 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:04.970015Z","level":"info","event":"25/12/28 17:43:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.057548Z","level":"info","event":"25/12/28 17:43:05 INFO Executor: Finished task 0.0 in stage 62.0 (TID 114). 4031 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.076752Z","level":"info","event":"25/12/28 17:43:05 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 114) in 167 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.077326Z","level":"info","event":"25/12/28 17:43:05 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.081329Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: ResultStage 62 (count at <unknown>:0) finished in 0.259 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.087624Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.088363Z","level":"info","event":"25/12/28 17:43:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 62: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.097208Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Job 42 finished: count at <unknown>:0, took 0.302725 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.180820Z","level":"info","event":"25/12/28 17:43:05 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.224369Z","level":"info","event":"25/12/28 17:43:05 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.470471Z","level":"info","event":"25/12/28 17:43:05 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.480590Z","level":"info","event":"25/12/28 17:43:05 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#321, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.510439Z","level":"info","event":"25/12/28 17:43:05 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 199.3 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.519825Z","level":"info","event":"25/12/28 17:43:05 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.521063Z","level":"info","event":"25/12/28 17:43:05 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on c252dd92c865:35057 (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.525576Z","level":"info","event":"25/12/28 17:43:05 INFO SparkContext: Created broadcast 69 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.531155Z","level":"info","event":"25/12/28 17:43:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.553313Z","level":"info","event":"25/12/28 17:43:05 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.556048Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Got job 43 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.556199Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Final stage: ResultStage 63 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.556246Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.556897Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.558844Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[173] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.564871Z","level":"info","event":"25/12/28 17:43:05 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 13.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.571791Z","level":"info","event":"25/12/28 17:43:05 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.572390Z","level":"info","event":"25/12/28 17:43:05 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on c252dd92c865:35057 (size: 6.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.573197Z","level":"info","event":"25/12/28 17:43:05 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.574428Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[173] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.574668Z","level":"info","event":"25/12/28 17:43:05 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.580667Z","level":"info","event":"25/12/28 17:43:05 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 115) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8296 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.583532Z","level":"info","event":"25/12/28 17:43:05 INFO Executor: Running task 0.0 in stage 63.0 (TID 115)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.599658Z","level":"info","event":"25/12/28 17:43:05 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_payments_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.624937Z","level":"info","event":"25/12/28 17:43:05 INFO Executor: Finished task 0.0 in stage 63.0 (TID 115). 1632 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.629021Z","level":"info","event":"25/12/28 17:43:05 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 115) in 50 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.629193Z","level":"info","event":"25/12/28 17:43:05 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.629843Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: ResultStage 63 (csv at NativeMethodAccessorImpl.java:0) finished in 0.067 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.630097Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.630166Z","level":"info","event":"25/12/28 17:43:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.630357Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Job 43 finished: csv at NativeMethodAccessorImpl.java:0, took 0.076913 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.647055Z","level":"info","event":"25/12/28 17:43:05 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.647392Z","level":"info","event":"25/12/28 17:43:05 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.654766Z","level":"info","event":"25/12/28 17:43:05 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 199.3 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.663645Z","level":"info","event":"25/12/28 17:43:05 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.664303Z","level":"info","event":"25/12/28 17:43:05 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on c252dd92c865:35057 (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.665052Z","level":"info","event":"25/12/28 17:43:05 INFO SparkContext: Created broadcast 71 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.665780Z","level":"info","event":"25/12/28 17:43:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.684959Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.703423Z","level":"info","event":"25/12/28 17:43:05 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.704005Z","level":"info","event":"25/12/28 17:43:05 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.721946Z","level":"info","event":"25/12/28 17:43:05 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 199.2 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.736783Z","level":"info","event":"25/12/28 17:43:05 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.737185Z","level":"info","event":"25/12/28 17:43:05 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.738786Z","level":"info","event":"25/12/28 17:43:05 INFO SparkContext: Created broadcast 72 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.740477Z","level":"info","event":"25/12/28 17:43:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.746955Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Registering RDD 183 (count at <unknown>:0) as input to shuffle 20","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.747448Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Got map stage job 44 (count at <unknown>:0) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.747672Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Final stage: ShuffleMapStage 64 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.747864Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.747957Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.748043Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Submitting ShuffleMapStage 64 (MapPartitionsRDD[183] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.750522Z","level":"info","event":"25/12/28 17:43:05 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 17.8 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.757056Z","level":"info","event":"25/12/28 17:43:05 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.761857Z","level":"info","event":"25/12/28 17:43:05 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on c252dd92c865:35057 (size: 8.7 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.762098Z","level":"info","event":"25/12/28 17:43:05 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.762243Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 64 (MapPartitionsRDD[183] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.762386Z","level":"info","event":"25/12/28 17:43:05 INFO TaskSchedulerImpl: Adding task set 64.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.763646Z","level":"info","event":"25/12/28 17:43:05 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 116) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8285 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.763948Z","level":"info","event":"25/12/28 17:43:05 INFO TaskSetManager: Starting task 1.0 in stage 64.0 (TID 117) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8285 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.764725Z","level":"info","event":"25/12/28 17:43:05 INFO Executor: Running task 0.0 in stage 64.0 (TID 116)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.764984Z","level":"info","event":"25/12/28 17:43:05 INFO Executor: Running task 1.0 in stage 64.0 (TID 117)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.770388Z","level":"info","event":"25/12/28 17:43:05 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_payments_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.770542Z","level":"info","event":"25/12/28 17:43:05 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_payments_dataset.csv, range: 4194304-5777138, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.802774Z","level":"info","event":"25/12/28 17:43:05 INFO Executor: Finished task 1.0 in stage 64.0 (TID 117). 1928 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.804877Z","level":"info","event":"25/12/28 17:43:05 INFO TaskSetManager: Finished task 1.0 in stage 64.0 (TID 117) in 41 ms on c252dd92c865 (executor driver) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.819914Z","level":"info","event":"25/12/28 17:43:05 INFO Executor: Finished task 0.0 in stage 64.0 (TID 116). 1928 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.820886Z","level":"info","event":"25/12/28 17:43:05 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 116) in 57 ms on c252dd92c865 (executor driver) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.821107Z","level":"info","event":"25/12/28 17:43:05 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.821279Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: ShuffleMapStage 64 (count at <unknown>:0) finished in 0.072 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.821485Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.821607Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.821721Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.821780Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.844533Z","level":"info","event":"25/12/28 17:43:05 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.845155Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Got job 45 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.845311Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Final stage: ResultStage 66 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.845425Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 65)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.845508Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.845604Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[186] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.846791Z","level":"info","event":"25/12/28 17:43:05 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 12.5 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.850772Z","level":"info","event":"25/12/28 17:43:05 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.852404Z","level":"info","event":"25/12/28 17:43:05 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.852851Z","level":"info","event":"25/12/28 17:43:05 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.853137Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[186] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.853275Z","level":"info","event":"25/12/28 17:43:05 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.854310Z","level":"info","event":"25/12/28 17:43:05 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 118) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.854987Z","level":"info","event":"25/12/28 17:43:05 INFO Executor: Running task 0.0 in stage 66.0 (TID 118)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.858047Z","level":"info","event":"25/12/28 17:43:05 INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.858311Z","level":"info","event":"25/12/28 17:43:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.861390Z","level":"info","event":"25/12/28 17:43:05 INFO Executor: Finished task 0.0 in stage 66.0 (TID 118). 3995 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.862555Z","level":"info","event":"25/12/28 17:43:05 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 118) in 9 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.862701Z","level":"info","event":"25/12/28 17:43:05 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.864213Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: ResultStage 66 (count at <unknown>:0) finished in 0.018 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.865522Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.865671Z","level":"info","event":"25/12/28 17:43:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 66: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.866366Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Job 45 finished: count at <unknown>:0, took 0.021561 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.867799Z","level":"info","event":"Loaded olist_order_payments with 103886 records.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.908664Z","level":"info","event":"25/12/28 17:43:05 INFO FileSourceStrategy: Pushed Filters: IsNull(order_id)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.908822Z","level":"info","event":"25/12/28 17:43:05 INFO FileSourceStrategy: Post-Scan Filters: isnull(order_id#338)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.932326Z","level":"info","event":"25/12/28 17:43:05 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 199.2 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.941635Z","level":"info","event":"25/12/28 17:43:05 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.941991Z","level":"info","event":"25/12/28 17:43:05 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.942524Z","level":"info","event":"25/12/28 17:43:05 INFO SparkContext: Created broadcast 75 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.943273Z","level":"info","event":"25/12/28 17:43:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.946176Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Registering RDD 190 (count at <unknown>:0) as input to shuffle 21","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.946316Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Got map stage job 46 (count at <unknown>:0) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.946357Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Final stage: ShuffleMapStage 67 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.946389Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.946592Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.946630Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Submitting ShuffleMapStage 67 (MapPartitionsRDD[190] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.948625Z","level":"info","event":"25/12/28 17:43:05 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 18.4 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.954825Z","level":"info","event":"25/12/28 17:43:05 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.955346Z","level":"info","event":"25/12/28 17:43:05 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.956192Z","level":"info","event":"25/12/28 17:43:05 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.956742Z","level":"info","event":"25/12/28 17:43:05 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 67 (MapPartitionsRDD[190] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.956795Z","level":"info","event":"25/12/28 17:43:05 INFO TaskSchedulerImpl: Adding task set 67.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.959879Z","level":"info","event":"25/12/28 17:43:05 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 119) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8285 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.960016Z","level":"info","event":"25/12/28 17:43:05 INFO TaskSetManager: Starting task 1.0 in stage 67.0 (TID 120) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8285 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.960486Z","level":"info","event":"25/12/28 17:43:05 INFO Executor: Running task 1.0 in stage 67.0 (TID 120)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.960661Z","level":"info","event":"25/12/28 17:43:05 INFO Executor: Running task 0.0 in stage 67.0 (TID 119)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.964217Z","level":"info","event":"25/12/28 17:43:05 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_payments_dataset.csv, range: 4194304-5777138, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:05.964668Z","level":"info","event":"25/12/28 17:43:05 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_payments_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.019240Z","level":"info","event":"25/12/28 17:43:06 INFO Executor: Finished task 1.0 in stage 67.0 (TID 120). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.022461Z","level":"info","event":"25/12/28 17:43:06 INFO TaskSetManager: Finished task 1.0 in stage 67.0 (TID 120) in 62 ms on c252dd92c865 (executor driver) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.098851Z","level":"info","event":"25/12/28 17:43:06 INFO Executor: Finished task 0.0 in stage 67.0 (TID 119). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.099521Z","level":"info","event":"25/12/28 17:43:06 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 119) in 141 ms on c252dd92c865 (executor driver) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.099602Z","level":"info","event":"25/12/28 17:43:06 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.100131Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: ShuffleMapStage 67 (count at <unknown>:0) finished in 0.153 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.100248Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.100320Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.100365Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.100395Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.113938Z","level":"info","event":"25/12/28 17:43:06 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.114776Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Got job 47 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.114942Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Final stage: ResultStage 69 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.115030Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 68)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.115113Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.115197Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[193] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.116213Z","level":"info","event":"25/12/28 17:43:06 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 12.5 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.121690Z","level":"info","event":"25/12/28 17:43:06 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.123370Z","level":"info","event":"25/12/28 17:43:06 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.124106Z","level":"info","event":"25/12/28 17:43:06 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.125399Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[193] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.125678Z","level":"info","event":"25/12/28 17:43:06 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.127440Z","level":"info","event":"25/12/28 17:43:06 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 121) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.128232Z","level":"info","event":"25/12/28 17:43:06 INFO Executor: Running task 0.0 in stage 69.0 (TID 121)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.131453Z","level":"info","event":"25/12/28 17:43:06 INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.131729Z","level":"info","event":"25/12/28 17:43:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.134427Z","level":"info","event":"25/12/28 17:43:06 INFO Executor: Finished task 0.0 in stage 69.0 (TID 121). 3988 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.135795Z","level":"info","event":"25/12/28 17:43:06 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 121) in 9 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.136030Z","level":"info","event":"25/12/28 17:43:06 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.136952Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: ResultStage 69 (count at <unknown>:0) finished in 0.021 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.137184Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.137242Z","level":"info","event":"25/12/28 17:43:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 69: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.137776Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Job 47 finished: count at <unknown>:0, took 0.023641 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.193419Z","level":"info","event":"25/12/28 17:43:06 INFO FileSourceStrategy: Pushed Filters: IsNull(payment_sequential)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.193865Z","level":"info","event":"25/12/28 17:43:06 INFO FileSourceStrategy: Post-Scan Filters: isnull(payment_sequential#339)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.216807Z","level":"info","event":"25/12/28 17:43:06 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 199.2 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.230814Z","level":"info","event":"25/12/28 17:43:06 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.232199Z","level":"info","event":"25/12/28 17:43:06 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.234272Z","level":"info","event":"25/12/28 17:43:06 INFO SparkContext: Created broadcast 78 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.235817Z","level":"info","event":"25/12/28 17:43:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.241430Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Registering RDD 197 (count at <unknown>:0) as input to shuffle 22","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.241760Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Got map stage job 48 (count at <unknown>:0) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.241888Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Final stage: ShuffleMapStage 70 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.241990Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.242110Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.242235Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Submitting ShuffleMapStage 70 (MapPartitionsRDD[197] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.244441Z","level":"info","event":"25/12/28 17:43:06 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 18.4 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.254509Z","level":"info","event":"25/12/28 17:43:06 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.256726Z","level":"info","event":"25/12/28 17:43:06 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.256820Z","level":"info","event":"25/12/28 17:43:06 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.256862Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[197] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.256906Z","level":"info","event":"25/12/28 17:43:06 INFO TaskSchedulerImpl: Adding task set 70.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.257628Z","level":"info","event":"25/12/28 17:43:06 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 122) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8285 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.257767Z","level":"info","event":"25/12/28 17:43:06 INFO TaskSetManager: Starting task 1.0 in stage 70.0 (TID 123) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8285 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.259812Z","level":"info","event":"25/12/28 17:43:06 INFO Executor: Running task 1.0 in stage 70.0 (TID 123)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.259903Z","level":"info","event":"25/12/28 17:43:06 INFO Executor: Running task 0.0 in stage 70.0 (TID 122)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.265750Z","level":"info","event":"25/12/28 17:43:06 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_payments_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.266226Z","level":"info","event":"25/12/28 17:43:06 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_payments_dataset.csv, range: 4194304-5777138, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.336761Z","level":"info","event":"25/12/28 17:43:06 INFO Executor: Finished task 1.0 in stage 70.0 (TID 123). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.342383Z","level":"info","event":"25/12/28 17:43:06 INFO TaskSetManager: Finished task 1.0 in stage 70.0 (TID 123) in 84 ms on c252dd92c865 (executor driver) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.395351Z","level":"info","event":"25/12/28 17:43:06 INFO Executor: Finished task 0.0 in stage 70.0 (TID 122). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.397131Z","level":"info","event":"25/12/28 17:43:06 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 122) in 139 ms on c252dd92c865 (executor driver) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.397411Z","level":"info","event":"25/12/28 17:43:06 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.398824Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: ShuffleMapStage 70 (count at <unknown>:0) finished in 0.155 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.399081Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.399282Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.399422Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.399502Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.444972Z","level":"info","event":"25/12/28 17:43:06 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.446663Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Got job 49 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.446981Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Final stage: ResultStage 72 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.447167Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 71)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.447223Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.447284Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[200] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.450028Z","level":"info","event":"25/12/28 17:43:06 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 12.5 KiB, free 432.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.459035Z","level":"info","event":"25/12/28 17:43:06 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 432.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.460314Z","level":"info","event":"25/12/28 17:43:06 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.461778Z","level":"info","event":"25/12/28 17:43:06 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.462684Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[200] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.462813Z","level":"info","event":"25/12/28 17:43:06 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.466390Z","level":"info","event":"25/12/28 17:43:06 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 124) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.469879Z","level":"info","event":"25/12/28 17:43:06 INFO Executor: Running task 0.0 in stage 72.0 (TID 124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.482280Z","level":"info","event":"25/12/28 17:43:06 INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.482813Z","level":"info","event":"25/12/28 17:43:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.504723Z","level":"info","event":"25/12/28 17:43:06 INFO Executor: Finished task 0.0 in stage 72.0 (TID 124). 4031 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.506679Z","level":"info","event":"25/12/28 17:43:06 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 124) in 41 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.506805Z","level":"info","event":"25/12/28 17:43:06 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.507704Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: ResultStage 72 (count at <unknown>:0) finished in 0.060 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.508202Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.508354Z","level":"info","event":"25/12/28 17:43:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.508692Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Job 49 finished: count at <unknown>:0, took 0.063112 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.623322Z","level":"info","event":"25/12/28 17:43:06 INFO FileSourceStrategy: Pushed Filters: IsNull(payment_type)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.623926Z","level":"info","event":"25/12/28 17:43:06 INFO FileSourceStrategy: Post-Scan Filters: isnull(payment_type#340)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.738656Z","level":"info","event":"25/12/28 17:43:06 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 199.2 KiB, free 432.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.881191Z","level":"info","event":"25/12/28 17:43:06 INFO BlockManagerInfo: Removed broadcast_68_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.888595Z","level":"info","event":"25/12/28 17:43:06 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 432.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.892277Z","level":"info","event":"25/12/28 17:43:06 INFO BlockManagerInfo: Removed broadcast_67_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.892593Z","level":"info","event":"25/12/28 17:43:06 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.897587Z","level":"info","event":"25/12/28 17:43:06 INFO SparkContext: Created broadcast 81 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.905708Z","level":"info","event":"25/12/28 17:43:06 INFO BlockManagerInfo: Removed broadcast_73_piece0 on c252dd92c865:35057 in memory (size: 8.7 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.926761Z","level":"info","event":"25/12/28 17:43:06 INFO BlockManagerInfo: Removed broadcast_66_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.929447Z","level":"info","event":"25/12/28 17:43:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.934712Z","level":"info","event":"25/12/28 17:43:06 INFO BlockManagerInfo: Removed broadcast_75_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.945683Z","level":"info","event":"25/12/28 17:43:06 INFO BlockManagerInfo: Removed broadcast_78_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.957092Z","level":"info","event":"25/12/28 17:43:06 INFO BlockManagerInfo: Removed broadcast_80_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.974595Z","level":"info","event":"25/12/28 17:43:06 INFO BlockManagerInfo: Removed broadcast_72_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.980412Z","level":"info","event":"25/12/28 17:43:06 INFO BlockManagerInfo: Removed broadcast_74_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.984011Z","level":"info","event":"25/12/28 17:43:06 INFO BlockManagerInfo: Removed broadcast_71_piece0 on c252dd92c865:35057 in memory (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.993255Z","level":"info","event":"25/12/28 17:43:06 INFO BlockManagerInfo: Removed broadcast_69_piece0 on c252dd92c865:35057 in memory (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.996926Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Registering RDD 204 (count at <unknown>:0) as input to shuffle 23","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:06.999253Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Got map stage job 50 (count at <unknown>:0) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.000137Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Final stage: ShuffleMapStage 73 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.000326Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.000453Z","level":"info","event":"25/12/28 17:43:06 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.001813Z","level":"info","event":"25/12/28 17:43:07 INFO BlockManagerInfo: Removed broadcast_76_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.003742Z","level":"info","event":"25/12/28 17:43:07 INFO DAGScheduler: Submitting ShuffleMapStage 73 (MapPartitionsRDD[204] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.009115Z","level":"info","event":"25/12/28 17:43:07 INFO BlockManagerInfo: Removed broadcast_79_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.009401Z","level":"info","event":"25/12/28 17:43:07 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 18.4 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.019378Z","level":"info","event":"25/12/28 17:43:07 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.019779Z","level":"info","event":"25/12/28 17:43:07 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.022240Z","level":"info","event":"25/12/28 17:43:07 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.022641Z","level":"info","event":"25/12/28 17:43:07 INFO BlockManagerInfo: Removed broadcast_70_piece0 on c252dd92c865:35057 in memory (size: 6.4 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.028021Z","level":"info","event":"25/12/28 17:43:07 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 73 (MapPartitionsRDD[204] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.028478Z","level":"info","event":"25/12/28 17:43:07 INFO TaskSchedulerImpl: Adding task set 73.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.029337Z","level":"info","event":"25/12/28 17:43:07 INFO BlockManagerInfo: Removed broadcast_77_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.034582Z","level":"info","event":"25/12/28 17:43:07 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 125) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8285 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.034906Z","level":"info","event":"25/12/28 17:43:07 INFO TaskSetManager: Starting task 1.0 in stage 73.0 (TID 126) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8285 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.037436Z","level":"info","event":"25/12/28 17:43:07 INFO Executor: Running task 1.0 in stage 73.0 (TID 126)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.037714Z","level":"info","event":"25/12/28 17:43:07 INFO Executor: Running task 0.0 in stage 73.0 (TID 125)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.081490Z","level":"info","event":"25/12/28 17:43:07 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_payments_dataset.csv, range: 4194304-5777138, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.082242Z","level":"info","event":"25/12/28 17:43:07 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_payments_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.234172Z","level":"info","event":"25/12/28 17:43:07 INFO Executor: Finished task 1.0 in stage 73.0 (TID 126). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.251322Z","level":"info","event":"25/12/28 17:43:07 INFO TaskSetManager: Finished task 1.0 in stage 73.0 (TID 126) in 217 ms on c252dd92c865 (executor driver) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.330734Z","level":"info","event":"25/12/28 17:43:07 INFO Executor: Finished task 0.0 in stage 73.0 (TID 125). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.334018Z","level":"info","event":"25/12/28 17:43:07 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 125) in 301 ms on c252dd92c865 (executor driver) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.334192Z","level":"info","event":"25/12/28 17:43:07 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.338711Z","level":"info","event":"25/12/28 17:43:07 INFO DAGScheduler: ShuffleMapStage 73 (count at <unknown>:0) finished in 0.329 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.338852Z","level":"info","event":"25/12/28 17:43:07 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.339043Z","level":"info","event":"25/12/28 17:43:07 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.339102Z","level":"info","event":"25/12/28 17:43:07 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.339146Z","level":"info","event":"25/12/28 17:43:07 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.506628Z","level":"info","event":"25/12/28 17:43:07 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.537191Z","level":"info","event":"25/12/28 17:43:07 INFO DAGScheduler: Got job 51 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.539402Z","level":"info","event":"25/12/28 17:43:07 INFO DAGScheduler: Final stage: ResultStage 75 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.539626Z","level":"info","event":"25/12/28 17:43:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 74)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.539787Z","level":"info","event":"25/12/28 17:43:07 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.539988Z","level":"info","event":"25/12/28 17:43:07 INFO DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[207] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.546472Z","level":"info","event":"25/12/28 17:43:07 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.560309Z","level":"info","event":"25/12/28 17:43:07 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.564663Z","level":"info","event":"25/12/28 17:43:07 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.579129Z","level":"info","event":"25/12/28 17:43:07 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.597735Z","level":"info","event":"25/12/28 17:43:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[207] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.601836Z","level":"info","event":"25/12/28 17:43:07 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.670591Z","level":"info","event":"25/12/28 17:43:07 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 127) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.699039Z","level":"info","event":"25/12/28 17:43:07 INFO Executor: Running task 0.0 in stage 75.0 (TID 127)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.757785Z","level":"info","event":"25/12/28 17:43:07 INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.759771Z","level":"info","event":"25/12/28 17:43:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.778341Z","level":"info","event":"25/12/28 17:43:07 INFO Executor: Finished task 0.0 in stage 75.0 (TID 127). 4031 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.790449Z","level":"info","event":"25/12/28 17:43:07 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 127) in 140 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.791342Z","level":"info","event":"25/12/28 17:43:07 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.809371Z","level":"info","event":"25/12/28 17:43:07 INFO DAGScheduler: ResultStage 75 (count at <unknown>:0) finished in 0.276 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.810628Z","level":"info","event":"25/12/28 17:43:07 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.810880Z","level":"info","event":"25/12/28 17:43:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 75: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.811044Z","level":"info","event":"25/12/28 17:43:07 INFO DAGScheduler: Job 51 finished: count at <unknown>:0, took 0.303935 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.959538Z","level":"info","event":"25/12/28 17:43:07 INFO FileSourceStrategy: Pushed Filters: IsNull(payment_installments)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:07.959712Z","level":"info","event":"25/12/28 17:43:07 INFO FileSourceStrategy: Post-Scan Filters: isnull(payment_installments#341)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.000446Z","level":"info","event":"25/12/28 17:43:08 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 199.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.033095Z","level":"info","event":"25/12/28 17:43:08 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.036754Z","level":"info","event":"25/12/28 17:43:08 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.050507Z","level":"info","event":"25/12/28 17:43:08 INFO SparkContext: Created broadcast 84 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.057985Z","level":"info","event":"25/12/28 17:43:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.080783Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Registering RDD 211 (count at <unknown>:0) as input to shuffle 24","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.083400Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Got map stage job 52 (count at <unknown>:0) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.086575Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Final stage: ShuffleMapStage 76 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.086707Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.086876Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.087004Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Submitting ShuffleMapStage 76 (MapPartitionsRDD[211] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.090459Z","level":"info","event":"25/12/28 17:43:08 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 18.4 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.093556Z","level":"info","event":"25/12/28 17:43:08 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.093765Z","level":"info","event":"25/12/28 17:43:08 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.094087Z","level":"info","event":"25/12/28 17:43:08 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.094548Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 76 (MapPartitionsRDD[211] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.094726Z","level":"info","event":"25/12/28 17:43:08 INFO TaskSchedulerImpl: Adding task set 76.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.096666Z","level":"info","event":"25/12/28 17:43:08 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 128) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8285 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.097544Z","level":"info","event":"25/12/28 17:43:08 INFO TaskSetManager: Starting task 1.0 in stage 76.0 (TID 129) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8285 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.099910Z","level":"info","event":"25/12/28 17:43:08 INFO Executor: Running task 1.0 in stage 76.0 (TID 129)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.104760Z","level":"info","event":"25/12/28 17:43:08 INFO Executor: Running task 0.0 in stage 76.0 (TID 128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.116796Z","level":"info","event":"25/12/28 17:43:08 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_payments_dataset.csv, range: 4194304-5777138, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.116935Z","level":"info","event":"25/12/28 17:43:08 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_payments_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.259123Z","level":"info","event":"25/12/28 17:43:08 INFO Executor: Finished task 1.0 in stage 76.0 (TID 129). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.281494Z","level":"info","event":"25/12/28 17:43:08 INFO TaskSetManager: Finished task 1.0 in stage 76.0 (TID 129) in 185 ms on c252dd92c865 (executor driver) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.354347Z","level":"info","event":"25/12/28 17:43:08 INFO Executor: Finished task 0.0 in stage 76.0 (TID 128). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.356156Z","level":"info","event":"25/12/28 17:43:08 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 128) in 259 ms on c252dd92c865 (executor driver) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.356448Z","level":"info","event":"25/12/28 17:43:08 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.358074Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: ShuffleMapStage 76 (count at <unknown>:0) finished in 0.272 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.358409Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.358660Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.358835Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.359035Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.444051Z","level":"info","event":"25/12/28 17:43:08 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.461935Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Got job 53 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.462470Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Final stage: ResultStage 78 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.462672Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.462832Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.465646Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[214] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.478496Z","level":"info","event":"25/12/28 17:43:08 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 12.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.494483Z","level":"info","event":"25/12/28 17:43:08 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.495322Z","level":"info","event":"25/12/28 17:43:08 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.498607Z","level":"info","event":"25/12/28 17:43:08 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.500627Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[214] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.500826Z","level":"info","event":"25/12/28 17:43:08 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.502204Z","level":"info","event":"25/12/28 17:43:08 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 130) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.504011Z","level":"info","event":"25/12/28 17:43:08 INFO Executor: Running task 0.0 in stage 78.0 (TID 130)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.521501Z","level":"info","event":"25/12/28 17:43:08 INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.521858Z","level":"info","event":"25/12/28 17:43:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.527058Z","level":"info","event":"25/12/28 17:43:08 INFO Executor: Finished task 0.0 in stage 78.0 (TID 130). 3988 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.529460Z","level":"info","event":"25/12/28 17:43:08 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 130) in 28 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.529583Z","level":"info","event":"25/12/28 17:43:08 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.531986Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: ResultStage 78 (count at <unknown>:0) finished in 0.060 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.532980Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.533604Z","level":"info","event":"25/12/28 17:43:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 78: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.534971Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Job 53 finished: count at <unknown>:0, took 0.092697 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.614516Z","level":"info","event":"25/12/28 17:43:08 INFO FileSourceStrategy: Pushed Filters: IsNull(payment_value)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.614916Z","level":"info","event":"25/12/28 17:43:08 INFO FileSourceStrategy: Post-Scan Filters: isnull(payment_value#342)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.645653Z","level":"info","event":"25/12/28 17:43:08 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.665705Z","level":"info","event":"25/12/28 17:43:08 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.666010Z","level":"info","event":"25/12/28 17:43:08 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.667243Z","level":"info","event":"25/12/28 17:43:08 INFO SparkContext: Created broadcast 87 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.672575Z","level":"info","event":"25/12/28 17:43:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.690164Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Registering RDD 218 (count at <unknown>:0) as input to shuffle 25","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.690770Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Got map stage job 54 (count at <unknown>:0) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.690885Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Final stage: ShuffleMapStage 79 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.691002Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.691093Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.697723Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Submitting ShuffleMapStage 79 (MapPartitionsRDD[218] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.702349Z","level":"info","event":"25/12/28 17:43:08 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 18.4 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.709100Z","level":"info","event":"25/12/28 17:43:08 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.710647Z","level":"info","event":"25/12/28 17:43:08 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.711722Z","level":"info","event":"25/12/28 17:43:08 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.712461Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 79 (MapPartitionsRDD[218] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.713690Z","level":"info","event":"25/12/28 17:43:08 INFO TaskSchedulerImpl: Adding task set 79.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.716365Z","level":"info","event":"25/12/28 17:43:08 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 131) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8285 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.716602Z","level":"info","event":"25/12/28 17:43:08 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 132) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8285 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.718422Z","level":"info","event":"25/12/28 17:43:08 INFO Executor: Running task 0.0 in stage 79.0 (TID 131)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.723377Z","level":"info","event":"25/12/28 17:43:08 INFO Executor: Running task 1.0 in stage 79.0 (TID 132)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.724798Z","level":"info","event":"25/12/28 17:43:08 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_payments_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.726556Z","level":"info","event":"25/12/28 17:43:08 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_payments_dataset.csv, range: 4194304-5777138, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.802404Z","level":"info","event":"25/12/28 17:43:08 INFO Executor: Finished task 1.0 in stage 79.0 (TID 132). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.806766Z","level":"info","event":"25/12/28 17:43:08 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 132) in 89 ms on c252dd92c865 (executor driver) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.890310Z","level":"info","event":"25/12/28 17:43:08 INFO Executor: Finished task 0.0 in stage 79.0 (TID 131). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.895276Z","level":"info","event":"25/12/28 17:43:08 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 131) in 179 ms on c252dd92c865 (executor driver) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.901786Z","level":"info","event":"25/12/28 17:43:08 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.905817Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: ShuffleMapStage 79 (count at <unknown>:0) finished in 0.209 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.906084Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.906204Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.906371Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.906492Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.993086Z","level":"info","event":"25/12/28 17:43:08 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.994717Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Got job 55 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.994932Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Final stage: ResultStage 81 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.995040Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 80)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.996180Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:08.997764Z","level":"info","event":"25/12/28 17:43:08 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[221] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.006267Z","level":"info","event":"25/12/28 17:43:09 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 12.5 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.025377Z","level":"info","event":"25/12/28 17:43:09 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.028831Z","level":"info","event":"25/12/28 17:43:09 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.030724Z","level":"info","event":"25/12/28 17:43:09 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.032493Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[221] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.032649Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.042019Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 133) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.054890Z","level":"info","event":"25/12/28 17:43:09 INFO Executor: Running task 0.0 in stage 81.0 (TID 133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.070018Z","level":"info","event":"25/12/28 17:43:09 INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.070764Z","level":"info","event":"25/12/28 17:43:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.078425Z","level":"info","event":"25/12/28 17:43:09 INFO Executor: Finished task 0.0 in stage 81.0 (TID 133). 3988 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.090576Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 133) in 51 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.090727Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.105278Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: ResultStage 81 (count at <unknown>:0) finished in 0.095 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.105906Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.106743Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 81: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.107976Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Job 55 finished: count at <unknown>:0, took 0.115009 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.170918Z","level":"info","event":"25/12/28 17:43:09 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.187963Z","level":"info","event":"25/12/28 17:43:09 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.315049Z","level":"info","event":"25/12/28 17:43:09 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.315398Z","level":"info","event":"25/12/28 17:43:09 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#414, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.334036Z","level":"info","event":"25/12/28 17:43:09 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 199.3 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.349588Z","level":"info","event":"25/12/28 17:43:09 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.350685Z","level":"info","event":"25/12/28 17:43:09 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on c252dd92c865:35057 (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.350786Z","level":"info","event":"25/12/28 17:43:09 INFO SparkContext: Created broadcast 90 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.351827Z","level":"info","event":"25/12/28 17:43:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.364829Z","level":"info","event":"25/12/28 17:43:09 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.366376Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Got job 56 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.366611Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Final stage: ResultStage 82 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.366687Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.366798Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.367099Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[225] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.368910Z","level":"info","event":"25/12/28 17:43:09 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 13.5 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.374810Z","level":"info","event":"25/12/28 17:43:09 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.376596Z","level":"info","event":"25/12/28 17:43:09 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on c252dd92c865:35057 (size: 6.4 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.377368Z","level":"info","event":"25/12/28 17:43:09 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.377535Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (MapPartitionsRDD[225] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.377615Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.379430Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 134) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8295 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.380270Z","level":"info","event":"25/12/28 17:43:09 INFO Executor: Running task 0.0 in stage 82.0 (TID 134)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.385604Z","level":"info","event":"25/12/28 17:43:09 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.396040Z","level":"info","event":"25/12/28 17:43:09 INFO Executor: Finished task 0.0 in stage 82.0 (TID 134). 1703 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.401412Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 134) in 22 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.401879Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.403191Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: ResultStage 82 (csv at NativeMethodAccessorImpl.java:0) finished in 0.035 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.403354Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.403411Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 82: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.404441Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Job 56 finished: csv at NativeMethodAccessorImpl.java:0, took 0.039431 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.430300Z","level":"info","event":"25/12/28 17:43:09 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.430532Z","level":"info","event":"25/12/28 17:43:09 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.433317Z","level":"info","event":"25/12/28 17:43:09 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 199.3 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.447066Z","level":"info","event":"25/12/28 17:43:09 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.447235Z","level":"info","event":"25/12/28 17:43:09 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on c252dd92c865:35057 (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.448219Z","level":"info","event":"25/12/28 17:43:09 INFO SparkContext: Created broadcast 92 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.449762Z","level":"info","event":"25/12/28 17:43:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.464721Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.479864Z","level":"info","event":"25/12/28 17:43:09 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.480268Z","level":"info","event":"25/12/28 17:43:09 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.503817Z","level":"info","event":"25/12/28 17:43:09 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 199.2 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.509673Z","level":"info","event":"25/12/28 17:43:09 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.510007Z","level":"info","event":"25/12/28 17:43:09 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.510467Z","level":"info","event":"25/12/28 17:43:09 INFO SparkContext: Created broadcast 93 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.511140Z","level":"info","event":"25/12/28 17:43:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.517727Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Registering RDD 235 (count at <unknown>:0) as input to shuffle 26","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.518095Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Got map stage job 57 (count at <unknown>:0) with 4 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.518198Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Final stage: ShuffleMapStage 83 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.518239Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.518274Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.518319Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Submitting ShuffleMapStage 83 (MapPartitionsRDD[235] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.518783Z","level":"info","event":"25/12/28 17:43:09 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 17.9 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.520990Z","level":"info","event":"25/12/28 17:43:09 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.521259Z","level":"info","event":"25/12/28 17:43:09 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on c252dd92c865:35057 (size: 8.8 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.521663Z","level":"info","event":"25/12/28 17:43:09 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.522162Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 83 (MapPartitionsRDD[235] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.522314Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSchedulerImpl: Adding task set 83.0 with 4 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.523048Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 135) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.523347Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSetManager: Starting task 1.0 in stage 83.0 (TID 136) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.523418Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSetManager: Starting task 2.0 in stage 83.0 (TID 137) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.523513Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSetManager: Starting task 3.0 in stage 83.0 (TID 138) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.524752Z","level":"info","event":"25/12/28 17:43:09 INFO Executor: Running task 1.0 in stage 83.0 (TID 136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.524839Z","level":"info","event":"25/12/28 17:43:09 INFO Executor: Running task 3.0 in stage 83.0 (TID 138)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.524866Z","level":"info","event":"25/12/28 17:43:09 INFO Executor: Running task 0.0 in stage 83.0 (TID 135)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.524884Z","level":"info","event":"25/12/28 17:43:09 INFO Executor: Running task 2.0 in stage 83.0 (TID 137)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.527193Z","level":"info","event":"25/12/28 17:43:09 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.527462Z","level":"info","event":"25/12/28 17:43:09 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.527730Z","level":"info","event":"25/12/28 17:43:09 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 12582912-14451670, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.533582Z","level":"info","event":"25/12/28 17:43:09 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.656190Z","level":"info","event":"25/12/28 17:43:09 INFO Executor: Finished task 3.0 in stage 83.0 (TID 138). 1928 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.665242Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSetManager: Finished task 3.0 in stage 83.0 (TID 138) in 141 ms on c252dd92c865 (executor driver) (1/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.747731Z","level":"info","event":"25/12/28 17:43:09 INFO BlockManagerInfo: Removed broadcast_92_piece0 on c252dd92c865:35057 in memory (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.779931Z","level":"info","event":"25/12/28 17:43:09 INFO BlockManagerInfo: Removed broadcast_85_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.793755Z","level":"info","event":"25/12/28 17:43:09 INFO BlockManagerInfo: Removed broadcast_89_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.808422Z","level":"info","event":"25/12/28 17:43:09 INFO BlockManagerInfo: Removed broadcast_84_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.808633Z","level":"info","event":"25/12/28 17:43:09 INFO Executor: Finished task 1.0 in stage 83.0 (TID 136). 2014 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.812421Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSetManager: Finished task 1.0 in stage 83.0 (TID 136) in 287 ms on c252dd92c865 (executor driver) (2/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.817479Z","level":"info","event":"25/12/28 17:43:09 INFO BlockManagerInfo: Removed broadcast_88_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.825579Z","level":"info","event":"25/12/28 17:43:09 INFO Executor: Finished task 2.0 in stage 83.0 (TID 137). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.830987Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSetManager: Finished task 2.0 in stage 83.0 (TID 137) in 306 ms on c252dd92c865 (executor driver) (3/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.831525Z","level":"info","event":"25/12/28 17:43:09 INFO Executor: Finished task 0.0 in stage 83.0 (TID 135). 2014 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.832436Z","level":"info","event":"25/12/28 17:43:09 INFO BlockManagerInfo: Removed broadcast_90_piece0 on c252dd92c865:35057 in memory (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.833669Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 135) in 311 ms on c252dd92c865 (executor driver) (4/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.833736Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.834493Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: ShuffleMapStage 83 (count at <unknown>:0) finished in 0.317 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.834741Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.834953Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.835106Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.835263Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.837350Z","level":"info","event":"25/12/28 17:43:09 INFO BlockManagerInfo: Removed broadcast_86_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.839447Z","level":"info","event":"25/12/28 17:43:09 INFO BlockManagerInfo: Removed broadcast_81_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.850040Z","level":"info","event":"25/12/28 17:43:09 INFO BlockManagerInfo: Removed broadcast_87_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.855141Z","level":"info","event":"25/12/28 17:43:09 INFO BlockManagerInfo: Removed broadcast_82_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.857180Z","level":"info","event":"25/12/28 17:43:09 INFO BlockManagerInfo: Removed broadcast_91_piece0 on c252dd92c865:35057 in memory (size: 6.4 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.866267Z","level":"info","event":"25/12/28 17:43:09 INFO BlockManagerInfo: Removed broadcast_83_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.892820Z","level":"info","event":"25/12/28 17:43:09 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.899602Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Got job 58 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.899804Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Final stage: ResultStage 85 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.899885Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 84)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.899924Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.900411Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[238] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.903463Z","level":"info","event":"25/12/28 17:43:09 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.911683Z","level":"info","event":"25/12/28 17:43:09 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.912822Z","level":"info","event":"25/12/28 17:43:09 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.914231Z","level":"info","event":"25/12/28 17:43:09 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.914560Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[238] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.914675Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.917353Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 139) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.919568Z","level":"info","event":"25/12/28 17:43:09 INFO Executor: Running task 0.0 in stage 85.0 (TID 139)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.928661Z","level":"info","event":"25/12/28 17:43:09 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.929467Z","level":"info","event":"25/12/28 17:43:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.931869Z","level":"info","event":"25/12/28 17:43:09 INFO Executor: Finished task 0.0 in stage 85.0 (TID 139). 3995 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.932701Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 139) in 16 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.932861Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.933073Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: ResultStage 85 (count at <unknown>:0) finished in 0.032 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.933186Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.933267Z","level":"info","event":"25/12/28 17:43:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 85: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.933377Z","level":"info","event":"25/12/28 17:43:09 INFO DAGScheduler: Job 58 finished: count at <unknown>:0, took 0.040572 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.937740Z","level":"info","event":"Loaded olist_order_reviews with 104162 records.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.979986Z","level":"info","event":"25/12/28 17:43:09 INFO FileSourceStrategy: Pushed Filters: IsNull(review_id)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.980142Z","level":"info","event":"25/12/28 17:43:09 INFO FileSourceStrategy: Post-Scan Filters: isnull(review_id#431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:09.993835Z","level":"info","event":"25/12/28 17:43:09 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 199.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.005276Z","level":"info","event":"25/12/28 17:43:10 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.005859Z","level":"info","event":"25/12/28 17:43:10 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.007111Z","level":"info","event":"25/12/28 17:43:10 INFO SparkContext: Created broadcast 96 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.009690Z","level":"info","event":"25/12/28 17:43:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.017574Z","level":"info","event":"25/12/28 17:43:10 INFO DAGScheduler: Registering RDD 242 (count at <unknown>:0) as input to shuffle 27","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.018417Z","level":"info","event":"25/12/28 17:43:10 INFO DAGScheduler: Got map stage job 59 (count at <unknown>:0) with 4 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.018951Z","level":"info","event":"25/12/28 17:43:10 INFO DAGScheduler: Final stage: ShuffleMapStage 86 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.019115Z","level":"info","event":"25/12/28 17:43:10 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.019193Z","level":"info","event":"25/12/28 17:43:10 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.019415Z","level":"info","event":"25/12/28 17:43:10 INFO DAGScheduler: Submitting ShuffleMapStage 86 (MapPartitionsRDD[242] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.025402Z","level":"info","event":"25/12/28 17:43:10 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 18.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.027685Z","level":"info","event":"25/12/28 17:43:10 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.028815Z","level":"info","event":"25/12/28 17:43:10 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.029800Z","level":"info","event":"25/12/28 17:43:10 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.030035Z","level":"info","event":"25/12/28 17:43:10 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 86 (MapPartitionsRDD[242] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.030322Z","level":"info","event":"25/12/28 17:43:10 INFO TaskSchedulerImpl: Adding task set 86.0 with 4 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.032467Z","level":"info","event":"25/12/28 17:43:10 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 140) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.032879Z","level":"info","event":"25/12/28 17:43:10 INFO TaskSetManager: Starting task 1.0 in stage 86.0 (TID 141) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.033133Z","level":"info","event":"25/12/28 17:43:10 INFO TaskSetManager: Starting task 2.0 in stage 86.0 (TID 142) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.033743Z","level":"info","event":"25/12/28 17:43:10 INFO TaskSetManager: Starting task 3.0 in stage 86.0 (TID 143) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.035866Z","level":"info","event":"25/12/28 17:43:10 INFO Executor: Running task 1.0 in stage 86.0 (TID 141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.036635Z","level":"info","event":"25/12/28 17:43:10 INFO Executor: Running task 0.0 in stage 86.0 (TID 140)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.036740Z","level":"info","event":"25/12/28 17:43:10 INFO Executor: Running task 2.0 in stage 86.0 (TID 142)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.036776Z","level":"info","event":"25/12/28 17:43:10 INFO Executor: Running task 3.0 in stage 86.0 (TID 143)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.043628Z","level":"info","event":"25/12/28 17:43:10 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.043885Z","level":"info","event":"25/12/28 17:43:10 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.043990Z","level":"info","event":"25/12/28 17:43:10 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 12582912-14451670, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.044080Z","level":"info","event":"25/12/28 17:43:10 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.290376Z","level":"info","event":"25/12/28 17:43:10 INFO Executor: Finished task 3.0 in stage 86.0 (TID 143). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.293179Z","level":"info","event":"25/12/28 17:43:10 INFO TaskSetManager: Finished task 3.0 in stage 86.0 (TID 143) in 259 ms on c252dd92c865 (executor driver) (1/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.526221Z","level":"info","event":"25/12/28 17:43:10 INFO Executor: Finished task 2.0 in stage 86.0 (TID 142). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.537359Z","level":"info","event":"25/12/28 17:43:10 INFO Executor: Finished task 0.0 in stage 86.0 (TID 140). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.539501Z","level":"info","event":"25/12/28 17:43:10 INFO Executor: Finished task 1.0 in stage 86.0 (TID 141). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.540949Z","level":"info","event":"25/12/28 17:43:10 INFO TaskSetManager: Finished task 1.0 in stage 86.0 (TID 141) in 508 ms on c252dd92c865 (executor driver) (2/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.541136Z","level":"info","event":"25/12/28 17:43:10 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 140) in 509 ms on c252dd92c865 (executor driver) (3/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.541213Z","level":"info","event":"25/12/28 17:43:10 INFO TaskSetManager: Finished task 2.0 in stage 86.0 (TID 142) in 508 ms on c252dd92c865 (executor driver) (4/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.541330Z","level":"info","event":"25/12/28 17:43:10 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.547738Z","level":"info","event":"25/12/28 17:43:10 INFO DAGScheduler: ShuffleMapStage 86 (count at <unknown>:0) finished in 0.524 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.550000Z","level":"info","event":"25/12/28 17:43:10 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.556442Z","level":"info","event":"25/12/28 17:43:10 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.556912Z","level":"info","event":"25/12/28 17:43:10 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.557038Z","level":"info","event":"25/12/28 17:43:10 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.704627Z","level":"info","event":"25/12/28 17:43:10 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.711420Z","level":"info","event":"25/12/28 17:43:10 INFO DAGScheduler: Got job 60 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.711709Z","level":"info","event":"25/12/28 17:43:10 INFO DAGScheduler: Final stage: ResultStage 88 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.711823Z","level":"info","event":"25/12/28 17:43:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 87)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.712716Z","level":"info","event":"25/12/28 17:43:10 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.714387Z","level":"info","event":"25/12/28 17:43:10 INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[245] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.733581Z","level":"info","event":"25/12/28 17:43:10 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 12.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.744208Z","level":"info","event":"25/12/28 17:43:10 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.753070Z","level":"info","event":"25/12/28 17:43:10 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.755247Z","level":"info","event":"25/12/28 17:43:10 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.755832Z","level":"info","event":"25/12/28 17:43:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[245] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.759279Z","level":"info","event":"25/12/28 17:43:10 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.759509Z","level":"info","event":"25/12/28 17:43:10 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 144) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.767399Z","level":"info","event":"25/12/28 17:43:10 INFO Executor: Running task 0.0 in stage 88.0 (TID 144)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.789495Z","level":"info","event":"25/12/28 17:43:10 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.789859Z","level":"info","event":"25/12/28 17:43:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.799661Z","level":"info","event":"25/12/28 17:43:10 INFO Executor: Finished task 0.0 in stage 88.0 (TID 144). 3995 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.802207Z","level":"info","event":"25/12/28 17:43:10 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 144) in 43 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.802380Z","level":"info","event":"25/12/28 17:43:10 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.803048Z","level":"info","event":"25/12/28 17:43:10 INFO DAGScheduler: ResultStage 88 (count at <unknown>:0) finished in 0.082 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.803248Z","level":"info","event":"25/12/28 17:43:10 INFO DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.803368Z","level":"info","event":"25/12/28 17:43:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 88: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.804030Z","level":"info","event":"25/12/28 17:43:10 INFO DAGScheduler: Job 60 finished: count at <unknown>:0, took 0.100222 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.820951Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.826586Z","level":"info","event":"Column review_id (StringType()) in olist_order_reviews has 1 null values.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.940707Z","level":"info","event":"25/12/28 17:43:10 INFO FileSourceStrategy: Pushed Filters: IsNull(order_id)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.940859Z","level":"info","event":"25/12/28 17:43:10 INFO FileSourceStrategy: Post-Scan Filters: isnull(order_id#432)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.983213Z","level":"info","event":"25/12/28 17:43:10 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.996833Z","level":"info","event":"25/12/28 17:43:10 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.997662Z","level":"info","event":"25/12/28 17:43:10 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:10.998395Z","level":"info","event":"25/12/28 17:43:10 INFO SparkContext: Created broadcast 99 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.000443Z","level":"info","event":"25/12/28 17:43:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.005225Z","level":"info","event":"25/12/28 17:43:11 INFO DAGScheduler: Registering RDD 249 (count at <unknown>:0) as input to shuffle 28","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.005579Z","level":"info","event":"25/12/28 17:43:11 INFO DAGScheduler: Got map stage job 61 (count at <unknown>:0) with 4 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.005676Z","level":"info","event":"25/12/28 17:43:11 INFO DAGScheduler: Final stage: ShuffleMapStage 89 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.005714Z","level":"info","event":"25/12/28 17:43:11 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.005759Z","level":"info","event":"25/12/28 17:43:11 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.005890Z","level":"info","event":"25/12/28 17:43:11 INFO DAGScheduler: Submitting ShuffleMapStage 89 (MapPartitionsRDD[249] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.007980Z","level":"info","event":"25/12/28 17:43:11 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 18.5 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.011091Z","level":"info","event":"25/12/28 17:43:11 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.011527Z","level":"info","event":"25/12/28 17:43:11 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.011913Z","level":"info","event":"25/12/28 17:43:11 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.012321Z","level":"info","event":"25/12/28 17:43:11 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 89 (MapPartitionsRDD[249] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.012487Z","level":"info","event":"25/12/28 17:43:11 INFO TaskSchedulerImpl: Adding task set 89.0 with 4 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.015331Z","level":"info","event":"25/12/28 17:43:11 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 145) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.016219Z","level":"info","event":"25/12/28 17:43:11 INFO TaskSetManager: Starting task 1.0 in stage 89.0 (TID 146) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.016909Z","level":"info","event":"25/12/28 17:43:11 INFO TaskSetManager: Starting task 2.0 in stage 89.0 (TID 147) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.017536Z","level":"info","event":"25/12/28 17:43:11 INFO TaskSetManager: Starting task 3.0 in stage 89.0 (TID 148) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.020003Z","level":"info","event":"25/12/28 17:43:11 INFO Executor: Running task 0.0 in stage 89.0 (TID 145)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.020328Z","level":"info","event":"25/12/28 17:43:11 INFO Executor: Running task 3.0 in stage 89.0 (TID 148)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.020563Z","level":"info","event":"25/12/28 17:43:11 INFO Executor: Running task 2.0 in stage 89.0 (TID 147)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.020731Z","level":"info","event":"25/12/28 17:43:11 INFO Executor: Running task 1.0 in stage 89.0 (TID 146)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.029780Z","level":"info","event":"25/12/28 17:43:11 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 12582912-14451670, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.030089Z","level":"info","event":"25/12/28 17:43:11 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.030360Z","level":"info","event":"25/12/28 17:43:11 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.030698Z","level":"info","event":"25/12/28 17:43:11 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.203525Z","level":"info","event":"25/12/28 17:43:11 INFO Executor: Finished task 3.0 in stage 89.0 (TID 148). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.216269Z","level":"info","event":"25/12/28 17:43:11 INFO TaskSetManager: Finished task 3.0 in stage 89.0 (TID 148) in 198 ms on c252dd92c865 (executor driver) (1/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.295517Z","level":"info","event":"25/12/28 17:43:11 INFO Executor: Finished task 1.0 in stage 89.0 (TID 146). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.298981Z","level":"info","event":"25/12/28 17:43:11 INFO TaskSetManager: Finished task 1.0 in stage 89.0 (TID 146) in 282 ms on c252dd92c865 (executor driver) (2/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.359226Z","level":"info","event":"25/12/28 17:43:11 INFO Executor: Finished task 0.0 in stage 89.0 (TID 145). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.361194Z","level":"info","event":"25/12/28 17:43:11 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 145) in 347 ms on c252dd92c865 (executor driver) (3/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.434023Z","level":"info","event":"25/12/28 17:43:11 INFO Executor: Finished task 2.0 in stage 89.0 (TID 147). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.437358Z","level":"info","event":"25/12/28 17:43:11 INFO TaskSetManager: Finished task 2.0 in stage 89.0 (TID 147) in 421 ms on c252dd92c865 (executor driver) (4/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.440709Z","level":"info","event":"25/12/28 17:43:11 INFO DAGScheduler: ShuffleMapStage 89 (count at <unknown>:0) finished in 0.431 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.440960Z","level":"info","event":"25/12/28 17:43:11 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.441093Z","level":"info","event":"25/12/28 17:43:11 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.441206Z","level":"info","event":"25/12/28 17:43:11 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.441667Z","level":"info","event":"25/12/28 17:43:11 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.441960Z","level":"info","event":"25/12/28 17:43:11 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.567143Z","level":"info","event":"25/12/28 17:43:11 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.582512Z","level":"info","event":"25/12/28 17:43:11 INFO DAGScheduler: Got job 62 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.583044Z","level":"info","event":"25/12/28 17:43:11 INFO DAGScheduler: Final stage: ResultStage 91 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.583177Z","level":"info","event":"25/12/28 17:43:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 90)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.588597Z","level":"info","event":"25/12/28 17:43:11 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.589521Z","level":"info","event":"25/12/28 17:43:11 INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[252] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.599766Z","level":"info","event":"25/12/28 17:43:11 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 12.5 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.620126Z","level":"info","event":"25/12/28 17:43:11 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.620392Z","level":"info","event":"25/12/28 17:43:11 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.624213Z","level":"info","event":"25/12/28 17:43:11 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.624407Z","level":"info","event":"25/12/28 17:43:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[252] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.624632Z","level":"info","event":"25/12/28 17:43:11 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.634849Z","level":"info","event":"25/12/28 17:43:11 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 149) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.635867Z","level":"info","event":"25/12/28 17:43:11 INFO Executor: Running task 0.0 in stage 91.0 (TID 149)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.712086Z","level":"info","event":"25/12/28 17:43:11 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.718568Z","level":"info","event":"25/12/28 17:43:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.742679Z","level":"info","event":"25/12/28 17:43:11 INFO Executor: Finished task 0.0 in stage 91.0 (TID 149). 4038 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.750181Z","level":"info","event":"25/12/28 17:43:11 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 149) in 115 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.750646Z","level":"info","event":"25/12/28 17:43:11 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.771318Z","level":"info","event":"25/12/28 17:43:11 INFO DAGScheduler: ResultStage 91 (count at <unknown>:0) finished in 0.160 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.771564Z","level":"info","event":"25/12/28 17:43:11 INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.771669Z","level":"info","event":"25/12/28 17:43:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 91: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.780850Z","level":"info","event":"25/12/28 17:43:11 INFO DAGScheduler: Job 62 finished: count at <unknown>:0, took 0.206197 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.862864Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:11.869999Z","level":"info","event":"Column order_id (StringType()) in olist_order_reviews has 2236 null values.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.280648Z","level":"info","event":"25/12/28 17:43:12 INFO FileSourceStrategy: Pushed Filters: IsNull(review_score)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.284865Z","level":"info","event":"25/12/28 17:43:12 INFO FileSourceStrategy: Post-Scan Filters: isnull(review_score#433)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.355858Z","level":"info","event":"25/12/28 17:43:12 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 199.2 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.394796Z","level":"info","event":"25/12/28 17:43:12 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.402202Z","level":"info","event":"25/12/28 17:43:12 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.407031Z","level":"info","event":"25/12/28 17:43:12 INFO SparkContext: Created broadcast 102 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.419902Z","level":"info","event":"25/12/28 17:43:12 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.450558Z","level":"info","event":"25/12/28 17:43:12 INFO DAGScheduler: Registering RDD 256 (count at <unknown>:0) as input to shuffle 29","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.455939Z","level":"info","event":"25/12/28 17:43:12 INFO DAGScheduler: Got map stage job 63 (count at <unknown>:0) with 4 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.457044Z","level":"info","event":"25/12/28 17:43:12 INFO DAGScheduler: Final stage: ShuffleMapStage 92 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.457295Z","level":"info","event":"25/12/28 17:43:12 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.462237Z","level":"info","event":"25/12/28 17:43:12 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.466777Z","level":"info","event":"25/12/28 17:43:12 INFO DAGScheduler: Submitting ShuffleMapStage 92 (MapPartitionsRDD[256] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.474207Z","level":"info","event":"25/12/28 17:43:12 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 18.5 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.477111Z","level":"info","event":"25/12/28 17:43:12 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.477500Z","level":"info","event":"25/12/28 17:43:12 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.479401Z","level":"info","event":"25/12/28 17:43:12 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.481060Z","level":"info","event":"25/12/28 17:43:12 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 92 (MapPartitionsRDD[256] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.481991Z","level":"info","event":"25/12/28 17:43:12 INFO TaskSchedulerImpl: Adding task set 92.0 with 4 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.492306Z","level":"info","event":"25/12/28 17:43:12 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 150) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.492668Z","level":"info","event":"25/12/28 17:43:12 INFO TaskSetManager: Starting task 1.0 in stage 92.0 (TID 151) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.492807Z","level":"info","event":"25/12/28 17:43:12 INFO TaskSetManager: Starting task 2.0 in stage 92.0 (TID 152) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.493541Z","level":"info","event":"25/12/28 17:43:12 INFO TaskSetManager: Starting task 3.0 in stage 92.0 (TID 153) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.504941Z","level":"info","event":"25/12/28 17:43:12 INFO Executor: Running task 0.0 in stage 92.0 (TID 150)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.505222Z","level":"info","event":"25/12/28 17:43:12 INFO Executor: Running task 2.0 in stage 92.0 (TID 152)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.506065Z","level":"info","event":"25/12/28 17:43:12 INFO Executor: Running task 1.0 in stage 92.0 (TID 151)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.506387Z","level":"info","event":"25/12/28 17:43:12 INFO Executor: Running task 3.0 in stage 92.0 (TID 153)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.531949Z","level":"info","event":"25/12/28 17:43:12 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.534560Z","level":"info","event":"25/12/28 17:43:12 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.534808Z","level":"info","event":"25/12/28 17:43:12 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.536167Z","level":"info","event":"25/12/28 17:43:12 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 12582912-14451670, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.616832Z","level":"info","event":"25/12/28 17:43:12 INFO BlockManagerInfo: Removed broadcast_96_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.630980Z","level":"info","event":"25/12/28 17:43:12 INFO BlockManagerInfo: Removed broadcast_95_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.657321Z","level":"info","event":"25/12/28 17:43:12 INFO BlockManagerInfo: Removed broadcast_94_piece0 on c252dd92c865:35057 in memory (size: 8.8 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.662011Z","level":"info","event":"25/12/28 17:43:12 INFO BlockManagerInfo: Removed broadcast_99_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.678365Z","level":"info","event":"25/12/28 17:43:12 INFO BlockManagerInfo: Removed broadcast_97_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.685196Z","level":"info","event":"25/12/28 17:43:12 INFO BlockManagerInfo: Removed broadcast_93_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.696327Z","level":"info","event":"25/12/28 17:43:12 INFO BlockManagerInfo: Removed broadcast_101_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.708708Z","level":"info","event":"25/12/28 17:43:12 INFO BlockManagerInfo: Removed broadcast_98_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.711098Z","level":"info","event":"25/12/28 17:43:12 INFO BlockManagerInfo: Removed broadcast_100_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.783624Z","level":"info","event":"25/12/28 17:43:12 INFO Executor: Finished task 3.0 in stage 92.0 (TID 153). 2070 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.790365Z","level":"info","event":"25/12/28 17:43:12 INFO TaskSetManager: Finished task 3.0 in stage 92.0 (TID 153) in 297 ms on c252dd92c865 (executor driver) (1/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.807284Z","level":"info","event":"25/12/28 17:43:12 INFO Executor: Finished task 2.0 in stage 92.0 (TID 152). 2070 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.812336Z","level":"info","event":"25/12/28 17:43:12 INFO TaskSetManager: Finished task 2.0 in stage 92.0 (TID 152) in 319 ms on c252dd92c865 (executor driver) (2/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.832949Z","level":"info","event":"25/12/28 17:43:12 INFO Executor: Finished task 0.0 in stage 92.0 (TID 150). 2070 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:12.834571Z","level":"info","event":"25/12/28 17:43:12 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 150) in 345 ms on c252dd92c865 (executor driver) (3/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.160384Z","level":"info","event":"25/12/28 17:43:13 INFO Executor: Finished task 1.0 in stage 92.0 (TID 151). 2070 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.180624Z","level":"info","event":"25/12/28 17:43:13 INFO TaskSetManager: Finished task 1.0 in stage 92.0 (TID 151) in 686 ms on c252dd92c865 (executor driver) (4/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.183689Z","level":"info","event":"25/12/28 17:43:13 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.202258Z","level":"info","event":"25/12/28 17:43:13 INFO DAGScheduler: ShuffleMapStage 92 (count at <unknown>:0) finished in 0.720 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.202491Z","level":"info","event":"25/12/28 17:43:13 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.202562Z","level":"info","event":"25/12/28 17:43:13 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.202602Z","level":"info","event":"25/12/28 17:43:13 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.202639Z","level":"info","event":"25/12/28 17:43:13 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.378962Z","level":"info","event":"25/12/28 17:43:13 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.383448Z","level":"info","event":"25/12/28 17:43:13 INFO DAGScheduler: Got job 64 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.383586Z","level":"info","event":"25/12/28 17:43:13 INFO DAGScheduler: Final stage: ResultStage 94 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.383648Z","level":"info","event":"25/12/28 17:43:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 93)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.383699Z","level":"info","event":"25/12/28 17:43:13 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.387583Z","level":"info","event":"25/12/28 17:43:13 INFO DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[259] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.402066Z","level":"info","event":"25/12/28 17:43:13 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.412663Z","level":"info","event":"25/12/28 17:43:13 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.415552Z","level":"info","event":"25/12/28 17:43:13 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.418356Z","level":"info","event":"25/12/28 17:43:13 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.418493Z","level":"info","event":"25/12/28 17:43:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[259] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.419457Z","level":"info","event":"25/12/28 17:43:13 INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.427279Z","level":"info","event":"25/12/28 17:43:13 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 154) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.430081Z","level":"info","event":"25/12/28 17:43:13 INFO Executor: Running task 0.0 in stage 94.0 (TID 154)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.452249Z","level":"info","event":"25/12/28 17:43:13 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.452586Z","level":"info","event":"25/12/28 17:43:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.460948Z","level":"info","event":"25/12/28 17:43:13 INFO Executor: Finished task 0.0 in stage 94.0 (TID 154). 4038 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.463633Z","level":"info","event":"25/12/28 17:43:13 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 154) in 37 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.463779Z","level":"info","event":"25/12/28 17:43:13 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.464855Z","level":"info","event":"25/12/28 17:43:13 INFO DAGScheduler: ResultStage 94 (count at <unknown>:0) finished in 0.071 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.466111Z","level":"info","event":"25/12/28 17:43:13 INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.466601Z","level":"info","event":"25/12/28 17:43:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 94: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.467266Z","level":"info","event":"25/12/28 17:43:13 INFO DAGScheduler: Job 64 finished: count at <unknown>:0, took 0.088676 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.486734Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.487710Z","level":"info","event":"Column review_score (StringType()) in olist_order_reviews has 2380 null values.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.583761Z","level":"info","event":"25/12/28 17:43:13 INFO FileSourceStrategy: Pushed Filters: IsNull(review_comment_title)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.583910Z","level":"info","event":"25/12/28 17:43:13 INFO FileSourceStrategy: Post-Scan Filters: isnull(review_comment_title#434)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.662767Z","level":"info","event":"25/12/28 17:43:13 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 199.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.722708Z","level":"info","event":"25/12/28 17:43:13 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.723316Z","level":"info","event":"25/12/28 17:43:13 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.729587Z","level":"info","event":"25/12/28 17:43:13 INFO SparkContext: Created broadcast 105 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.733043Z","level":"info","event":"25/12/28 17:43:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.748043Z","level":"info","event":"25/12/28 17:43:13 INFO DAGScheduler: Registering RDD 263 (count at <unknown>:0) as input to shuffle 30","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.749407Z","level":"info","event":"25/12/28 17:43:13 INFO DAGScheduler: Got map stage job 65 (count at <unknown>:0) with 4 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.749554Z","level":"info","event":"25/12/28 17:43:13 INFO DAGScheduler: Final stage: ShuffleMapStage 95 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.749597Z","level":"info","event":"25/12/28 17:43:13 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.749654Z","level":"info","event":"25/12/28 17:43:13 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.753868Z","level":"info","event":"25/12/28 17:43:13 INFO DAGScheduler: Submitting ShuffleMapStage 95 (MapPartitionsRDD[263] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.769929Z","level":"info","event":"25/12/28 17:43:13 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 18.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.776560Z","level":"info","event":"25/12/28 17:43:13 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.780749Z","level":"info","event":"25/12/28 17:43:13 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.780999Z","level":"info","event":"25/12/28 17:43:13 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.781110Z","level":"info","event":"25/12/28 17:43:13 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 95 (MapPartitionsRDD[263] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.781861Z","level":"info","event":"25/12/28 17:43:13 INFO TaskSchedulerImpl: Adding task set 95.0 with 4 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.793324Z","level":"info","event":"25/12/28 17:43:13 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 155) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.796203Z","level":"info","event":"25/12/28 17:43:13 INFO TaskSetManager: Starting task 1.0 in stage 95.0 (TID 156) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.798243Z","level":"info","event":"25/12/28 17:43:13 INFO TaskSetManager: Starting task 2.0 in stage 95.0 (TID 157) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.798940Z","level":"info","event":"25/12/28 17:43:13 INFO TaskSetManager: Starting task 3.0 in stage 95.0 (TID 158) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.805642Z","level":"info","event":"25/12/28 17:43:13 INFO Executor: Running task 3.0 in stage 95.0 (TID 158)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.809618Z","level":"info","event":"25/12/28 17:43:13 INFO Executor: Running task 2.0 in stage 95.0 (TID 157)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.810117Z","level":"info","event":"25/12/28 17:43:13 INFO Executor: Running task 0.0 in stage 95.0 (TID 155)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.812089Z","level":"info","event":"25/12/28 17:43:13 INFO Executor: Running task 1.0 in stage 95.0 (TID 156)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.826605Z","level":"info","event":"25/12/28 17:43:13 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 12582912-14451670, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.827872Z","level":"info","event":"25/12/28 17:43:13 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.885552Z","level":"info","event":"25/12/28 17:43:13 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:13.886189Z","level":"info","event":"25/12/28 17:43:13 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.372595Z","level":"info","event":"25/12/28 17:43:14 INFO Executor: Finished task 3.0 in stage 95.0 (TID 158). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.386285Z","level":"info","event":"25/12/28 17:43:14 INFO Executor: Finished task 2.0 in stage 95.0 (TID 157). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.446771Z","level":"info","event":"25/12/28 17:43:14 INFO TaskSetManager: Finished task 2.0 in stage 95.0 (TID 157) in 642 ms on c252dd92c865 (executor driver) (1/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.461668Z","level":"info","event":"25/12/28 17:43:14 INFO TaskSetManager: Finished task 3.0 in stage 95.0 (TID 158) in 663 ms on c252dd92c865 (executor driver) (2/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.597613Z","level":"info","event":"25/12/28 17:43:14 INFO Executor: Finished task 1.0 in stage 95.0 (TID 156). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.603692Z","level":"info","event":"25/12/28 17:43:14 INFO Executor: Finished task 0.0 in stage 95.0 (TID 155). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.603852Z","level":"info","event":"25/12/28 17:43:14 INFO TaskSetManager: Finished task 1.0 in stage 95.0 (TID 156) in 808 ms on c252dd92c865 (executor driver) (3/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.620098Z","level":"info","event":"25/12/28 17:43:14 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 155) in 826 ms on c252dd92c865 (executor driver) (4/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.620597Z","level":"info","event":"25/12/28 17:43:14 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.631720Z","level":"info","event":"25/12/28 17:43:14 INFO DAGScheduler: ShuffleMapStage 95 (count at <unknown>:0) finished in 0.865 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.632249Z","level":"info","event":"25/12/28 17:43:14 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.632784Z","level":"info","event":"25/12/28 17:43:14 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.634495Z","level":"info","event":"25/12/28 17:43:14 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.640078Z","level":"info","event":"25/12/28 17:43:14 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.739605Z","level":"info","event":"25/12/28 17:43:14 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.744805Z","level":"info","event":"25/12/28 17:43:14 INFO DAGScheduler: Got job 66 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.745033Z","level":"info","event":"25/12/28 17:43:14 INFO DAGScheduler: Final stage: ResultStage 97 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.745104Z","level":"info","event":"25/12/28 17:43:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 96)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.745306Z","level":"info","event":"25/12/28 17:43:14 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.748565Z","level":"info","event":"25/12/28 17:43:14 INFO DAGScheduler: Submitting ResultStage 97 (MapPartitionsRDD[266] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.754596Z","level":"info","event":"25/12/28 17:43:14 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 12.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.769157Z","level":"info","event":"25/12/28 17:43:14 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.771132Z","level":"info","event":"25/12/28 17:43:14 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.772713Z","level":"info","event":"25/12/28 17:43:14 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.774142Z","level":"info","event":"25/12/28 17:43:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 97 (MapPartitionsRDD[266] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.774297Z","level":"info","event":"25/12/28 17:43:14 INFO TaskSchedulerImpl: Adding task set 97.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.779481Z","level":"info","event":"25/12/28 17:43:14 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 159) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.780776Z","level":"info","event":"25/12/28 17:43:14 INFO Executor: Running task 0.0 in stage 97.0 (TID 159)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.806832Z","level":"info","event":"25/12/28 17:43:14 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.809625Z","level":"info","event":"25/12/28 17:43:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.830356Z","level":"info","event":"25/12/28 17:43:14 INFO Executor: Finished task 0.0 in stage 97.0 (TID 159). 4038 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.836293Z","level":"info","event":"25/12/28 17:43:14 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 159) in 58 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.836770Z","level":"info","event":"25/12/28 17:43:14 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.846738Z","level":"info","event":"25/12/28 17:43:14 INFO DAGScheduler: ResultStage 97 (count at <unknown>:0) finished in 0.090 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.846999Z","level":"info","event":"25/12/28 17:43:14 INFO DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.847330Z","level":"info","event":"25/12/28 17:43:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 97: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.849582Z","level":"info","event":"25/12/28 17:43:14 INFO DAGScheduler: Job 66 finished: count at <unknown>:0, took 0.108877 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.887299Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:14.887961Z","level":"info","event":"Column review_comment_title (StringType()) in olist_order_reviews has 92157 null values.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.230101Z","level":"info","event":"25/12/28 17:43:15 INFO FileSourceStrategy: Pushed Filters: IsNull(review_comment_message)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.232083Z","level":"info","event":"25/12/28 17:43:15 INFO FileSourceStrategy: Post-Scan Filters: isnull(review_comment_message#435)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.342461Z","level":"info","event":"25/12/28 17:43:15 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.376744Z","level":"info","event":"25/12/28 17:43:15 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.385562Z","level":"info","event":"25/12/28 17:43:15 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.390815Z","level":"info","event":"25/12/28 17:43:15 INFO SparkContext: Created broadcast 108 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.402381Z","level":"info","event":"25/12/28 17:43:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.433794Z","level":"info","event":"25/12/28 17:43:15 INFO DAGScheduler: Registering RDD 270 (count at <unknown>:0) as input to shuffle 31","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.435721Z","level":"info","event":"25/12/28 17:43:15 INFO DAGScheduler: Got map stage job 67 (count at <unknown>:0) with 4 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.435979Z","level":"info","event":"25/12/28 17:43:15 INFO DAGScheduler: Final stage: ShuffleMapStage 98 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.436116Z","level":"info","event":"25/12/28 17:43:15 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.436242Z","level":"info","event":"25/12/28 17:43:15 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.438734Z","level":"info","event":"25/12/28 17:43:15 INFO DAGScheduler: Submitting ShuffleMapStage 98 (MapPartitionsRDD[270] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.444173Z","level":"info","event":"25/12/28 17:43:15 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 18.5 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.446469Z","level":"info","event":"25/12/28 17:43:15 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.446895Z","level":"info","event":"25/12/28 17:43:15 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.447928Z","level":"info","event":"25/12/28 17:43:15 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.450602Z","level":"info","event":"25/12/28 17:43:15 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 98 (MapPartitionsRDD[270] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.450861Z","level":"info","event":"25/12/28 17:43:15 INFO TaskSchedulerImpl: Adding task set 98.0 with 4 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.457652Z","level":"info","event":"25/12/28 17:43:15 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 160) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.459522Z","level":"info","event":"25/12/28 17:43:15 INFO TaskSetManager: Starting task 1.0 in stage 98.0 (TID 161) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.459690Z","level":"info","event":"25/12/28 17:43:15 INFO TaskSetManager: Starting task 2.0 in stage 98.0 (TID 162) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.460320Z","level":"info","event":"25/12/28 17:43:15 INFO TaskSetManager: Starting task 3.0 in stage 98.0 (TID 163) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.463323Z","level":"info","event":"25/12/28 17:43:15 INFO Executor: Running task 1.0 in stage 98.0 (TID 161)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.471595Z","level":"info","event":"25/12/28 17:43:15 INFO Executor: Running task 3.0 in stage 98.0 (TID 163)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.472048Z","level":"info","event":"25/12/28 17:43:15 INFO Executor: Running task 2.0 in stage 98.0 (TID 162)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.472319Z","level":"info","event":"25/12/28 17:43:15 INFO Executor: Running task 0.0 in stage 98.0 (TID 160)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.482793Z","level":"info","event":"25/12/28 17:43:15 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.483073Z","level":"info","event":"25/12/28 17:43:15 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 12582912-14451670, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.483321Z","level":"info","event":"25/12/28 17:43:15 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.493532Z","level":"info","event":"25/12/28 17:43:15 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.732008Z","level":"info","event":"25/12/28 17:43:15 INFO BlockManagerInfo: Removed broadcast_103_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.744541Z","level":"info","event":"25/12/28 17:43:15 INFO BlockManagerInfo: Removed broadcast_106_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.750553Z","level":"info","event":"25/12/28 17:43:15 INFO BlockManagerInfo: Removed broadcast_105_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.772604Z","level":"info","event":"25/12/28 17:43:15 INFO BlockManagerInfo: Removed broadcast_102_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.778500Z","level":"info","event":"25/12/28 17:43:15 INFO Executor: Finished task 3.0 in stage 98.0 (TID 163). 2070 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.780504Z","level":"info","event":"25/12/28 17:43:15 INFO BlockManagerInfo: Removed broadcast_107_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.784344Z","level":"info","event":"25/12/28 17:43:15 INFO TaskSetManager: Finished task 3.0 in stage 98.0 (TID 163) in 325 ms on c252dd92c865 (executor driver) (1/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.786722Z","level":"info","event":"25/12/28 17:43:15 INFO BlockManagerInfo: Removed broadcast_104_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.804145Z","level":"info","event":"25/12/28 17:43:15 INFO Executor: Finished task 0.0 in stage 98.0 (TID 160). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.804277Z","level":"info","event":"25/12/28 17:43:15 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 160) in 349 ms on c252dd92c865 (executor driver) (2/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.837138Z","level":"info","event":"25/12/28 17:43:15 INFO Executor: Finished task 2.0 in stage 98.0 (TID 162). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.843841Z","level":"info","event":"25/12/28 17:43:15 INFO Executor: Finished task 1.0 in stage 98.0 (TID 161). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.844133Z","level":"info","event":"25/12/28 17:43:15 INFO TaskSetManager: Finished task 2.0 in stage 98.0 (TID 162) in 386 ms on c252dd92c865 (executor driver) (3/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.855683Z","level":"info","event":"25/12/28 17:43:15 INFO TaskSetManager: Finished task 1.0 in stage 98.0 (TID 161) in 399 ms on c252dd92c865 (executor driver) (4/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.856076Z","level":"info","event":"25/12/28 17:43:15 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.861840Z","level":"info","event":"25/12/28 17:43:15 INFO DAGScheduler: ShuffleMapStage 98 (count at <unknown>:0) finished in 0.421 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.862028Z","level":"info","event":"25/12/28 17:43:15 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.862653Z","level":"info","event":"25/12/28 17:43:15 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.862837Z","level":"info","event":"25/12/28 17:43:15 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.862907Z","level":"info","event":"25/12/28 17:43:15 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.956638Z","level":"info","event":"25/12/28 17:43:15 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.963309Z","level":"info","event":"25/12/28 17:43:15 INFO DAGScheduler: Got job 68 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.963466Z","level":"info","event":"25/12/28 17:43:15 INFO DAGScheduler: Final stage: ResultStage 100 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.963538Z","level":"info","event":"25/12/28 17:43:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 99)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.964143Z","level":"info","event":"25/12/28 17:43:15 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.969847Z","level":"info","event":"25/12/28 17:43:15 INFO DAGScheduler: Submitting ResultStage 100 (MapPartitionsRDD[273] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.976207Z","level":"info","event":"25/12/28 17:43:15 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.984008Z","level":"info","event":"25/12/28 17:43:15 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.987018Z","level":"info","event":"25/12/28 17:43:15 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.991495Z","level":"info","event":"25/12/28 17:43:15 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.991668Z","level":"info","event":"25/12/28 17:43:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[273] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.991928Z","level":"info","event":"25/12/28 17:43:15 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.996894Z","level":"info","event":"25/12/28 17:43:15 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 164) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:15.997835Z","level":"info","event":"25/12/28 17:43:15 INFO Executor: Running task 0.0 in stage 100.0 (TID 164)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.008375Z","level":"info","event":"25/12/28 17:43:16 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.008691Z","level":"info","event":"25/12/28 17:43:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.023400Z","level":"info","event":"25/12/28 17:43:16 INFO Executor: Finished task 0.0 in stage 100.0 (TID 164). 3995 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.024531Z","level":"info","event":"25/12/28 17:43:16 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 164) in 29 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.024624Z","level":"info","event":"25/12/28 17:43:16 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.027469Z","level":"info","event":"25/12/28 17:43:16 INFO DAGScheduler: ResultStage 100 (count at <unknown>:0) finished in 0.058 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.027765Z","level":"info","event":"25/12/28 17:43:16 INFO DAGScheduler: Job 68 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.028283Z","level":"info","event":"25/12/28 17:43:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 100: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.028463Z","level":"info","event":"25/12/28 17:43:16 INFO DAGScheduler: Job 68 finished: count at <unknown>:0, took 0.072205 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.037468Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.037937Z","level":"info","event":"Column review_comment_message (StringType()) in olist_order_reviews has 63079 null values.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.167305Z","level":"info","event":"25/12/28 17:43:16 INFO FileSourceStrategy: Pushed Filters: IsNull(review_creation_date)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.168596Z","level":"info","event":"25/12/28 17:43:16 INFO FileSourceStrategy: Post-Scan Filters: isnull(review_creation_date#436)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.211516Z","level":"info","event":"25/12/28 17:43:16 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 199.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.232175Z","level":"info","event":"25/12/28 17:43:16 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.235369Z","level":"info","event":"25/12/28 17:43:16 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.244545Z","level":"info","event":"25/12/28 17:43:16 INFO SparkContext: Created broadcast 111 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.252320Z","level":"info","event":"25/12/28 17:43:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.259332Z","level":"info","event":"25/12/28 17:43:16 INFO DAGScheduler: Registering RDD 277 (count at <unknown>:0) as input to shuffle 32","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.259468Z","level":"info","event":"25/12/28 17:43:16 INFO DAGScheduler: Got map stage job 69 (count at <unknown>:0) with 4 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.259526Z","level":"info","event":"25/12/28 17:43:16 INFO DAGScheduler: Final stage: ShuffleMapStage 101 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.259564Z","level":"info","event":"25/12/28 17:43:16 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.259608Z","level":"info","event":"25/12/28 17:43:16 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.260285Z","level":"info","event":"25/12/28 17:43:16 INFO DAGScheduler: Submitting ShuffleMapStage 101 (MapPartitionsRDD[277] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.264486Z","level":"info","event":"25/12/28 17:43:16 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 18.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.271507Z","level":"info","event":"25/12/28 17:43:16 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.272470Z","level":"info","event":"25/12/28 17:43:16 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.275540Z","level":"info","event":"25/12/28 17:43:16 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.275824Z","level":"info","event":"25/12/28 17:43:16 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 101 (MapPartitionsRDD[277] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.275945Z","level":"info","event":"25/12/28 17:43:16 INFO TaskSchedulerImpl: Adding task set 101.0 with 4 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.277859Z","level":"info","event":"25/12/28 17:43:16 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 165) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.278682Z","level":"info","event":"25/12/28 17:43:16 INFO TaskSetManager: Starting task 1.0 in stage 101.0 (TID 166) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.278952Z","level":"info","event":"25/12/28 17:43:16 INFO TaskSetManager: Starting task 2.0 in stage 101.0 (TID 167) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.279467Z","level":"info","event":"25/12/28 17:43:16 INFO TaskSetManager: Starting task 3.0 in stage 101.0 (TID 168) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.280062Z","level":"info","event":"25/12/28 17:43:16 INFO Executor: Running task 1.0 in stage 101.0 (TID 166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.280966Z","level":"info","event":"25/12/28 17:43:16 INFO Executor: Running task 3.0 in stage 101.0 (TID 168)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.281618Z","level":"info","event":"25/12/28 17:43:16 INFO Executor: Running task 0.0 in stage 101.0 (TID 165)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.285117Z","level":"info","event":"25/12/28 17:43:16 INFO Executor: Running task 2.0 in stage 101.0 (TID 167)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.289283Z","level":"info","event":"25/12/28 17:43:16 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.294317Z","level":"info","event":"25/12/28 17:43:16 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.294598Z","level":"info","event":"25/12/28 17:43:16 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 12582912-14451670, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.297099Z","level":"info","event":"25/12/28 17:43:16 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.410751Z","level":"info","event":"25/12/28 17:43:16 INFO Executor: Finished task 3.0 in stage 101.0 (TID 168). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.413807Z","level":"info","event":"25/12/28 17:43:16 INFO TaskSetManager: Finished task 3.0 in stage 101.0 (TID 168) in 133 ms on c252dd92c865 (executor driver) (1/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.519799Z","level":"info","event":"25/12/28 17:43:16 INFO Executor: Finished task 0.0 in stage 101.0 (TID 165). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.524941Z","level":"info","event":"25/12/28 17:43:16 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 165) in 248 ms on c252dd92c865 (executor driver) (2/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.664873Z","level":"info","event":"25/12/28 17:43:16 INFO Executor: Finished task 2.0 in stage 101.0 (TID 167). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.666815Z","level":"info","event":"25/12/28 17:43:16 INFO Executor: Finished task 1.0 in stage 101.0 (TID 166). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.672640Z","level":"info","event":"25/12/28 17:43:16 INFO TaskSetManager: Finished task 1.0 in stage 101.0 (TID 166) in 394 ms on c252dd92c865 (executor driver) (3/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.672980Z","level":"info","event":"25/12/28 17:43:16 INFO TaskSetManager: Finished task 2.0 in stage 101.0 (TID 167) in 394 ms on c252dd92c865 (executor driver) (4/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.673065Z","level":"info","event":"25/12/28 17:43:16 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.676098Z","level":"info","event":"25/12/28 17:43:16 INFO DAGScheduler: ShuffleMapStage 101 (count at <unknown>:0) finished in 0.412 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.678641Z","level":"info","event":"25/12/28 17:43:16 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.678860Z","level":"info","event":"25/12/28 17:43:16 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.678926Z","level":"info","event":"25/12/28 17:43:16 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.678964Z","level":"info","event":"25/12/28 17:43:16 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.786535Z","level":"info","event":"25/12/28 17:43:16 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.808615Z","level":"info","event":"25/12/28 17:43:16 INFO DAGScheduler: Got job 70 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.808878Z","level":"info","event":"25/12/28 17:43:16 INFO DAGScheduler: Final stage: ResultStage 103 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.809485Z","level":"info","event":"25/12/28 17:43:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 102)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.809904Z","level":"info","event":"25/12/28 17:43:16 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.816160Z","level":"info","event":"25/12/28 17:43:16 INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[280] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.825678Z","level":"info","event":"25/12/28 17:43:16 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 12.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.838018Z","level":"info","event":"25/12/28 17:43:16 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.839321Z","level":"info","event":"25/12/28 17:43:16 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.842498Z","level":"info","event":"25/12/28 17:43:16 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.842625Z","level":"info","event":"25/12/28 17:43:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[280] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.842685Z","level":"info","event":"25/12/28 17:43:16 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.844405Z","level":"info","event":"25/12/28 17:43:16 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 169) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.846317Z","level":"info","event":"25/12/28 17:43:16 INFO Executor: Running task 0.0 in stage 103.0 (TID 169)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.864508Z","level":"info","event":"25/12/28 17:43:16 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.864755Z","level":"info","event":"25/12/28 17:43:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.875695Z","level":"info","event":"25/12/28 17:43:16 INFO Executor: Finished task 0.0 in stage 103.0 (TID 169). 3995 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.878725Z","level":"info","event":"25/12/28 17:43:16 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 169) in 35 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.878841Z","level":"info","event":"25/12/28 17:43:16 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.880097Z","level":"info","event":"25/12/28 17:43:16 INFO DAGScheduler: ResultStage 103 (count at <unknown>:0) finished in 0.058 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.880177Z","level":"info","event":"25/12/28 17:43:16 INFO DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.880237Z","level":"info","event":"25/12/28 17:43:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 103: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.880289Z","level":"info","event":"25/12/28 17:43:16 INFO DAGScheduler: Job 70 finished: count at <unknown>:0, took 0.092707 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.890958Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.891689Z","level":"info","event":"Column review_creation_date (StringType()) in olist_order_reviews has 8764 null values.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.970021Z","level":"info","event":"25/12/28 17:43:16 INFO FileSourceStrategy: Pushed Filters: IsNull(review_answer_timestamp)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.970148Z","level":"info","event":"25/12/28 17:43:16 INFO FileSourceStrategy: Post-Scan Filters: isnull(review_answer_timestamp#437)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.986865Z","level":"info","event":"25/12/28 17:43:16 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.994535Z","level":"info","event":"25/12/28 17:43:16 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.994689Z","level":"info","event":"25/12/28 17:43:16 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:16.995488Z","level":"info","event":"25/12/28 17:43:16 INFO SparkContext: Created broadcast 114 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.002010Z","level":"info","event":"25/12/28 17:43:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.006945Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Registering RDD 284 (count at <unknown>:0) as input to shuffle 33","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.007296Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Got map stage job 71 (count at <unknown>:0) with 4 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.007407Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Final stage: ShuffleMapStage 104 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.007553Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.007594Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.007638Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Submitting ShuffleMapStage 104 (MapPartitionsRDD[284] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.009164Z","level":"info","event":"25/12/28 17:43:17 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 18.5 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.019692Z","level":"info","event":"25/12/28 17:43:17 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.020275Z","level":"info","event":"25/12/28 17:43:17 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.021271Z","level":"info","event":"25/12/28 17:43:17 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.022136Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 104 (MapPartitionsRDD[284] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.022357Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSchedulerImpl: Adding task set 104.0 with 4 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.025778Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 170) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.028613Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSetManager: Starting task 1.0 in stage 104.0 (TID 171) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.028827Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSetManager: Starting task 2.0 in stage 104.0 (TID 172) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.029128Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSetManager: Starting task 3.0 in stage 104.0 (TID 173) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8284 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.031911Z","level":"info","event":"25/12/28 17:43:17 INFO Executor: Running task 1.0 in stage 104.0 (TID 171)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.032042Z","level":"info","event":"25/12/28 17:43:17 INFO Executor: Running task 0.0 in stage 104.0 (TID 170)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.034214Z","level":"info","event":"25/12/28 17:43:17 INFO Executor: Running task 2.0 in stage 104.0 (TID 172)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.034547Z","level":"info","event":"25/12/28 17:43:17 INFO Executor: Running task 3.0 in stage 104.0 (TID 173)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.039012Z","level":"info","event":"25/12/28 17:43:17 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.039225Z","level":"info","event":"25/12/28 17:43:17 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.039307Z","level":"info","event":"25/12/28 17:43:17 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.046546Z","level":"info","event":"25/12/28 17:43:17 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 12582912-14451670, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.119125Z","level":"info","event":"25/12/28 17:43:17 INFO Executor: Finished task 3.0 in stage 104.0 (TID 173). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.124462Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSetManager: Finished task 3.0 in stage 104.0 (TID 173) in 98 ms on c252dd92c865 (executor driver) (1/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.198313Z","level":"info","event":"25/12/28 17:43:17 INFO BlockManagerInfo: Removed broadcast_108_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.207156Z","level":"info","event":"25/12/28 17:43:17 INFO Executor: Finished task 1.0 in stage 104.0 (TID 171). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.210148Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSetManager: Finished task 1.0 in stage 104.0 (TID 171) in 184 ms on c252dd92c865 (executor driver) (2/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.210452Z","level":"info","event":"25/12/28 17:43:17 INFO BlockManagerInfo: Removed broadcast_113_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.210618Z","level":"info","event":"25/12/28 17:43:17 INFO Executor: Finished task 2.0 in stage 104.0 (TID 172). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.215881Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSetManager: Finished task 2.0 in stage 104.0 (TID 172) in 189 ms on c252dd92c865 (executor driver) (3/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.217018Z","level":"info","event":"25/12/28 17:43:17 INFO BlockManagerInfo: Removed broadcast_112_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.234222Z","level":"info","event":"25/12/28 17:43:17 INFO BlockManagerInfo: Removed broadcast_110_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.235557Z","level":"info","event":"25/12/28 17:43:17 INFO Executor: Finished task 0.0 in stage 104.0 (TID 170). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.237514Z","level":"info","event":"25/12/28 17:43:17 INFO BlockManagerInfo: Removed broadcast_111_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.238176Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 170) in 213 ms on c252dd92c865 (executor driver) (4/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.238506Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.238806Z","level":"info","event":"25/12/28 17:43:17 INFO BlockManagerInfo: Removed broadcast_109_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.239579Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: ShuffleMapStage 104 (count at <unknown>:0) finished in 0.231 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.239673Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.239750Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.239827Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.239877Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.297205Z","level":"info","event":"25/12/28 17:43:17 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.299032Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Got job 72 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.299298Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Final stage: ResultStage 106 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.299476Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 105)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.299591Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.299709Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[287] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.305051Z","level":"info","event":"25/12/28 17:43:17 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.308215Z","level":"info","event":"25/12/28 17:43:17 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.308873Z","level":"info","event":"25/12/28 17:43:17 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.309938Z","level":"info","event":"25/12/28 17:43:17 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.310980Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[287] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.311223Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.314630Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 174) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.316176Z","level":"info","event":"25/12/28 17:43:17 INFO Executor: Running task 0.0 in stage 106.0 (TID 174)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.323563Z","level":"info","event":"25/12/28 17:43:17 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.323920Z","level":"info","event":"25/12/28 17:43:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.328098Z","level":"info","event":"25/12/28 17:43:17 INFO Executor: Finished task 0.0 in stage 106.0 (TID 174). 3995 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.330943Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 174) in 17 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.331097Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.331737Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: ResultStage 106 (count at <unknown>:0) finished in 0.031 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.331935Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.332053Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 106: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.332296Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Job 72 finished: count at <unknown>:0, took 0.034826 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.334598Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.334820Z","level":"info","event":"Column review_answer_timestamp (StringType()) in olist_order_reviews has 8785 null values.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.366262Z","level":"info","event":"25/12/28 17:43:17 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.369822Z","level":"info","event":"25/12/28 17:43:17 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.465154Z","level":"info","event":"25/12/28 17:43:17 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.467255Z","level":"info","event":"25/12/28 17:43:17 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#549, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.479635Z","level":"info","event":"25/12/28 17:43:17 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 199.3 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.496217Z","level":"info","event":"25/12/28 17:43:17 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.496557Z","level":"info","event":"25/12/28 17:43:17 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on c252dd92c865:35057 (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.497360Z","level":"info","event":"25/12/28 17:43:17 INFO SparkContext: Created broadcast 117 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.498299Z","level":"info","event":"25/12/28 17:43:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.506352Z","level":"info","event":"25/12/28 17:43:17 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.507115Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Got job 73 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.507271Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Final stage: ResultStage 107 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.507362Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.507503Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.507579Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Submitting ResultStage 107 (MapPartitionsRDD[291] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.513047Z","level":"info","event":"25/12/28 17:43:17 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 13.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.522771Z","level":"info","event":"25/12/28 17:43:17 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.523796Z","level":"info","event":"25/12/28 17:43:17 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on c252dd92c865:35057 (size: 6.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.524896Z","level":"info","event":"25/12/28 17:43:17 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.525469Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 107 (MapPartitionsRDD[291] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.525673Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSchedulerImpl: Adding task set 107.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.528620Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 175) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8288 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.529596Z","level":"info","event":"25/12/28 17:43:17 INFO Executor: Running task 0.0 in stage 107.0 (TID 175)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.532899Z","level":"info","event":"25/12/28 17:43:17 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.544687Z","level":"info","event":"25/12/28 17:43:17 INFO Executor: Finished task 0.0 in stage 107.0 (TID 175). 1733 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.549071Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 175) in 19 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.549197Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.549225Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: ResultStage 107 (csv at NativeMethodAccessorImpl.java:0) finished in 0.037 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.549242Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.549259Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 107: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.549284Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Job 73 finished: csv at NativeMethodAccessorImpl.java:0, took 0.042306 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.564381Z","level":"info","event":"25/12/28 17:43:17 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.564693Z","level":"info","event":"25/12/28 17:43:17 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.573775Z","level":"info","event":"25/12/28 17:43:17 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 199.3 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.598604Z","level":"info","event":"25/12/28 17:43:17 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.599162Z","level":"info","event":"25/12/28 17:43:17 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on c252dd92c865:35057 (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.599327Z","level":"info","event":"25/12/28 17:43:17 INFO SparkContext: Created broadcast 119 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.605619Z","level":"info","event":"25/12/28 17:43:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.665577Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.698483Z","level":"info","event":"25/12/28 17:43:17 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.698754Z","level":"info","event":"25/12/28 17:43:17 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.754627Z","level":"info","event":"25/12/28 17:43:17 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 199.2 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.821331Z","level":"info","event":"25/12/28 17:43:17 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.822405Z","level":"info","event":"25/12/28 17:43:17 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.840782Z","level":"info","event":"25/12/28 17:43:17 INFO SparkContext: Created broadcast 120 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.844710Z","level":"info","event":"25/12/28 17:43:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.874457Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Registering RDD 301 (count at <unknown>:0) as input to shuffle 34","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.878983Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Got map stage job 74 (count at <unknown>:0) with 5 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.880497Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Final stage: ShuffleMapStage 108 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.880883Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.884358Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.890177Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Submitting ShuffleMapStage 108 (MapPartitionsRDD[301] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.894070Z","level":"info","event":"25/12/28 17:43:17 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 17.9 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.896824Z","level":"info","event":"25/12/28 17:43:17 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.897813Z","level":"info","event":"25/12/28 17:43:17 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on c252dd92c865:35057 (size: 8.8 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.900276Z","level":"info","event":"25/12/28 17:43:17 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.904287Z","level":"info","event":"25/12/28 17:43:17 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 108 (MapPartitionsRDD[301] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.904411Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSchedulerImpl: Adding task set 108.0 with 5 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.905831Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 176) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.906042Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSetManager: Starting task 1.0 in stage 108.0 (TID 177) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.906295Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSetManager: Starting task 2.0 in stage 108.0 (TID 178) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.906528Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSetManager: Starting task 3.0 in stage 108.0 (TID 179) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.906747Z","level":"info","event":"25/12/28 17:43:17 INFO TaskSetManager: Starting task 4.0 in stage 108.0 (TID 180) (c252dd92c865, executor driver, partition 4, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.908828Z","level":"info","event":"25/12/28 17:43:17 INFO Executor: Running task 1.0 in stage 108.0 (TID 177)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.909103Z","level":"info","event":"25/12/28 17:43:17 INFO Executor: Running task 2.0 in stage 108.0 (TID 178)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.909221Z","level":"info","event":"25/12/28 17:43:17 INFO Executor: Running task 4.0 in stage 108.0 (TID 180)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.915686Z","level":"info","event":"25/12/28 17:43:17 INFO Executor: Running task 0.0 in stage 108.0 (TID 176)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.915868Z","level":"info","event":"25/12/28 17:43:17 INFO Executor: Running task 3.0 in stage 108.0 (TID 179)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.929101Z","level":"info","event":"25/12/28 17:43:17 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.931049Z","level":"info","event":"25/12/28 17:43:17 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.931557Z","level":"info","event":"25/12/28 17:43:17 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 12582912-16777216, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.936583Z","level":"info","event":"25/12/28 17:43:17 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 16777216-17654914, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:17.936745Z","level":"info","event":"25/12/28 17:43:17 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.042971Z","level":"info","event":"25/12/28 17:43:18 INFO Executor: Finished task 2.0 in stage 108.0 (TID 178). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.043336Z","level":"info","event":"25/12/28 17:43:18 INFO Executor: Finished task 0.0 in stage 108.0 (TID 176). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.046498Z","level":"info","event":"25/12/28 17:43:18 INFO Executor: Finished task 4.0 in stage 108.0 (TID 180). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.046820Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSetManager: Finished task 2.0 in stage 108.0 (TID 178) in 140 ms on c252dd92c865 (executor driver) (1/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.050684Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 176) in 144 ms on c252dd92c865 (executor driver) (2/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.051767Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSetManager: Finished task 4.0 in stage 108.0 (TID 180) in 145 ms on c252dd92c865 (executor driver) (3/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.074103Z","level":"info","event":"25/12/28 17:43:18 INFO Executor: Finished task 1.0 in stage 108.0 (TID 177). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.080891Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSetManager: Finished task 1.0 in stage 108.0 (TID 177) in 173 ms on c252dd92c865 (executor driver) (4/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.109660Z","level":"info","event":"25/12/28 17:43:18 INFO Executor: Finished task 3.0 in stage 108.0 (TID 179). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.112329Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSetManager: Finished task 3.0 in stage 108.0 (TID 179) in 206 ms on c252dd92c865 (executor driver) (5/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.125614Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: ShuffleMapStage 108 (count at <unknown>:0) finished in 0.222 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.125853Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.128539Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.128827Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.128893Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.128937Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.169013Z","level":"info","event":"25/12/28 17:43:18 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.171655Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: Got job 75 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.171916Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: Final stage: ResultStage 110 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.172004Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 109)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.172091Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.172178Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: Submitting ResultStage 110 (MapPartitionsRDD[304] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.173946Z","level":"info","event":"25/12/28 17:43:18 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 12.5 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.181980Z","level":"info","event":"25/12/28 17:43:18 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.185918Z","level":"info","event":"25/12/28 17:43:18 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.188072Z","level":"info","event":"25/12/28 17:43:18 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.188285Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 110 (MapPartitionsRDD[304] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.188383Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSchedulerImpl: Adding task set 110.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.190724Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 181) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.191443Z","level":"info","event":"25/12/28 17:43:18 INFO Executor: Running task 0.0 in stage 110.0 (TID 181)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.199696Z","level":"info","event":"25/12/28 17:43:18 INFO ShuffleBlockFetcherIterator: Getting 5 (300.0 B) non-empty blocks including 5 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.199924Z","level":"info","event":"25/12/28 17:43:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.207052Z","level":"info","event":"25/12/28 17:43:18 INFO Executor: Finished task 0.0 in stage 110.0 (TID 181). 3995 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.212512Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 181) in 23 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.213608Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: ResultStage 110 (count at <unknown>:0) finished in 0.042 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.213712Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: Job 75 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.213767Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.214939Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 110: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.216571Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: Job 75 finished: count at <unknown>:0, took 0.046448 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.225557Z","level":"info","event":"Loaded olist_orders with 99441 records.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.318648Z","level":"info","event":"25/12/28 17:43:18 INFO FileSourceStrategy: Pushed Filters: IsNull(order_id)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.318827Z","level":"info","event":"25/12/28 17:43:18 INFO FileSourceStrategy: Post-Scan Filters: isnull(order_id#566)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.345963Z","level":"info","event":"25/12/28 17:43:18 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 199.2 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.357626Z","level":"info","event":"25/12/28 17:43:18 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.359759Z","level":"info","event":"25/12/28 17:43:18 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.365103Z","level":"info","event":"25/12/28 17:43:18 INFO SparkContext: Created broadcast 123 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.370102Z","level":"info","event":"25/12/28 17:43:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.383084Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: Registering RDD 308 (count at <unknown>:0) as input to shuffle 35","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.387615Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: Got map stage job 76 (count at <unknown>:0) with 5 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.388209Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: Final stage: ShuffleMapStage 111 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.388282Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.388322Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.389175Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: Submitting ShuffleMapStage 111 (MapPartitionsRDD[308] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.392822Z","level":"info","event":"25/12/28 17:43:18 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 18.6 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.395852Z","level":"info","event":"25/12/28 17:43:18 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.396863Z","level":"info","event":"25/12/28 17:43:18 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on c252dd92c865:35057 (size: 9.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.397592Z","level":"info","event":"25/12/28 17:43:18 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.399086Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 111 (MapPartitionsRDD[308] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.399789Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSchedulerImpl: Adding task set 111.0 with 5 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.404362Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 182) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.409224Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSetManager: Starting task 1.0 in stage 111.0 (TID 183) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.409639Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSetManager: Starting task 2.0 in stage 111.0 (TID 184) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.410199Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSetManager: Starting task 3.0 in stage 111.0 (TID 185) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.410332Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSetManager: Starting task 4.0 in stage 111.0 (TID 186) (c252dd92c865, executor driver, partition 4, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.412024Z","level":"info","event":"25/12/28 17:43:18 INFO Executor: Running task 3.0 in stage 111.0 (TID 185)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.412361Z","level":"info","event":"25/12/28 17:43:18 INFO Executor: Running task 0.0 in stage 111.0 (TID 182)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.416533Z","level":"info","event":"25/12/28 17:43:18 INFO Executor: Running task 1.0 in stage 111.0 (TID 183)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.418508Z","level":"info","event":"25/12/28 17:43:18 INFO Executor: Running task 2.0 in stage 111.0 (TID 184)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.418690Z","level":"info","event":"25/12/28 17:43:18 INFO Executor: Running task 4.0 in stage 111.0 (TID 186)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.426042Z","level":"info","event":"25/12/28 17:43:18 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 16777216-17654914, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.426311Z","level":"info","event":"25/12/28 17:43:18 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.426511Z","level":"info","event":"25/12/28 17:43:18 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 12582912-16777216, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.433137Z","level":"info","event":"25/12/28 17:43:18 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.433257Z","level":"info","event":"25/12/28 17:43:18 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.492396Z","level":"info","event":"25/12/28 17:43:18 INFO Executor: Finished task 4.0 in stage 111.0 (TID 186). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.507602Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSetManager: Finished task 4.0 in stage 111.0 (TID 186) in 93 ms on c252dd92c865 (executor driver) (1/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.627559Z","level":"info","event":"25/12/28 17:43:18 INFO Executor: Finished task 2.0 in stage 111.0 (TID 184). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.628527Z","level":"info","event":"25/12/28 17:43:18 INFO Executor: Finished task 3.0 in stage 111.0 (TID 185). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.631707Z","level":"info","event":"25/12/28 17:43:18 INFO Executor: Finished task 1.0 in stage 111.0 (TID 183). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.635918Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSetManager: Finished task 2.0 in stage 111.0 (TID 184) in 225 ms on c252dd92c865 (executor driver) (2/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.636345Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSetManager: Finished task 3.0 in stage 111.0 (TID 185) in 227 ms on c252dd92c865 (executor driver) (3/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.636816Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSetManager: Finished task 1.0 in stage 111.0 (TID 183) in 232 ms on c252dd92c865 (executor driver) (4/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.647688Z","level":"info","event":"25/12/28 17:43:18 INFO Executor: Finished task 0.0 in stage 111.0 (TID 182). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.649504Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 182) in 246 ms on c252dd92c865 (executor driver) (5/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.649837Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.652045Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: ShuffleMapStage 111 (count at <unknown>:0) finished in 0.260 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.652206Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.652269Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.652328Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.652368Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.726360Z","level":"info","event":"25/12/28 17:43:18 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.729497Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: Got job 77 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.729796Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: Final stage: ResultStage 113 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.729842Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 112)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.729888Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.729930Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: Submitting ResultStage 113 (MapPartitionsRDD[311] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.735493Z","level":"info","event":"25/12/28 17:43:18 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 12.5 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.742406Z","level":"info","event":"25/12/28 17:43:18 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.749015Z","level":"info","event":"25/12/28 17:43:18 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.749297Z","level":"info","event":"25/12/28 17:43:18 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.749475Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 113 (MapPartitionsRDD[311] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.749630Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSchedulerImpl: Adding task set 113.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.749832Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 187) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.753701Z","level":"info","event":"25/12/28 17:43:18 INFO Executor: Running task 0.0 in stage 113.0 (TID 187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.764205Z","level":"info","event":"25/12/28 17:43:18 INFO ShuffleBlockFetcherIterator: Getting 5 (300.0 B) non-empty blocks including 5 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.765367Z","level":"info","event":"25/12/28 17:43:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.779816Z","level":"info","event":"25/12/28 17:43:18 INFO Executor: Finished task 0.0 in stage 113.0 (TID 187). 4031 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.782859Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 187) in 34 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.783331Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.786771Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: ResultStage 113 (count at <unknown>:0) finished in 0.054 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.791488Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: Job 77 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.791599Z","level":"info","event":"25/12/28 17:43:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 113: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.793064Z","level":"info","event":"25/12/28 17:43:18 INFO DAGScheduler: Job 77 finished: count at <unknown>:0, took 0.069697 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.920718Z","level":"info","event":"25/12/28 17:43:18 INFO FileSourceStrategy: Pushed Filters: IsNull(customer_id)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.921279Z","level":"info","event":"25/12/28 17:43:18 INFO FileSourceStrategy: Post-Scan Filters: isnull(customer_id#567)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:18.979114Z","level":"info","event":"25/12/28 17:43:18 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 199.2 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.004249Z","level":"info","event":"25/12/28 17:43:19 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.014496Z","level":"info","event":"25/12/28 17:43:19 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.020935Z","level":"info","event":"25/12/28 17:43:19 INFO SparkContext: Created broadcast 126 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.035082Z","level":"info","event":"25/12/28 17:43:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.049285Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: Registering RDD 315 (count at <unknown>:0) as input to shuffle 36","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.050193Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: Got map stage job 78 (count at <unknown>:0) with 5 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.050292Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: Final stage: ShuffleMapStage 114 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.050328Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.050645Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.051008Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: Submitting ShuffleMapStage 114 (MapPartitionsRDD[315] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.055629Z","level":"info","event":"25/12/28 17:43:19 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 18.6 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.060348Z","level":"info","event":"25/12/28 17:43:19 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.060923Z","level":"info","event":"25/12/28 17:43:19 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on c252dd92c865:35057 (size: 9.1 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.063565Z","level":"info","event":"25/12/28 17:43:19 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.064977Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 114 (MapPartitionsRDD[315] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.066617Z","level":"info","event":"25/12/28 17:43:19 INFO TaskSchedulerImpl: Adding task set 114.0 with 5 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.072118Z","level":"info","event":"25/12/28 17:43:19 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 188) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.072483Z","level":"info","event":"25/12/28 17:43:19 INFO TaskSetManager: Starting task 1.0 in stage 114.0 (TID 189) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.072654Z","level":"info","event":"25/12/28 17:43:19 INFO TaskSetManager: Starting task 2.0 in stage 114.0 (TID 190) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.074053Z","level":"info","event":"25/12/28 17:43:19 INFO TaskSetManager: Starting task 3.0 in stage 114.0 (TID 191) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.074149Z","level":"info","event":"25/12/28 17:43:19 INFO TaskSetManager: Starting task 4.0 in stage 114.0 (TID 192) (c252dd92c865, executor driver, partition 4, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.074794Z","level":"info","event":"25/12/28 17:43:19 INFO Executor: Running task 0.0 in stage 114.0 (TID 188)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.074852Z","level":"info","event":"25/12/28 17:43:19 INFO Executor: Running task 3.0 in stage 114.0 (TID 191)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.075113Z","level":"info","event":"25/12/28 17:43:19 INFO Executor: Running task 4.0 in stage 114.0 (TID 192)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.075298Z","level":"info","event":"25/12/28 17:43:19 INFO Executor: Running task 1.0 in stage 114.0 (TID 189)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.077555Z","level":"info","event":"25/12/28 17:43:19 INFO Executor: Running task 2.0 in stage 114.0 (TID 190)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.083740Z","level":"info","event":"25/12/28 17:43:19 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.084353Z","level":"info","event":"25/12/28 17:43:19 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 16777216-17654914, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.084505Z","level":"info","event":"25/12/28 17:43:19 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.084685Z","level":"info","event":"25/12/28 17:43:19 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 12582912-16777216, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.090545Z","level":"info","event":"25/12/28 17:43:19 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.223031Z","level":"info","event":"25/12/28 17:43:19 INFO BlockManagerInfo: Removed broadcast_117_piece0 on c252dd92c865:35057 in memory (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.235499Z","level":"info","event":"25/12/28 17:43:19 INFO BlockManagerInfo: Removed broadcast_114_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.254778Z","level":"info","event":"25/12/28 17:43:19 INFO BlockManagerInfo: Removed broadcast_120_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.258620Z","level":"info","event":"25/12/28 17:43:19 INFO Executor: Finished task 4.0 in stage 114.0 (TID 192). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.281058Z","level":"info","event":"25/12/28 17:43:19 INFO TaskSetManager: Finished task 4.0 in stage 114.0 (TID 192) in 195 ms on c252dd92c865 (executor driver) (1/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.295692Z","level":"info","event":"25/12/28 17:43:19 INFO BlockManagerInfo: Removed broadcast_115_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.307554Z","level":"info","event":"25/12/28 17:43:19 INFO Executor: Finished task 3.0 in stage 114.0 (TID 191). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.307840Z","level":"info","event":"25/12/28 17:43:19 INFO BlockManagerInfo: Removed broadcast_119_piece0 on c252dd92c865:35057 in memory (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.311405Z","level":"info","event":"25/12/28 17:43:19 INFO TaskSetManager: Finished task 3.0 in stage 114.0 (TID 191) in 238 ms on c252dd92c865 (executor driver) (2/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.312236Z","level":"info","event":"25/12/28 17:43:19 INFO BlockManagerInfo: Removed broadcast_118_piece0 on c252dd92c865:35057 in memory (size: 6.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.316157Z","level":"info","event":"25/12/28 17:43:19 INFO Executor: Finished task 0.0 in stage 114.0 (TID 188). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.319645Z","level":"info","event":"25/12/28 17:43:19 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 188) in 249 ms on c252dd92c865 (executor driver) (3/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.329984Z","level":"info","event":"25/12/28 17:43:19 INFO BlockManagerInfo: Removed broadcast_122_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.332382Z","level":"info","event":"25/12/28 17:43:19 INFO BlockManagerInfo: Removed broadcast_124_piece0 on c252dd92c865:35057 in memory (size: 9.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.339647Z","level":"info","event":"25/12/28 17:43:19 INFO BlockManagerInfo: Removed broadcast_121_piece0 on c252dd92c865:35057 in memory (size: 8.8 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.341761Z","level":"info","event":"25/12/28 17:43:19 INFO BlockManagerInfo: Removed broadcast_123_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.346044Z","level":"info","event":"25/12/28 17:43:19 INFO BlockManagerInfo: Removed broadcast_116_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.353477Z","level":"info","event":"25/12/28 17:43:19 INFO Executor: Finished task 1.0 in stage 114.0 (TID 189). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.354560Z","level":"info","event":"25/12/28 17:43:19 INFO BlockManagerInfo: Removed broadcast_125_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.356001Z","level":"info","event":"25/12/28 17:43:19 INFO TaskSetManager: Finished task 1.0 in stage 114.0 (TID 189) in 283 ms on c252dd92c865 (executor driver) (4/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.401240Z","level":"info","event":"25/12/28 17:43:19 INFO Executor: Finished task 2.0 in stage 114.0 (TID 190). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.402715Z","level":"info","event":"25/12/28 17:43:19 INFO TaskSetManager: Finished task 2.0 in stage 114.0 (TID 190) in 330 ms on c252dd92c865 (executor driver) (5/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.402943Z","level":"info","event":"25/12/28 17:43:19 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.411244Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: ShuffleMapStage 114 (count at <unknown>:0) finished in 0.353 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.414032Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.414323Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.414770Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.418046Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.473708Z","level":"info","event":"25/12/28 17:43:19 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.475564Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: Got job 79 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.475777Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: Final stage: ResultStage 116 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.475908Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 115)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.476000Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.476120Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: Submitting ResultStage 116 (MapPartitionsRDD[318] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.478344Z","level":"info","event":"25/12/28 17:43:19 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.481821Z","level":"info","event":"25/12/28 17:43:19 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.483698Z","level":"info","event":"25/12/28 17:43:19 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.484776Z","level":"info","event":"25/12/28 17:43:19 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.485815Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 116 (MapPartitionsRDD[318] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.486067Z","level":"info","event":"25/12/28 17:43:19 INFO TaskSchedulerImpl: Adding task set 116.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.490629Z","level":"info","event":"25/12/28 17:43:19 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 193) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.491843Z","level":"info","event":"25/12/28 17:43:19 INFO Executor: Running task 0.0 in stage 116.0 (TID 193)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.497075Z","level":"info","event":"25/12/28 17:43:19 INFO ShuffleBlockFetcherIterator: Getting 5 (300.0 B) non-empty blocks including 5 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.497376Z","level":"info","event":"25/12/28 17:43:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.502108Z","level":"info","event":"25/12/28 17:43:19 INFO Executor: Finished task 0.0 in stage 116.0 (TID 193). 3988 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.505370Z","level":"info","event":"25/12/28 17:43:19 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 193) in 15 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.506098Z","level":"info","event":"25/12/28 17:43:19 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.506495Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: ResultStage 116 (count at <unknown>:0) finished in 0.030 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.506555Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: Job 79 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.506618Z","level":"info","event":"25/12/28 17:43:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 116: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.507210Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: Job 79 finished: count at <unknown>:0, took 0.033112 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.612359Z","level":"info","event":"25/12/28 17:43:19 INFO FileSourceStrategy: Pushed Filters: IsNull(order_status)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.613165Z","level":"info","event":"25/12/28 17:43:19 INFO FileSourceStrategy: Post-Scan Filters: isnull(order_status#568)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.734771Z","level":"info","event":"25/12/28 17:43:19 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 199.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.774625Z","level":"info","event":"25/12/28 17:43:19 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.777283Z","level":"info","event":"25/12/28 17:43:19 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.787820Z","level":"info","event":"25/12/28 17:43:19 INFO SparkContext: Created broadcast 129 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.796647Z","level":"info","event":"25/12/28 17:43:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.804697Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: Registering RDD 322 (count at <unknown>:0) as input to shuffle 37","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.805570Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: Got map stage job 80 (count at <unknown>:0) with 5 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.805872Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: Final stage: ShuffleMapStage 117 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.806039Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.806179Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.806316Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: Submitting ShuffleMapStage 117 (MapPartitionsRDD[322] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.808689Z","level":"info","event":"25/12/28 17:43:19 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 18.6 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.813358Z","level":"info","event":"25/12/28 17:43:19 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.813873Z","level":"info","event":"25/12/28 17:43:19 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on c252dd92c865:35057 (size: 9.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.814475Z","level":"info","event":"25/12/28 17:43:19 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.815240Z","level":"info","event":"25/12/28 17:43:19 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 117 (MapPartitionsRDD[322] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.815800Z","level":"info","event":"25/12/28 17:43:19 INFO TaskSchedulerImpl: Adding task set 117.0 with 5 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.824915Z","level":"info","event":"25/12/28 17:43:19 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 194) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.825709Z","level":"info","event":"25/12/28 17:43:19 INFO TaskSetManager: Starting task 1.0 in stage 117.0 (TID 195) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.826639Z","level":"info","event":"25/12/28 17:43:19 INFO TaskSetManager: Starting task 2.0 in stage 117.0 (TID 196) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.829532Z","level":"info","event":"25/12/28 17:43:19 INFO TaskSetManager: Starting task 3.0 in stage 117.0 (TID 197) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.830000Z","level":"info","event":"25/12/28 17:43:19 INFO TaskSetManager: Starting task 4.0 in stage 117.0 (TID 198) (c252dd92c865, executor driver, partition 4, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.830209Z","level":"info","event":"25/12/28 17:43:19 INFO Executor: Running task 1.0 in stage 117.0 (TID 195)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.830486Z","level":"info","event":"25/12/28 17:43:19 INFO Executor: Running task 0.0 in stage 117.0 (TID 194)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.838990Z","level":"info","event":"25/12/28 17:43:19 INFO Executor: Running task 2.0 in stage 117.0 (TID 196)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.839267Z","level":"info","event":"25/12/28 17:43:19 INFO Executor: Running task 3.0 in stage 117.0 (TID 197)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.842885Z","level":"info","event":"25/12/28 17:43:19 INFO Executor: Running task 4.0 in stage 117.0 (TID 198)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.843032Z","level":"info","event":"25/12/28 17:43:19 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 12582912-16777216, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.843220Z","level":"info","event":"25/12/28 17:43:19 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.843272Z","level":"info","event":"25/12/28 17:43:19 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.848561Z","level":"info","event":"25/12/28 17:43:19 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 16777216-17654914, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:19.851190Z","level":"info","event":"25/12/28 17:43:19 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.006882Z","level":"info","event":"25/12/28 17:43:19 INFO Executor: Finished task 4.0 in stage 117.0 (TID 198). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.028388Z","level":"info","event":"25/12/28 17:43:20 INFO TaskSetManager: Finished task 4.0 in stage 117.0 (TID 198) in 200 ms on c252dd92c865 (executor driver) (1/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.325728Z","level":"info","event":"25/12/28 17:43:20 INFO Executor: Finished task 3.0 in stage 117.0 (TID 197). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.330964Z","level":"info","event":"25/12/28 17:43:20 INFO Executor: Finished task 1.0 in stage 117.0 (TID 195). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.332108Z","level":"info","event":"25/12/28 17:43:20 INFO TaskSetManager: Finished task 3.0 in stage 117.0 (TID 197) in 507 ms on c252dd92c865 (executor driver) (2/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.332645Z","level":"info","event":"25/12/28 17:43:20 INFO TaskSetManager: Finished task 1.0 in stage 117.0 (TID 195) in 509 ms on c252dd92c865 (executor driver) (3/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.376635Z","level":"info","event":"25/12/28 17:43:20 INFO Executor: Finished task 0.0 in stage 117.0 (TID 194). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.398588Z","level":"info","event":"25/12/28 17:43:20 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 194) in 568 ms on c252dd92c865 (executor driver) (4/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.453389Z","level":"info","event":"25/12/28 17:43:20 INFO Executor: Finished task 2.0 in stage 117.0 (TID 196). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.456500Z","level":"info","event":"25/12/28 17:43:20 INFO TaskSetManager: Finished task 2.0 in stage 117.0 (TID 196) in 633 ms on c252dd92c865 (executor driver) (5/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.456757Z","level":"info","event":"25/12/28 17:43:20 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.465272Z","level":"info","event":"25/12/28 17:43:20 INFO DAGScheduler: ShuffleMapStage 117 (count at <unknown>:0) finished in 0.650 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.468590Z","level":"info","event":"25/12/28 17:43:20 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.470578Z","level":"info","event":"25/12/28 17:43:20 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.470781Z","level":"info","event":"25/12/28 17:43:20 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.471766Z","level":"info","event":"25/12/28 17:43:20 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.671529Z","level":"info","event":"25/12/28 17:43:20 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.679000Z","level":"info","event":"25/12/28 17:43:20 INFO DAGScheduler: Got job 81 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.679369Z","level":"info","event":"25/12/28 17:43:20 INFO DAGScheduler: Final stage: ResultStage 119 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.679655Z","level":"info","event":"25/12/28 17:43:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 118)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.679956Z","level":"info","event":"25/12/28 17:43:20 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.684307Z","level":"info","event":"25/12/28 17:43:20 INFO DAGScheduler: Submitting ResultStage 119 (MapPartitionsRDD[325] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.705889Z","level":"info","event":"25/12/28 17:43:20 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 12.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.716942Z","level":"info","event":"25/12/28 17:43:20 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.717969Z","level":"info","event":"25/12/28 17:43:20 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.722884Z","level":"info","event":"25/12/28 17:43:20 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.723176Z","level":"info","event":"25/12/28 17:43:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 119 (MapPartitionsRDD[325] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.723526Z","level":"info","event":"25/12/28 17:43:20 INFO TaskSchedulerImpl: Adding task set 119.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.730393Z","level":"info","event":"25/12/28 17:43:20 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 199) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.737289Z","level":"info","event":"25/12/28 17:43:20 INFO Executor: Running task 0.0 in stage 119.0 (TID 199)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.818270Z","level":"info","event":"25/12/28 17:43:20 INFO ShuffleBlockFetcherIterator: Getting 5 (300.0 B) non-empty blocks including 5 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.819453Z","level":"info","event":"25/12/28 17:43:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.836603Z","level":"info","event":"25/12/28 17:43:20 INFO Executor: Finished task 0.0 in stage 119.0 (TID 199). 4031 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.843688Z","level":"info","event":"25/12/28 17:43:20 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 199) in 115 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.843995Z","level":"info","event":"25/12/28 17:43:20 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.847574Z","level":"info","event":"25/12/28 17:43:20 INFO DAGScheduler: ResultStage 119 (count at <unknown>:0) finished in 0.153 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.847930Z","level":"info","event":"25/12/28 17:43:20 INFO DAGScheduler: Job 81 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.848160Z","level":"info","event":"25/12/28 17:43:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 119: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:20.848461Z","level":"info","event":"25/12/28 17:43:20 INFO DAGScheduler: Job 81 finished: count at <unknown>:0, took 0.175341 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.249879Z","level":"info","event":"25/12/28 17:43:21 INFO FileSourceStrategy: Pushed Filters: IsNull(order_purchase_timestamp)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.253974Z","level":"info","event":"25/12/28 17:43:21 INFO FileSourceStrategy: Post-Scan Filters: isnull(order_purchase_timestamp#569)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.321669Z","level":"info","event":"25/12/28 17:43:21 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.387644Z","level":"info","event":"25/12/28 17:43:21 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.389000Z","level":"info","event":"25/12/28 17:43:21 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.389175Z","level":"info","event":"25/12/28 17:43:21 INFO SparkContext: Created broadcast 132 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.397149Z","level":"info","event":"25/12/28 17:43:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.436354Z","level":"info","event":"25/12/28 17:43:21 INFO DAGScheduler: Registering RDD 329 (count at <unknown>:0) as input to shuffle 38","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.437835Z","level":"info","event":"25/12/28 17:43:21 INFO DAGScheduler: Got map stage job 82 (count at <unknown>:0) with 5 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.438080Z","level":"info","event":"25/12/28 17:43:21 INFO DAGScheduler: Final stage: ShuffleMapStage 120 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.438209Z","level":"info","event":"25/12/28 17:43:21 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.438417Z","level":"info","event":"25/12/28 17:43:21 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.440317Z","level":"info","event":"25/12/28 17:43:21 INFO DAGScheduler: Submitting ShuffleMapStage 120 (MapPartitionsRDD[329] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.457746Z","level":"info","event":"25/12/28 17:43:21 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 18.6 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.461888Z","level":"info","event":"25/12/28 17:43:21 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.462221Z","level":"info","event":"25/12/28 17:43:21 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on c252dd92c865:35057 (size: 9.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.463280Z","level":"info","event":"25/12/28 17:43:21 INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.465201Z","level":"info","event":"25/12/28 17:43:21 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 120 (MapPartitionsRDD[329] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.465943Z","level":"info","event":"25/12/28 17:43:21 INFO TaskSchedulerImpl: Adding task set 120.0 with 5 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.473888Z","level":"info","event":"25/12/28 17:43:21 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 200) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.474244Z","level":"info","event":"25/12/28 17:43:21 INFO TaskSetManager: Starting task 1.0 in stage 120.0 (TID 201) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.474301Z","level":"info","event":"25/12/28 17:43:21 INFO TaskSetManager: Starting task 2.0 in stage 120.0 (TID 202) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.474326Z","level":"info","event":"25/12/28 17:43:21 INFO TaskSetManager: Starting task 3.0 in stage 120.0 (TID 203) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.474415Z","level":"info","event":"25/12/28 17:43:21 INFO TaskSetManager: Starting task 4.0 in stage 120.0 (TID 204) (c252dd92c865, executor driver, partition 4, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.477468Z","level":"info","event":"25/12/28 17:43:21 INFO Executor: Running task 0.0 in stage 120.0 (TID 200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.477871Z","level":"info","event":"25/12/28 17:43:21 INFO Executor: Running task 2.0 in stage 120.0 (TID 202)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.478024Z","level":"info","event":"25/12/28 17:43:21 INFO Executor: Running task 1.0 in stage 120.0 (TID 201)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.479162Z","level":"info","event":"25/12/28 17:43:21 INFO Executor: Running task 4.0 in stage 120.0 (TID 204)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.479239Z","level":"info","event":"25/12/28 17:43:21 INFO Executor: Running task 3.0 in stage 120.0 (TID 203)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.532701Z","level":"info","event":"25/12/28 17:43:21 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 12582912-16777216, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.533396Z","level":"info","event":"25/12/28 17:43:21 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.537279Z","level":"info","event":"25/12/28 17:43:21 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 16777216-17654914, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.551034Z","level":"info","event":"25/12/28 17:43:21 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.563067Z","level":"info","event":"25/12/28 17:43:21 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.857100Z","level":"info","event":"25/12/28 17:43:21 INFO Executor: Finished task 4.0 in stage 120.0 (TID 204). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:21.883417Z","level":"info","event":"25/12/28 17:43:21 INFO TaskSetManager: Finished task 4.0 in stage 120.0 (TID 204) in 404 ms on c252dd92c865 (executor driver) (1/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:22.351373Z","level":"info","event":"25/12/28 17:43:22 INFO BlockManagerInfo: Removed broadcast_129_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:22.379335Z","level":"info","event":"25/12/28 17:43:22 INFO BlockManagerInfo: Removed broadcast_128_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:22.432604Z","level":"info","event":"25/12/28 17:43:22 INFO BlockManagerInfo: Removed broadcast_127_piece0 on c252dd92c865:35057 in memory (size: 9.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:22.506646Z","level":"info","event":"25/12/28 17:43:22 INFO BlockManagerInfo: Removed broadcast_126_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:22.536248Z","level":"info","event":"25/12/28 17:43:22 INFO Executor: Finished task 3.0 in stage 120.0 (TID 203). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:22.548113Z","level":"info","event":"25/12/28 17:43:22 INFO BlockManagerInfo: Removed broadcast_130_piece0 on c252dd92c865:35057 in memory (size: 9.1 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:22.555743Z","level":"info","event":"25/12/28 17:43:22 INFO Executor: Finished task 0.0 in stage 120.0 (TID 200). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:22.570896Z","level":"info","event":"25/12/28 17:43:22 INFO BlockManagerInfo: Removed broadcast_131_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:22.572291Z","level":"info","event":"25/12/28 17:43:22 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 200) in 1097 ms on c252dd92c865 (executor driver) (2/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:22.590034Z","level":"info","event":"25/12/28 17:43:22 INFO TaskSetManager: Finished task 3.0 in stage 120.0 (TID 203) in 1110 ms on c252dd92c865 (executor driver) (3/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:22.632524Z","level":"info","event":"25/12/28 17:43:22 INFO Executor: Finished task 1.0 in stage 120.0 (TID 201). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:22.643469Z","level":"info","event":"25/12/28 17:43:22 INFO TaskSetManager: Finished task 1.0 in stage 120.0 (TID 201) in 1168 ms on c252dd92c865 (executor driver) (4/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:22.695631Z","level":"info","event":"25/12/28 17:43:22 INFO Executor: Finished task 2.0 in stage 120.0 (TID 202). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:22.698042Z","level":"info","event":"25/12/28 17:43:22 INFO TaskSetManager: Finished task 2.0 in stage 120.0 (TID 202) in 1223 ms on c252dd92c865 (executor driver) (5/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:22.704267Z","level":"info","event":"25/12/28 17:43:22 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:22.714567Z","level":"info","event":"25/12/28 17:43:22 INFO DAGScheduler: ShuffleMapStage 120 (count at <unknown>:0) finished in 1.250 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:22.716861Z","level":"info","event":"25/12/28 17:43:22 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:22.725151Z","level":"info","event":"25/12/28 17:43:22 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:22.725373Z","level":"info","event":"25/12/28 17:43:22 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:22.725413Z","level":"info","event":"25/12/28 17:43:22 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.153947Z","level":"info","event":"25/12/28 17:43:23 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.182844Z","level":"info","event":"25/12/28 17:43:23 INFO DAGScheduler: Got job 83 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.183037Z","level":"info","event":"25/12/28 17:43:23 INFO DAGScheduler: Final stage: ResultStage 122 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.183381Z","level":"info","event":"25/12/28 17:43:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 121)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.183939Z","level":"info","event":"25/12/28 17:43:23 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.191550Z","level":"info","event":"25/12/28 17:43:23 INFO DAGScheduler: Submitting ResultStage 122 (MapPartitionsRDD[332] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.232633Z","level":"info","event":"25/12/28 17:43:23 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.258330Z","level":"info","event":"25/12/28 17:43:23 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.267345Z","level":"info","event":"25/12/28 17:43:23 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.275696Z","level":"info","event":"25/12/28 17:43:23 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.278118Z","level":"info","event":"25/12/28 17:43:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 122 (MapPartitionsRDD[332] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.281493Z","level":"info","event":"25/12/28 17:43:23 INFO TaskSchedulerImpl: Adding task set 122.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.329035Z","level":"info","event":"25/12/28 17:43:23 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 205) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.346130Z","level":"info","event":"25/12/28 17:43:23 INFO Executor: Running task 0.0 in stage 122.0 (TID 205)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.436602Z","level":"info","event":"25/12/28 17:43:23 INFO ShuffleBlockFetcherIterator: Getting 5 (300.0 B) non-empty blocks including 5 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.437711Z","level":"info","event":"25/12/28 17:43:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.461551Z","level":"info","event":"25/12/28 17:43:23 INFO Executor: Finished task 0.0 in stage 122.0 (TID 205). 4031 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.466475Z","level":"info","event":"25/12/28 17:43:23 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 205) in 138 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.466636Z","level":"info","event":"25/12/28 17:43:23 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.466684Z","level":"info","event":"25/12/28 17:43:23 INFO DAGScheduler: ResultStage 122 (count at <unknown>:0) finished in 0.261 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.468344Z","level":"info","event":"25/12/28 17:43:23 INFO DAGScheduler: Job 83 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.469156Z","level":"info","event":"25/12/28 17:43:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 122: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.470964Z","level":"info","event":"25/12/28 17:43:23 INFO DAGScheduler: Job 83 finished: count at <unknown>:0, took 0.317074 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.696931Z","level":"info","event":"25/12/28 17:43:23 INFO FileSourceStrategy: Pushed Filters: IsNull(order_approved_at)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.698620Z","level":"info","event":"25/12/28 17:43:23 INFO FileSourceStrategy: Post-Scan Filters: isnull(order_approved_at#570)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.776714Z","level":"info","event":"25/12/28 17:43:23 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 199.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.806529Z","level":"info","event":"25/12/28 17:43:23 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.810569Z","level":"info","event":"25/12/28 17:43:23 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.827819Z","level":"info","event":"25/12/28 17:43:23 INFO SparkContext: Created broadcast 135 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.843726Z","level":"info","event":"25/12/28 17:43:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.901664Z","level":"info","event":"25/12/28 17:43:23 INFO DAGScheduler: Registering RDD 336 (count at <unknown>:0) as input to shuffle 39","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.901841Z","level":"info","event":"25/12/28 17:43:23 INFO DAGScheduler: Got map stage job 84 (count at <unknown>:0) with 5 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.901903Z","level":"info","event":"25/12/28 17:43:23 INFO DAGScheduler: Final stage: ShuffleMapStage 123 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.901944Z","level":"info","event":"25/12/28 17:43:23 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.905643Z","level":"info","event":"25/12/28 17:43:23 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.917622Z","level":"info","event":"25/12/28 17:43:23 INFO DAGScheduler: Submitting ShuffleMapStage 123 (MapPartitionsRDD[336] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.925938Z","level":"info","event":"25/12/28 17:43:23 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 18.6 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.930332Z","level":"info","event":"25/12/28 17:43:23 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.931944Z","level":"info","event":"25/12/28 17:43:23 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on c252dd92c865:35057 (size: 9.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.936716Z","level":"info","event":"25/12/28 17:43:23 INFO SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.937017Z","level":"info","event":"25/12/28 17:43:23 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 123 (MapPartitionsRDD[336] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.937200Z","level":"info","event":"25/12/28 17:43:23 INFO TaskSchedulerImpl: Adding task set 123.0 with 5 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.943462Z","level":"info","event":"25/12/28 17:43:23 INFO TaskSetManager: Starting task 0.0 in stage 123.0 (TID 206) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.946863Z","level":"info","event":"25/12/28 17:43:23 INFO TaskSetManager: Starting task 1.0 in stage 123.0 (TID 207) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.947010Z","level":"info","event":"25/12/28 17:43:23 INFO TaskSetManager: Starting task 2.0 in stage 123.0 (TID 208) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.947058Z","level":"info","event":"25/12/28 17:43:23 INFO TaskSetManager: Starting task 3.0 in stage 123.0 (TID 209) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.947093Z","level":"info","event":"25/12/28 17:43:23 INFO TaskSetManager: Starting task 4.0 in stage 123.0 (TID 210) (c252dd92c865, executor driver, partition 4, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.956248Z","level":"info","event":"25/12/28 17:43:23 INFO Executor: Running task 2.0 in stage 123.0 (TID 208)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.958115Z","level":"info","event":"25/12/28 17:43:23 INFO Executor: Running task 3.0 in stage 123.0 (TID 209)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.961966Z","level":"info","event":"25/12/28 17:43:23 INFO Executor: Running task 4.0 in stage 123.0 (TID 210)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.962115Z","level":"info","event":"25/12/28 17:43:23 INFO Executor: Running task 1.0 in stage 123.0 (TID 207)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.962163Z","level":"info","event":"25/12/28 17:43:23 INFO Executor: Running task 0.0 in stage 123.0 (TID 206)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.983469Z","level":"info","event":"25/12/28 17:43:23 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 12582912-16777216, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.983690Z","level":"info","event":"25/12/28 17:43:23 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.984040Z","level":"info","event":"25/12/28 17:43:23 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.984441Z","level":"info","event":"25/12/28 17:43:23 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:23.991041Z","level":"info","event":"25/12/28 17:43:23 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 16777216-17654914, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.164801Z","level":"info","event":"25/12/28 17:43:24 INFO Executor: Finished task 4.0 in stage 123.0 (TID 210). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.183921Z","level":"info","event":"25/12/28 17:43:24 INFO TaskSetManager: Finished task 4.0 in stage 123.0 (TID 210) in 226 ms on c252dd92c865 (executor driver) (1/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.461817Z","level":"info","event":"25/12/28 17:43:24 INFO Executor: Finished task 1.0 in stage 123.0 (TID 207). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.465149Z","level":"info","event":"25/12/28 17:43:24 INFO Executor: Finished task 2.0 in stage 123.0 (TID 208). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.472204Z","level":"info","event":"25/12/28 17:43:24 INFO TaskSetManager: Finished task 2.0 in stage 123.0 (TID 208) in 526 ms on c252dd92c865 (executor driver) (2/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.482696Z","level":"info","event":"25/12/28 17:43:24 INFO Executor: Finished task 0.0 in stage 123.0 (TID 206). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.483156Z","level":"info","event":"25/12/28 17:43:24 INFO TaskSetManager: Finished task 1.0 in stage 123.0 (TID 207) in 536 ms on c252dd92c865 (executor driver) (3/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.485581Z","level":"info","event":"25/12/28 17:43:24 INFO TaskSetManager: Finished task 0.0 in stage 123.0 (TID 206) in 542 ms on c252dd92c865 (executor driver) (4/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.526077Z","level":"info","event":"25/12/28 17:43:24 INFO Executor: Finished task 3.0 in stage 123.0 (TID 209). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.532741Z","level":"info","event":"25/12/28 17:43:24 INFO TaskSetManager: Finished task 3.0 in stage 123.0 (TID 209) in 583 ms on c252dd92c865 (executor driver) (5/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.533073Z","level":"info","event":"25/12/28 17:43:24 INFO TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.533357Z","level":"info","event":"25/12/28 17:43:24 INFO DAGScheduler: ShuffleMapStage 123 (count at <unknown>:0) finished in 0.614 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.534310Z","level":"info","event":"25/12/28 17:43:24 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.534760Z","level":"info","event":"25/12/28 17:43:24 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.535308Z","level":"info","event":"25/12/28 17:43:24 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.535446Z","level":"info","event":"25/12/28 17:43:24 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.651998Z","level":"info","event":"25/12/28 17:43:24 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.656945Z","level":"info","event":"25/12/28 17:43:24 INFO DAGScheduler: Got job 85 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.657177Z","level":"info","event":"25/12/28 17:43:24 INFO DAGScheduler: Final stage: ResultStage 125 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.657313Z","level":"info","event":"25/12/28 17:43:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 124)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.657637Z","level":"info","event":"25/12/28 17:43:24 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.658815Z","level":"info","event":"25/12/28 17:43:24 INFO DAGScheduler: Submitting ResultStage 125 (MapPartitionsRDD[339] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.665526Z","level":"info","event":"25/12/28 17:43:24 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 12.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.681353Z","level":"info","event":"25/12/28 17:43:24 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.683781Z","level":"info","event":"25/12/28 17:43:24 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.685260Z","level":"info","event":"25/12/28 17:43:24 INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.686575Z","level":"info","event":"25/12/28 17:43:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 125 (MapPartitionsRDD[339] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.687565Z","level":"info","event":"25/12/28 17:43:24 INFO TaskSchedulerImpl: Adding task set 125.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.697449Z","level":"info","event":"25/12/28 17:43:24 INFO TaskSetManager: Starting task 0.0 in stage 125.0 (TID 211) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.701850Z","level":"info","event":"25/12/28 17:43:24 INFO Executor: Running task 0.0 in stage 125.0 (TID 211)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.718098Z","level":"info","event":"25/12/28 17:43:24 INFO ShuffleBlockFetcherIterator: Getting 5 (300.0 B) non-empty blocks including 5 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.718955Z","level":"info","event":"25/12/28 17:43:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.744125Z","level":"info","event":"25/12/28 17:43:24 INFO Executor: Finished task 0.0 in stage 125.0 (TID 211). 4038 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.747082Z","level":"info","event":"25/12/28 17:43:24 INFO TaskSetManager: Finished task 0.0 in stage 125.0 (TID 211) in 51 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.747206Z","level":"info","event":"25/12/28 17:43:24 INFO TaskSchedulerImpl: Removed TaskSet 125.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.748996Z","level":"info","event":"25/12/28 17:43:24 INFO DAGScheduler: ResultStage 125 (count at <unknown>:0) finished in 0.087 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.757460Z","level":"info","event":"25/12/28 17:43:24 INFO DAGScheduler: Job 85 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.758295Z","level":"info","event":"25/12/28 17:43:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 125: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.760572Z","level":"info","event":"25/12/28 17:43:24 INFO DAGScheduler: Job 85 finished: count at <unknown>:0, took 0.108685 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.775797Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.776166Z","level":"info","event":"Column order_approved_at (StringType()) in olist_orders has 160 null values.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.961347Z","level":"info","event":"25/12/28 17:43:24 INFO FileSourceStrategy: Pushed Filters: IsNull(order_delivered_carrier_date)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:24.964146Z","level":"info","event":"25/12/28 17:43:24 INFO FileSourceStrategy: Post-Scan Filters: isnull(order_delivered_carrier_date#571)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.015700Z","level":"info","event":"25/12/28 17:43:25 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.069292Z","level":"info","event":"25/12/28 17:43:25 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.075297Z","level":"info","event":"25/12/28 17:43:25 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.081658Z","level":"info","event":"25/12/28 17:43:25 INFO SparkContext: Created broadcast 138 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.105128Z","level":"info","event":"25/12/28 17:43:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.136500Z","level":"info","event":"25/12/28 17:43:25 INFO DAGScheduler: Registering RDD 343 (count at <unknown>:0) as input to shuffle 40","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.137271Z","level":"info","event":"25/12/28 17:43:25 INFO DAGScheduler: Got map stage job 86 (count at <unknown>:0) with 5 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.137485Z","level":"info","event":"25/12/28 17:43:25 INFO DAGScheduler: Final stage: ShuffleMapStage 126 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.137697Z","level":"info","event":"25/12/28 17:43:25 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.139412Z","level":"info","event":"25/12/28 17:43:25 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.141516Z","level":"info","event":"25/12/28 17:43:25 INFO DAGScheduler: Submitting ShuffleMapStage 126 (MapPartitionsRDD[343] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.152662Z","level":"info","event":"25/12/28 17:43:25 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 18.6 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.159637Z","level":"info","event":"25/12/28 17:43:25 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.160267Z","level":"info","event":"25/12/28 17:43:25 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on c252dd92c865:35057 (size: 9.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.160849Z","level":"info","event":"25/12/28 17:43:25 INFO SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.161569Z","level":"info","event":"25/12/28 17:43:25 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 126 (MapPartitionsRDD[343] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.163528Z","level":"info","event":"25/12/28 17:43:25 INFO TaskSchedulerImpl: Adding task set 126.0 with 5 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.176995Z","level":"info","event":"25/12/28 17:43:25 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 212) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.185358Z","level":"info","event":"25/12/28 17:43:25 INFO TaskSetManager: Starting task 1.0 in stage 126.0 (TID 213) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.188671Z","level":"info","event":"25/12/28 17:43:25 INFO TaskSetManager: Starting task 2.0 in stage 126.0 (TID 214) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.189038Z","level":"info","event":"25/12/28 17:43:25 INFO TaskSetManager: Starting task 3.0 in stage 126.0 (TID 215) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.194991Z","level":"info","event":"25/12/28 17:43:25 INFO TaskSetManager: Starting task 4.0 in stage 126.0 (TID 216) (c252dd92c865, executor driver, partition 4, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.197587Z","level":"info","event":"25/12/28 17:43:25 INFO Executor: Running task 3.0 in stage 126.0 (TID 215)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.197945Z","level":"info","event":"25/12/28 17:43:25 INFO Executor: Running task 4.0 in stage 126.0 (TID 216)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.204027Z","level":"info","event":"25/12/28 17:43:25 INFO Executor: Running task 0.0 in stage 126.0 (TID 212)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.204523Z","level":"info","event":"25/12/28 17:43:25 INFO Executor: Running task 1.0 in stage 126.0 (TID 213)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.204629Z","level":"info","event":"25/12/28 17:43:25 INFO Executor: Running task 2.0 in stage 126.0 (TID 214)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.226520Z","level":"info","event":"25/12/28 17:43:25 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.226917Z","level":"info","event":"25/12/28 17:43:25 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.229503Z","level":"info","event":"25/12/28 17:43:25 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.229737Z","level":"info","event":"25/12/28 17:43:25 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 16777216-17654914, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.232580Z","level":"info","event":"25/12/28 17:43:25 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 12582912-16777216, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.577888Z","level":"info","event":"25/12/28 17:43:25 INFO Executor: Finished task 4.0 in stage 126.0 (TID 216). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.592633Z","level":"info","event":"25/12/28 17:43:25 INFO Executor: Finished task 1.0 in stage 126.0 (TID 213). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.624557Z","level":"info","event":"25/12/28 17:43:25 INFO TaskSetManager: Finished task 4.0 in stage 126.0 (TID 216) in 424 ms on c252dd92c865 (executor driver) (1/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.639551Z","level":"info","event":"25/12/28 17:43:25 INFO TaskSetManager: Finished task 1.0 in stage 126.0 (TID 213) in 454 ms on c252dd92c865 (executor driver) (2/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.663737Z","level":"info","event":"25/12/28 17:43:25 INFO Executor: Finished task 2.0 in stage 126.0 (TID 214). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.673955Z","level":"info","event":"25/12/28 17:43:25 INFO TaskSetManager: Finished task 2.0 in stage 126.0 (TID 214) in 493 ms on c252dd92c865 (executor driver) (3/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.695806Z","level":"info","event":"25/12/28 17:43:25 INFO Executor: Finished task 0.0 in stage 126.0 (TID 212). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.696519Z","level":"info","event":"25/12/28 17:43:25 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 212) in 523 ms on c252dd92c865 (executor driver) (4/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.709903Z","level":"info","event":"25/12/28 17:43:25 INFO Executor: Finished task 3.0 in stage 126.0 (TID 215). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:25.711808Z","level":"info","event":"25/12/28 17:43:25 INFO TaskSetManager: Finished task 3.0 in stage 126.0 (TID 215) in 531 ms on c252dd92c865 (executor driver) (5/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.950127Z","level":"info","event":"25/12/28 17:43:25 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.959431Z","level":"info","event":"25/12/28 17:43:25 INFO DAGScheduler: ShuffleMapStage 126 (count at <unknown>:0) finished in 0.566 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.959748Z","level":"info","event":"25/12/28 17:43:25 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.960067Z","level":"info","event":"25/12/28 17:43:25 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.960155Z","level":"info","event":"25/12/28 17:43:25 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.960203Z","level":"info","event":"25/12/28 17:43:25 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.960242Z","level":"info","event":"25/12/28 17:43:26 INFO BlockManagerInfo: Removed broadcast_135_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.960294Z","level":"info","event":"25/12/28 17:43:26 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.960342Z","level":"info","event":"25/12/28 17:43:26 INFO BlockManagerInfo: Removed broadcast_133_piece0 on c252dd92c865:35057 in memory (size: 9.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.960382Z","level":"info","event":"25/12/28 17:43:26 INFO BlockManagerInfo: Removed broadcast_139_piece0 on c252dd92c865:35057 in memory (size: 9.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.960404Z","level":"info","event":"25/12/28 17:43:26 INFO BlockManagerInfo: Removed broadcast_134_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.960483Z","level":"info","event":"25/12/28 17:43:26 INFO BlockManagerInfo: Removed broadcast_132_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.960726Z","level":"info","event":"25/12/28 17:43:26 INFO BlockManagerInfo: Removed broadcast_136_piece0 on c252dd92c865:35057 in memory (size: 9.1 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.960835Z","level":"info","event":"25/12/28 17:43:26 INFO DAGScheduler: Got job 87 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.960939Z","level":"info","event":"25/12/28 17:43:26 INFO DAGScheduler: Final stage: ResultStage 128 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.961468Z","level":"info","event":"25/12/28 17:43:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 127)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.961652Z","level":"info","event":"25/12/28 17:43:26 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.961775Z","level":"info","event":"25/12/28 17:43:26 INFO DAGScheduler: Submitting ResultStage 128 (MapPartitionsRDD[346] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.961890Z","level":"info","event":"25/12/28 17:43:26 INFO BlockManagerInfo: Removed broadcast_137_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.961997Z","level":"info","event":"25/12/28 17:43:26 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 12.5 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.962173Z","level":"info","event":"25/12/28 17:43:26 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.962235Z","level":"info","event":"25/12/28 17:43:26 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.962267Z","level":"info","event":"25/12/28 17:43:26 INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.962296Z","level":"info","event":"25/12/28 17:43:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 128 (MapPartitionsRDD[346] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.962337Z","level":"info","event":"25/12/28 17:43:26 INFO TaskSchedulerImpl: Adding task set 128.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.962567Z","level":"info","event":"25/12/28 17:43:26 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 217) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.962642Z","level":"info","event":"25/12/28 17:43:26 INFO Executor: Running task 0.0 in stage 128.0 (TID 217)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.962692Z","level":"info","event":"25/12/28 17:43:26 INFO ShuffleBlockFetcherIterator: Getting 5 (300.0 B) non-empty blocks including 5 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.962743Z","level":"info","event":"25/12/28 17:43:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 21 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.962782Z","level":"info","event":"25/12/28 17:43:26 INFO Executor: Finished task 0.0 in stage 128.0 (TID 217). 4038 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.962827Z","level":"info","event":"25/12/28 17:43:26 INFO TaskSetManager: Finished task 0.0 in stage 128.0 (TID 217) in 203 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.962870Z","level":"info","event":"25/12/28 17:43:26 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.962909Z","level":"info","event":"25/12/28 17:43:26 INFO DAGScheduler: ResultStage 128 (count at <unknown>:0) finished in 0.284 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.962937Z","level":"info","event":"25/12/28 17:43:26 INFO DAGScheduler: Job 87 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.962981Z","level":"info","event":"25/12/28 17:43:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 128: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.963015Z","level":"info","event":"25/12/28 17:43:26 INFO DAGScheduler: Job 87 finished: count at <unknown>:0, took 0.377124 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.963044Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.963081Z","level":"info","event":"Column order_delivered_carrier_date (StringType()) in olist_orders has 1783 null values.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.963225Z","level":"info","event":"25/12/28 17:43:27 INFO FileSourceStrategy: Pushed Filters: IsNull(order_delivered_customer_date)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.963313Z","level":"info","event":"25/12/28 17:43:27 INFO FileSourceStrategy: Post-Scan Filters: isnull(order_delivered_customer_date#572)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.963660Z","level":"info","event":"25/12/28 17:43:27 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 199.2 KiB, free 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.963810Z","level":"info","event":"25/12/28 17:43:27 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.963948Z","level":"info","event":"25/12/28 17:43:27 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.964047Z","level":"info","event":"25/12/28 17:43:27 INFO SparkContext: Created broadcast 141 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.964119Z","level":"info","event":"25/12/28 17:43:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.964170Z","level":"info","event":"25/12/28 17:43:27 INFO DAGScheduler: Registering RDD 350 (count at <unknown>:0) as input to shuffle 41","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.964220Z","level":"info","event":"25/12/28 17:43:27 INFO DAGScheduler: Got map stage job 88 (count at <unknown>:0) with 5 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.964269Z","level":"info","event":"25/12/28 17:43:27 INFO DAGScheduler: Final stage: ShuffleMapStage 129 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.964400Z","level":"info","event":"25/12/28 17:43:27 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.964442Z","level":"info","event":"25/12/28 17:43:27 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.964522Z","level":"info","event":"25/12/28 17:43:27 INFO DAGScheduler: Submitting ShuffleMapStage 129 (MapPartitionsRDD[350] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.964662Z","level":"info","event":"25/12/28 17:43:27 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 18.6 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.964779Z","level":"info","event":"25/12/28 17:43:27 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.964874Z","level":"info","event":"25/12/28 17:43:27 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on c252dd92c865:35057 (size: 9.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.964947Z","level":"info","event":"25/12/28 17:43:27 INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.965025Z","level":"info","event":"25/12/28 17:43:27 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 129 (MapPartitionsRDD[350] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.965375Z","level":"info","event":"25/12/28 17:43:27 INFO TaskSchedulerImpl: Adding task set 129.0 with 5 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.965565Z","level":"info","event":"25/12/28 17:43:27 INFO TaskSetManager: Starting task 0.0 in stage 129.0 (TID 218) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.965634Z","level":"info","event":"25/12/28 17:43:27 INFO TaskSetManager: Starting task 1.0 in stage 129.0 (TID 219) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.965687Z","level":"info","event":"25/12/28 17:43:27 INFO TaskSetManager: Starting task 2.0 in stage 129.0 (TID 220) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.965775Z","level":"info","event":"25/12/28 17:43:27 INFO TaskSetManager: Starting task 3.0 in stage 129.0 (TID 221) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.965875Z","level":"info","event":"25/12/28 17:43:27 INFO TaskSetManager: Starting task 4.0 in stage 129.0 (TID 222) (c252dd92c865, executor driver, partition 4, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.965965Z","level":"info","event":"25/12/28 17:43:27 INFO Executor: Running task 0.0 in stage 129.0 (TID 218)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.966146Z","level":"info","event":"25/12/28 17:43:27 INFO Executor: Running task 1.0 in stage 129.0 (TID 219)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.966221Z","level":"info","event":"25/12/28 17:43:27 INFO Executor: Running task 3.0 in stage 129.0 (TID 221)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.966277Z","level":"info","event":"25/12/28 17:43:27 INFO Executor: Running task 4.0 in stage 129.0 (TID 222)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.966321Z","level":"info","event":"25/12/28 17:43:27 INFO Executor: Running task 2.0 in stage 129.0 (TID 220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.966353Z","level":"info","event":"25/12/28 17:43:27 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.966406Z","level":"info","event":"25/12/28 17:43:27 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 16777216-17654914, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.966471Z","level":"info","event":"25/12/28 17:43:27 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.966559Z","level":"info","event":"25/12/28 17:43:27 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.966599Z","level":"info","event":"25/12/28 17:43:27 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 12582912-16777216, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.966630Z","level":"info","event":"25/12/28 17:43:27 INFO Executor: Finished task 4.0 in stage 129.0 (TID 222). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.966666Z","level":"info","event":"25/12/28 17:43:27 INFO TaskSetManager: Finished task 4.0 in stage 129.0 (TID 222) in 195 ms on c252dd92c865 (executor driver) (1/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.966689Z","level":"info","event":"25/12/28 17:43:27 INFO Executor: Finished task 2.0 in stage 129.0 (TID 220). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.966716Z","level":"info","event":"25/12/28 17:43:27 INFO TaskSetManager: Finished task 2.0 in stage 129.0 (TID 220) in 332 ms on c252dd92c865 (executor driver) (2/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.966735Z","level":"info","event":"25/12/28 17:43:27 INFO Executor: Finished task 1.0 in stage 129.0 (TID 219). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.966768Z","level":"info","event":"25/12/28 17:43:27 INFO TaskSetManager: Finished task 1.0 in stage 129.0 (TID 219) in 342 ms on c252dd92c865 (executor driver) (3/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.966794Z","level":"info","event":"25/12/28 17:43:27 INFO Executor: Finished task 0.0 in stage 129.0 (TID 218). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.966825Z","level":"info","event":"25/12/28 17:43:27 INFO TaskSetManager: Finished task 0.0 in stage 129.0 (TID 218) in 380 ms on c252dd92c865 (executor driver) (4/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.966857Z","level":"info","event":"25/12/28 17:43:27 INFO Executor: Finished task 3.0 in stage 129.0 (TID 221). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.966891Z","level":"info","event":"25/12/28 17:43:27 INFO TaskSetManager: Finished task 3.0 in stage 129.0 (TID 221) in 396 ms on c252dd92c865 (executor driver) (5/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.966912Z","level":"info","event":"25/12/28 17:43:27 INFO TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.966933Z","level":"info","event":"25/12/28 17:43:27 INFO DAGScheduler: ShuffleMapStage 129 (count at <unknown>:0) finished in 0.428 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.966969Z","level":"info","event":"25/12/28 17:43:27 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.966990Z","level":"info","event":"25/12/28 17:43:27 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967005Z","level":"info","event":"25/12/28 17:43:27 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967019Z","level":"info","event":"25/12/28 17:43:27 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967043Z","level":"info","event":"25/12/28 17:43:27 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967070Z","level":"info","event":"25/12/28 17:43:27 INFO DAGScheduler: Got job 89 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967103Z","level":"info","event":"25/12/28 17:43:27 INFO DAGScheduler: Final stage: ResultStage 131 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967136Z","level":"info","event":"25/12/28 17:43:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 130)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967168Z","level":"info","event":"25/12/28 17:43:27 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967198Z","level":"info","event":"25/12/28 17:43:27 INFO DAGScheduler: Submitting ResultStage 131 (MapPartitionsRDD[353] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967237Z","level":"info","event":"25/12/28 17:43:27 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 12.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967264Z","level":"info","event":"25/12/28 17:43:27 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967280Z","level":"info","event":"25/12/28 17:43:27 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967305Z","level":"info","event":"25/12/28 17:43:27 INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967329Z","level":"info","event":"25/12/28 17:43:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 131 (MapPartitionsRDD[353] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967352Z","level":"info","event":"25/12/28 17:43:27 INFO TaskSchedulerImpl: Adding task set 131.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967375Z","level":"info","event":"25/12/28 17:43:27 INFO TaskSetManager: Starting task 0.0 in stage 131.0 (TID 223) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967405Z","level":"info","event":"25/12/28 17:43:27 INFO Executor: Running task 0.0 in stage 131.0 (TID 223)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967455Z","level":"info","event":"25/12/28 17:43:27 INFO ShuffleBlockFetcherIterator: Getting 5 (300.0 B) non-empty blocks including 5 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967481Z","level":"info","event":"25/12/28 17:43:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967506Z","level":"info","event":"25/12/28 17:43:27 INFO Executor: Finished task 0.0 in stage 131.0 (TID 223). 3995 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967555Z","level":"info","event":"25/12/28 17:43:27 INFO TaskSetManager: Finished task 0.0 in stage 131.0 (TID 223) in 62 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967605Z","level":"info","event":"25/12/28 17:43:27 INFO TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967654Z","level":"info","event":"25/12/28 17:43:27 INFO DAGScheduler: ResultStage 131 (count at <unknown>:0) finished in 0.124 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967701Z","level":"info","event":"25/12/28 17:43:27 INFO DAGScheduler: Job 89 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967746Z","level":"info","event":"25/12/28 17:43:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 131: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967789Z","level":"info","event":"25/12/28 17:43:27 INFO DAGScheduler: Job 89 finished: count at <unknown>:0, took 0.158407 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.967838Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.968042Z","level":"info","event":"Column order_delivered_customer_date (StringType()) in olist_orders has 2965 null values.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.973521Z","level":"info","event":"25/12/28 17:43:28 INFO FileSourceStrategy: Pushed Filters: IsNull(order_estimated_delivery_date)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.973925Z","level":"info","event":"25/12/28 17:43:28 INFO FileSourceStrategy: Post-Scan Filters: isnull(order_estimated_delivery_date#573)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.974120Z","level":"info","event":"25/12/28 17:43:28 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.974263Z","level":"info","event":"25/12/28 17:43:28 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.974384Z","level":"info","event":"25/12/28 17:43:28 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.974544Z","level":"info","event":"25/12/28 17:43:28 INFO SparkContext: Created broadcast 144 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.974610Z","level":"info","event":"25/12/28 17:43:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.974784Z","level":"info","event":"25/12/28 17:43:28 INFO DAGScheduler: Registering RDD 357 (count at <unknown>:0) as input to shuffle 42","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.974825Z","level":"info","event":"25/12/28 17:43:28 INFO DAGScheduler: Got map stage job 90 (count at <unknown>:0) with 5 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.974934Z","level":"info","event":"25/12/28 17:43:28 INFO DAGScheduler: Final stage: ShuffleMapStage 132 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.975085Z","level":"info","event":"25/12/28 17:43:28 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.975172Z","level":"info","event":"25/12/28 17:43:28 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.975403Z","level":"info","event":"25/12/28 17:43:28 INFO DAGScheduler: Submitting ShuffleMapStage 132 (MapPartitionsRDD[357] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.979173Z","level":"info","event":"25/12/28 17:43:28 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 18.6 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.979338Z","level":"info","event":"25/12/28 17:43:28 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.979376Z","level":"info","event":"25/12/28 17:43:28 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on c252dd92c865:35057 (size: 9.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.979396Z","level":"info","event":"25/12/28 17:43:28 INFO SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.979415Z","level":"info","event":"25/12/28 17:43:28 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 132 (MapPartitionsRDD[357] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.979469Z","level":"info","event":"25/12/28 17:43:28 INFO TaskSchedulerImpl: Adding task set 132.0 with 5 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.979491Z","level":"info","event":"25/12/28 17:43:28 INFO TaskSetManager: Starting task 0.0 in stage 132.0 (TID 224) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.979516Z","level":"info","event":"25/12/28 17:43:28 INFO TaskSetManager: Starting task 1.0 in stage 132.0 (TID 225) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.979539Z","level":"info","event":"25/12/28 17:43:28 INFO TaskSetManager: Starting task 2.0 in stage 132.0 (TID 226) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.979554Z","level":"info","event":"25/12/28 17:43:28 INFO TaskSetManager: Starting task 3.0 in stage 132.0 (TID 227) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.979584Z","level":"info","event":"25/12/28 17:43:28 INFO TaskSetManager: Starting task 4.0 in stage 132.0 (TID 228) (c252dd92c865, executor driver, partition 4, PROCESS_LOCAL, 8277 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.979616Z","level":"info","event":"25/12/28 17:43:28 INFO Executor: Running task 2.0 in stage 132.0 (TID 226)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.979634Z","level":"info","event":"25/12/28 17:43:28 INFO Executor: Running task 1.0 in stage 132.0 (TID 225)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.979661Z","level":"info","event":"25/12/28 17:43:28 INFO Executor: Running task 0.0 in stage 132.0 (TID 224)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.979682Z","level":"info","event":"25/12/28 17:43:28 INFO Executor: Running task 3.0 in stage 132.0 (TID 227)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.979706Z","level":"info","event":"25/12/28 17:43:28 INFO Executor: Running task 4.0 in stage 132.0 (TID 228)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.979735Z","level":"info","event":"25/12/28 17:43:28 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.979819Z","level":"info","event":"25/12/28 17:43:28 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 12582912-16777216, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.979851Z","level":"info","event":"25/12/28 17:43:28 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.979878Z","level":"info","event":"25/12/28 17:43:28 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 16777216-17654914, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.979895Z","level":"info","event":"25/12/28 17:43:28 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.979912Z","level":"info","event":"25/12/28 17:43:28 INFO Executor: Finished task 4.0 in stage 132.0 (TID 228). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.979945Z","level":"info","event":"25/12/28 17:43:28 INFO TaskSetManager: Finished task 4.0 in stage 132.0 (TID 228) in 344 ms on c252dd92c865 (executor driver) (1/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.979978Z","level":"info","event":"25/12/28 17:43:28 INFO Executor: Finished task 3.0 in stage 132.0 (TID 227). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.980012Z","level":"info","event":"25/12/28 17:43:28 INFO TaskSetManager: Finished task 3.0 in stage 132.0 (TID 227) in 452 ms on c252dd92c865 (executor driver) (2/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.980029Z","level":"info","event":"25/12/28 17:43:28 INFO Executor: Finished task 1.0 in stage 132.0 (TID 225). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.980093Z","level":"info","event":"25/12/28 17:43:28 INFO TaskSetManager: Finished task 1.0 in stage 132.0 (TID 225) in 490 ms on c252dd92c865 (executor driver) (3/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.980131Z","level":"info","event":"25/12/28 17:43:28 INFO Executor: Finished task 0.0 in stage 132.0 (TID 224). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.980170Z","level":"info","event":"25/12/28 17:43:28 INFO Executor: Finished task 2.0 in stage 132.0 (TID 226). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.980211Z","level":"info","event":"25/12/28 17:43:28 INFO TaskSetManager: Finished task 2.0 in stage 132.0 (TID 226) in 538 ms on c252dd92c865 (executor driver) (4/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.980248Z","level":"info","event":"25/12/28 17:43:28 INFO TaskSetManager: Finished task 0.0 in stage 132.0 (TID 224) in 540 ms on c252dd92c865 (executor driver) (5/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.980286Z","level":"info","event":"25/12/28 17:43:28 INFO TaskSchedulerImpl: Removed TaskSet 132.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.980315Z","level":"info","event":"25/12/28 17:43:28 INFO DAGScheduler: ShuffleMapStage 132 (count at <unknown>:0) finished in 0.576 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.980353Z","level":"info","event":"25/12/28 17:43:28 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.980390Z","level":"info","event":"25/12/28 17:43:28 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:30.980620Z","level":"info","event":"25/12/28 17:43:28 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.148411Z","level":"info","event":"25/12/28 17:43:28 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.148766Z","level":"info","event":"25/12/28 17:43:29 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.148845Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: Got job 91 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.148912Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: Final stage: ResultStage 134 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.151029Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 133)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.151143Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.151366Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: Submitting ResultStage 134 (MapPartitionsRDD[360] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.151407Z","level":"info","event":"25/12/28 17:43:29 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 12.5 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.151625Z","level":"info","event":"25/12/28 17:43:29 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.151680Z","level":"info","event":"25/12/28 17:43:29 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.151748Z","level":"info","event":"25/12/28 17:43:29 INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.151817Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 134 (MapPartitionsRDD[360] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.151857Z","level":"info","event":"25/12/28 17:43:29 INFO TaskSchedulerImpl: Adding task set 134.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.151908Z","level":"info","event":"25/12/28 17:43:29 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 229) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.151943Z","level":"info","event":"25/12/28 17:43:29 INFO Executor: Running task 0.0 in stage 134.0 (TID 229)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.152007Z","level":"info","event":"25/12/28 17:43:29 INFO ShuffleBlockFetcherIterator: Getting 5 (300.0 B) non-empty blocks including 5 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.152046Z","level":"info","event":"25/12/28 17:43:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.152064Z","level":"info","event":"25/12/28 17:43:29 INFO Executor: Finished task 0.0 in stage 134.0 (TID 229). 4031 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.152153Z","level":"info","event":"25/12/28 17:43:29 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 229) in 67 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.152230Z","level":"info","event":"25/12/28 17:43:29 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.152345Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: ResultStage 134 (count at <unknown>:0) finished in 0.102 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.152376Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: Job 91 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.152414Z","level":"info","event":"25/12/28 17:43:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 134: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.153329Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: Job 91 finished: count at <unknown>:0, took 0.117466 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.153368Z","level":"info","event":"25/12/28 17:43:29 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.153384Z","level":"info","event":"25/12/28 17:43:29 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.153400Z","level":"info","event":"25/12/28 17:43:29 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.153415Z","level":"info","event":"25/12/28 17:43:29 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#708, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.153451Z","level":"info","event":"25/12/28 17:43:29 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 199.3 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.153482Z","level":"info","event":"25/12/28 17:43:29 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.153628Z","level":"info","event":"25/12/28 17:43:29 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on c252dd92c865:35057 (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.153657Z","level":"info","event":"25/12/28 17:43:29 INFO SparkContext: Created broadcast 147 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.153680Z","level":"info","event":"25/12/28 17:43:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.153695Z","level":"info","event":"25/12/28 17:43:29 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.153717Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: Got job 92 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.153759Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: Final stage: ResultStage 135 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.153889Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.153923Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.153944Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: Submitting ResultStage 135 (MapPartitionsRDD[364] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.157349Z","level":"info","event":"25/12/28 17:43:29 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 13.5 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.157476Z","level":"info","event":"25/12/28 17:43:29 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.157519Z","level":"info","event":"25/12/28 17:43:29 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on c252dd92c865:35057 (size: 6.4 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.157551Z","level":"info","event":"25/12/28 17:43:29 INFO SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.157609Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 135 (MapPartitionsRDD[364] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.158546Z","level":"info","event":"25/12/28 17:43:29 INFO TaskSchedulerImpl: Adding task set 135.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.158826Z","level":"info","event":"25/12/28 17:43:29 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 230) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8290 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.158866Z","level":"info","event":"25/12/28 17:43:29 INFO Executor: Running task 0.0 in stage 135.0 (TID 230)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.159068Z","level":"info","event":"25/12/28 17:43:29 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_products_dataset.csv, range: 0-2379446, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.159096Z","level":"info","event":"25/12/28 17:43:29 INFO Executor: Finished task 0.0 in stage 135.0 (TID 230). 1725 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.159115Z","level":"info","event":"25/12/28 17:43:29 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 230) in 33 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.159565Z","level":"info","event":"25/12/28 17:43:29 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.159607Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: ResultStage 135 (csv at NativeMethodAccessorImpl.java:0) finished in 0.047 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.159816Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: Job 92 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.159881Z","level":"info","event":"25/12/28 17:43:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 135: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.160465Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: Job 92 finished: csv at NativeMethodAccessorImpl.java:0, took 0.058034 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.162161Z","level":"info","event":"25/12/28 17:43:29 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.162463Z","level":"info","event":"25/12/28 17:43:29 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.162502Z","level":"info","event":"25/12/28 17:43:29 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 199.3 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.162522Z","level":"info","event":"25/12/28 17:43:29 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.162552Z","level":"info","event":"25/12/28 17:43:29 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on c252dd92c865:35057 (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.162585Z","level":"info","event":"25/12/28 17:43:29 INFO SparkContext: Created broadcast 149 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.163047Z","level":"info","event":"25/12/28 17:43:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.163083Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.163108Z","level":"info","event":"25/12/28 17:43:29 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.163123Z","level":"info","event":"25/12/28 17:43:29 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.163267Z","level":"info","event":"25/12/28 17:43:29 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 199.2 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.163292Z","level":"info","event":"25/12/28 17:43:29 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.163316Z","level":"info","event":"25/12/28 17:43:29 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.163350Z","level":"info","event":"25/12/28 17:43:29 INFO SparkContext: Created broadcast 150 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.163372Z","level":"info","event":"25/12/28 17:43:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.163538Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: Registering RDD 374 (count at <unknown>:0) as input to shuffle 43","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.163566Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: Got map stage job 93 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.163737Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: Final stage: ShuffleMapStage 136 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.163770Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.163792Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.164825Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: Submitting ShuffleMapStage 136 (MapPartitionsRDD[374] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.165067Z","level":"info","event":"25/12/28 17:43:29 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 18.0 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.165106Z","level":"info","event":"25/12/28 17:43:29 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.165410Z","level":"info","event":"25/12/28 17:43:29 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on c252dd92c865:35057 (size: 8.8 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.165462Z","level":"info","event":"25/12/28 17:43:29 INFO SparkContext: Created broadcast 151 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.165495Z","level":"info","event":"25/12/28 17:43:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 136 (MapPartitionsRDD[374] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.165528Z","level":"info","event":"25/12/28 17:43:29 INFO TaskSchedulerImpl: Adding task set 136.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.165707Z","level":"info","event":"25/12/28 17:43:29 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 231) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8279 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.165726Z","level":"info","event":"25/12/28 17:43:29 INFO Executor: Running task 0.0 in stage 136.0 (TID 231)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.165744Z","level":"info","event":"25/12/28 17:43:29 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_products_dataset.csv, range: 0-2379446, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.165909Z","level":"info","event":"25/12/28 17:43:29 INFO BlockManagerInfo: Removed broadcast_142_piece0 on c252dd92c865:35057 in memory (size: 9.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.165955Z","level":"info","event":"25/12/28 17:43:29 INFO BlockManagerInfo: Removed broadcast_145_piece0 on c252dd92c865:35057 in memory (size: 9.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.166053Z","level":"info","event":"25/12/28 17:43:29 INFO BlockManagerInfo: Removed broadcast_149_piece0 on c252dd92c865:35057 in memory (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.166484Z","level":"info","event":"25/12/28 17:43:29 INFO BlockManagerInfo: Removed broadcast_144_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.166582Z","level":"info","event":"25/12/28 17:43:29 INFO BlockManagerInfo: Removed broadcast_146_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.166701Z","level":"info","event":"25/12/28 17:43:29 INFO BlockManagerInfo: Removed broadcast_140_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.176352Z","level":"info","event":"25/12/28 17:43:29 INFO BlockManagerInfo: Removed broadcast_147_piece0 on c252dd92c865:35057 in memory (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.176783Z","level":"info","event":"25/12/28 17:43:29 INFO BlockManagerInfo: Removed broadcast_141_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.177133Z","level":"info","event":"25/12/28 17:43:30 INFO BlockManagerInfo: Removed broadcast_148_piece0 on c252dd92c865:35057 in memory (size: 6.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.177326Z","level":"info","event":"25/12/28 17:43:30 INFO BlockManagerInfo: Removed broadcast_138_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.182804Z","level":"info","event":"25/12/28 17:43:30 INFO BlockManagerInfo: Removed broadcast_143_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.182874Z","level":"info","event":"25/12/28 17:43:30 INFO Executor: Finished task 0.0 in stage 136.0 (TID 231). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.182892Z","level":"info","event":"25/12/28 17:43:30 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 231) in 93 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.182909Z","level":"info","event":"25/12/28 17:43:30 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.182924Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: ShuffleMapStage 136 (count at <unknown>:0) finished in 0.103 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.182941Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.182966Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.182982Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.182997Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.183011Z","level":"info","event":"25/12/28 17:43:30 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.183025Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: Got job 94 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.183050Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: Final stage: ResultStage 138 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.183072Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 137)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.183101Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.183132Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: Submitting ResultStage 138 (MapPartitionsRDD[377] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.183147Z","level":"info","event":"25/12/28 17:43:30 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.183162Z","level":"info","event":"25/12/28 17:43:30 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.183176Z","level":"info","event":"25/12/28 17:43:30 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.183190Z","level":"info","event":"25/12/28 17:43:30 INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.183204Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 138 (MapPartitionsRDD[377] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.183220Z","level":"info","event":"25/12/28 17:43:30 INFO TaskSchedulerImpl: Adding task set 138.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.183233Z","level":"info","event":"25/12/28 17:43:30 INFO TaskSetManager: Starting task 0.0 in stage 138.0 (TID 232) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.183248Z","level":"info","event":"25/12/28 17:43:30 INFO Executor: Running task 0.0 in stage 138.0 (TID 232)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.183511Z","level":"info","event":"25/12/28 17:43:30 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.183639Z","level":"info","event":"25/12/28 17:43:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.183784Z","level":"info","event":"25/12/28 17:43:30 INFO Executor: Finished task 0.0 in stage 138.0 (TID 232). 3995 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.183873Z","level":"info","event":"25/12/28 17:43:30 INFO TaskSetManager: Finished task 0.0 in stage 138.0 (TID 232) in 9 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.183959Z","level":"info","event":"25/12/28 17:43:30 INFO TaskSchedulerImpl: Removed TaskSet 138.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.184334Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: ResultStage 138 (count at <unknown>:0) finished in 0.020 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.184752Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: Job 94 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.184846Z","level":"info","event":"25/12/28 17:43:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 138: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.184875Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: Job 94 finished: count at <unknown>:0, took 0.025596 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.184903Z","level":"info","event":"Loaded olist_products with 32951 records.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.184933Z","level":"info","event":"25/12/28 17:43:30 INFO FileSourceStrategy: Pushed Filters: IsNull(product_id)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.184966Z","level":"info","event":"25/12/28 17:43:30 INFO FileSourceStrategy: Post-Scan Filters: isnull(product_id#725)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.184997Z","level":"info","event":"25/12/28 17:43:30 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 199.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.185033Z","level":"info","event":"25/12/28 17:43:30 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.185082Z","level":"info","event":"25/12/28 17:43:30 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.185112Z","level":"info","event":"25/12/28 17:43:30 INFO SparkContext: Created broadcast 153 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.185136Z","level":"info","event":"25/12/28 17:43:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.185286Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: Registering RDD 381 (count at <unknown>:0) as input to shuffle 44","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.185343Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: Got map stage job 95 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.185377Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: Final stage: ShuffleMapStage 139 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.185397Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.186540Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.186760Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: Submitting ShuffleMapStage 139 (MapPartitionsRDD[381] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.186854Z","level":"info","event":"25/12/28 17:43:30 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 18.6 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.186934Z","level":"info","event":"25/12/28 17:43:30 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.187013Z","level":"info","event":"25/12/28 17:43:30 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on c252dd92c865:35057 (size: 9.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.187088Z","level":"info","event":"25/12/28 17:43:30 INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.187169Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 139 (MapPartitionsRDD[381] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.187253Z","level":"info","event":"25/12/28 17:43:30 INFO TaskSchedulerImpl: Adding task set 139.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.187331Z","level":"info","event":"25/12/28 17:43:30 INFO TaskSetManager: Starting task 0.0 in stage 139.0 (TID 233) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8279 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.187558Z","level":"info","event":"25/12/28 17:43:30 INFO Executor: Running task 0.0 in stage 139.0 (TID 233)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.187611Z","level":"info","event":"25/12/28 17:43:30 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_products_dataset.csv, range: 0-2379446, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.187647Z","level":"info","event":"25/12/28 17:43:30 INFO Executor: Finished task 0.0 in stage 139.0 (TID 233). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.309683Z","level":"info","event":"25/12/28 17:43:30 INFO TaskSetManager: Finished task 0.0 in stage 139.0 (TID 233) in 251 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.309804Z","level":"info","event":"25/12/28 17:43:30 INFO TaskSchedulerImpl: Removed TaskSet 139.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.309829Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: ShuffleMapStage 139 (count at <unknown>:0) finished in 0.285 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.309846Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.309862Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.309878Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.309892Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.309906Z","level":"info","event":"25/12/28 17:43:30 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.309921Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: Got job 96 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.309935Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: Final stage: ResultStage 141 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.309950Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 140)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.309963Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.309978Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: Submitting ResultStage 141 (MapPartitionsRDD[384] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.309992Z","level":"info","event":"25/12/28 17:43:30 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 12.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310006Z","level":"info","event":"25/12/28 17:43:30 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310020Z","level":"info","event":"25/12/28 17:43:30 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310033Z","level":"info","event":"25/12/28 17:43:30 INFO SparkContext: Created broadcast 155 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310047Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 141 (MapPartitionsRDD[384] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310061Z","level":"info","event":"25/12/28 17:43:30 INFO TaskSchedulerImpl: Adding task set 141.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310076Z","level":"info","event":"25/12/28 17:43:30 INFO TaskSetManager: Starting task 0.0 in stage 141.0 (TID 234) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310090Z","level":"info","event":"25/12/28 17:43:30 INFO Executor: Running task 0.0 in stage 141.0 (TID 234)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310104Z","level":"info","event":"25/12/28 17:43:30 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310120Z","level":"info","event":"25/12/28 17:43:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310134Z","level":"info","event":"25/12/28 17:43:30 INFO Executor: Finished task 0.0 in stage 141.0 (TID 234). 4031 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310156Z","level":"info","event":"25/12/28 17:43:30 INFO TaskSetManager: Finished task 0.0 in stage 141.0 (TID 234) in 91 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310175Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: ResultStage 141 (count at <unknown>:0) finished in 0.198 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310189Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: Job 96 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310203Z","level":"info","event":"25/12/28 17:43:30 INFO TaskSchedulerImpl: Removed TaskSet 141.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310217Z","level":"info","event":"25/12/28 17:43:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 141: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310231Z","level":"info","event":"25/12/28 17:43:30 INFO DAGScheduler: Job 96 finished: count at <unknown>:0, took 0.348447 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310245Z","level":"info","event":"25/12/28 17:43:31 INFO FileSourceStrategy: Pushed Filters: IsNull(product_category_name)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310258Z","level":"info","event":"25/12/28 17:43:31 INFO FileSourceStrategy: Post-Scan Filters: isnull(product_category_name#726)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310272Z","level":"info","event":"25/12/28 17:43:31 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310320Z","level":"info","event":"25/12/28 17:43:31 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310344Z","level":"info","event":"25/12/28 17:43:31 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310358Z","level":"info","event":"25/12/28 17:43:31 INFO SparkContext: Created broadcast 156 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310372Z","level":"info","event":"25/12/28 17:43:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310385Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Registering RDD 388 (count at <unknown>:0) as input to shuffle 45","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310400Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Got map stage job 97 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310413Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Final stage: ShuffleMapStage 142 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310444Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310459Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310473Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Submitting ShuffleMapStage 142 (MapPartitionsRDD[388] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310488Z","level":"info","event":"25/12/28 17:43:31 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 18.6 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310514Z","level":"info","event":"25/12/28 17:43:31 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310544Z","level":"info","event":"25/12/28 17:43:31 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on c252dd92c865:35057 (size: 9.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310572Z","level":"info","event":"25/12/28 17:43:31 INFO SparkContext: Created broadcast 157 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310599Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 142 (MapPartitionsRDD[388] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310617Z","level":"info","event":"25/12/28 17:43:31 INFO TaskSchedulerImpl: Adding task set 142.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310644Z","level":"info","event":"25/12/28 17:43:31 INFO TaskSetManager: Starting task 0.0 in stage 142.0 (TID 235) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8279 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310668Z","level":"info","event":"25/12/28 17:43:31 INFO Executor: Running task 0.0 in stage 142.0 (TID 235)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.310697Z","level":"info","event":"25/12/28 17:43:31 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_products_dataset.csv, range: 0-2379446, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.378142Z","level":"info","event":"25/12/28 17:43:31 INFO Executor: Finished task 0.0 in stage 142.0 (TID 235). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.378965Z","level":"info","event":"25/12/28 17:43:31 INFO TaskSetManager: Finished task 0.0 in stage 142.0 (TID 235) in 142 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.379036Z","level":"info","event":"25/12/28 17:43:31 INFO TaskSchedulerImpl: Removed TaskSet 142.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.379388Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: ShuffleMapStage 142 (count at <unknown>:0) finished in 0.161 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.382223Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.382304Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.382337Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.382369Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.405247Z","level":"info","event":"25/12/28 17:43:31 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.408515Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Got job 98 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.408720Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Final stage: ResultStage 144 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.408771Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 143)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.408932Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.409497Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Submitting ResultStage 144 (MapPartitionsRDD[391] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.415517Z","level":"info","event":"25/12/28 17:43:31 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 12.5 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.418222Z","level":"info","event":"25/12/28 17:43:31 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.419296Z","level":"info","event":"25/12/28 17:43:31 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.420784Z","level":"info","event":"25/12/28 17:43:31 INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.421734Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 144 (MapPartitionsRDD[391] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.421813Z","level":"info","event":"25/12/28 17:43:31 INFO TaskSchedulerImpl: Adding task set 144.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.423304Z","level":"info","event":"25/12/28 17:43:31 INFO TaskSetManager: Starting task 0.0 in stage 144.0 (TID 236) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.425370Z","level":"info","event":"25/12/28 17:43:31 INFO Executor: Running task 0.0 in stage 144.0 (TID 236)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.429531Z","level":"info","event":"25/12/28 17:43:31 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.429728Z","level":"info","event":"25/12/28 17:43:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.432441Z","level":"info","event":"25/12/28 17:43:31 INFO Executor: Finished task 0.0 in stage 144.0 (TID 236). 3995 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.433607Z","level":"info","event":"25/12/28 17:43:31 INFO TaskSetManager: Finished task 0.0 in stage 144.0 (TID 236) in 11 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.433706Z","level":"info","event":"25/12/28 17:43:31 INFO TaskSchedulerImpl: Removed TaskSet 144.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.434362Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: ResultStage 144 (count at <unknown>:0) finished in 0.023 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.434560Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Job 98 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.434646Z","level":"info","event":"25/12/28 17:43:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 144: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.434727Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Job 98 finished: count at <unknown>:0, took 0.029135 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.436072Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.436265Z","level":"info","event":"Column product_category_name (StringType()) in olist_products has 610 null values.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.467674Z","level":"info","event":"25/12/28 17:43:31 INFO FileSourceStrategy: Pushed Filters: IsNull(product_name_lenght)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.467914Z","level":"info","event":"25/12/28 17:43:31 INFO FileSourceStrategy: Post-Scan Filters: isnull(product_name_lenght#727)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.491480Z","level":"info","event":"25/12/28 17:43:31 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 199.2 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.505991Z","level":"info","event":"25/12/28 17:43:31 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.507409Z","level":"info","event":"25/12/28 17:43:31 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.510124Z","level":"info","event":"25/12/28 17:43:31 INFO SparkContext: Created broadcast 159 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.512990Z","level":"info","event":"25/12/28 17:43:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.519144Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Registering RDD 395 (count at <unknown>:0) as input to shuffle 46","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.519235Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Got map stage job 99 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.519267Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Final stage: ShuffleMapStage 145 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.519284Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.519445Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.519527Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Submitting ShuffleMapStage 145 (MapPartitionsRDD[395] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.521377Z","level":"info","event":"25/12/28 17:43:31 INFO MemoryStore: Block broadcast_160 stored as values in memory (estimated size 18.6 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.529041Z","level":"info","event":"25/12/28 17:43:31 INFO MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.530455Z","level":"info","event":"25/12/28 17:43:31 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on c252dd92c865:35057 (size: 9.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.531122Z","level":"info","event":"25/12/28 17:43:31 INFO SparkContext: Created broadcast 160 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.532225Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 145 (MapPartitionsRDD[395] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.532523Z","level":"info","event":"25/12/28 17:43:31 INFO TaskSchedulerImpl: Adding task set 145.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.533468Z","level":"info","event":"25/12/28 17:43:31 INFO TaskSetManager: Starting task 0.0 in stage 145.0 (TID 237) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8279 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.535849Z","level":"info","event":"25/12/28 17:43:31 INFO Executor: Running task 0.0 in stage 145.0 (TID 237)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.542343Z","level":"info","event":"25/12/28 17:43:31 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_products_dataset.csv, range: 0-2379446, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.652314Z","level":"info","event":"25/12/28 17:43:31 INFO Executor: Finished task 0.0 in stage 145.0 (TID 237). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.656142Z","level":"info","event":"25/12/28 17:43:31 INFO TaskSetManager: Finished task 0.0 in stage 145.0 (TID 237) in 122 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.656752Z","level":"info","event":"25/12/28 17:43:31 INFO TaskSchedulerImpl: Removed TaskSet 145.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.658350Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: ShuffleMapStage 145 (count at <unknown>:0) finished in 0.138 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.658854Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.659469Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.659686Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.662956Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.734547Z","level":"info","event":"25/12/28 17:43:31 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.734933Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Got job 100 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.734991Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Final stage: ResultStage 147 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.735194Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 146)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.735382Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.741571Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Submitting ResultStage 147 (MapPartitionsRDD[398] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.752812Z","level":"info","event":"25/12/28 17:43:31 INFO MemoryStore: Block broadcast_161 stored as values in memory (estimated size 12.5 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.759061Z","level":"info","event":"25/12/28 17:43:31 INFO MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.759337Z","level":"info","event":"25/12/28 17:43:31 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.759879Z","level":"info","event":"25/12/28 17:43:31 INFO SparkContext: Created broadcast 161 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.760274Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 147 (MapPartitionsRDD[398] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.760348Z","level":"info","event":"25/12/28 17:43:31 INFO TaskSchedulerImpl: Adding task set 147.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.762581Z","level":"info","event":"25/12/28 17:43:31 INFO TaskSetManager: Starting task 0.0 in stage 147.0 (TID 238) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.762960Z","level":"info","event":"25/12/28 17:43:31 INFO Executor: Running task 0.0 in stage 147.0 (TID 238)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.772215Z","level":"info","event":"25/12/28 17:43:31 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.774142Z","level":"info","event":"25/12/28 17:43:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.822545Z","level":"info","event":"25/12/28 17:43:31 INFO Executor: Finished task 0.0 in stage 147.0 (TID 238). 4038 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.834078Z","level":"info","event":"25/12/28 17:43:31 INFO TaskSetManager: Finished task 0.0 in stage 147.0 (TID 238) in 70 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.834780Z","level":"info","event":"25/12/28 17:43:31 INFO TaskSchedulerImpl: Removed TaskSet 147.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.842330Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: ResultStage 147 (count at <unknown>:0) finished in 0.092 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.842480Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Job 100 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.842523Z","level":"info","event":"25/12/28 17:43:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 147: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.842755Z","level":"info","event":"25/12/28 17:43:31 INFO DAGScheduler: Job 100 finished: count at <unknown>:0, took 0.108608 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.854554Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.855748Z","level":"info","event":"Column product_name_lenght (StringType()) in olist_products has 610 null values.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.974982Z","level":"info","event":"25/12/28 17:43:31 INFO FileSourceStrategy: Pushed Filters: IsNull(product_description_lenght)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:31.975755Z","level":"info","event":"25/12/28 17:43:31 INFO FileSourceStrategy: Post-Scan Filters: isnull(product_description_lenght#728)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.019120Z","level":"info","event":"25/12/28 17:43:32 INFO MemoryStore: Block broadcast_162 stored as values in memory (estimated size 199.2 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.041787Z","level":"info","event":"25/12/28 17:43:32 INFO MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.042941Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.046749Z","level":"info","event":"25/12/28 17:43:32 INFO SparkContext: Created broadcast 162 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.052312Z","level":"info","event":"25/12/28 17:43:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.067950Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Registering RDD 402 (count at <unknown>:0) as input to shuffle 47","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.068484Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Got map stage job 101 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.068538Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Final stage: ShuffleMapStage 148 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.068693Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.069100Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.072080Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Submitting ShuffleMapStage 148 (MapPartitionsRDD[402] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.075188Z","level":"info","event":"25/12/28 17:43:32 INFO MemoryStore: Block broadcast_163 stored as values in memory (estimated size 18.6 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.085346Z","level":"info","event":"25/12/28 17:43:32 INFO MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.090720Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on c252dd92c865:35057 (size: 9.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.091758Z","level":"info","event":"25/12/28 17:43:32 INFO SparkContext: Created broadcast 163 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.092217Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 148 (MapPartitionsRDD[402] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.092306Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSchedulerImpl: Adding task set 148.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.093999Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSetManager: Starting task 0.0 in stage 148.0 (TID 239) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8279 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.094795Z","level":"info","event":"25/12/28 17:43:32 INFO Executor: Running task 0.0 in stage 148.0 (TID 239)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.111204Z","level":"info","event":"25/12/28 17:43:32 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_products_dataset.csv, range: 0-2379446, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.241744Z","level":"info","event":"25/12/28 17:43:32 INFO Executor: Finished task 0.0 in stage 148.0 (TID 239). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.243592Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSetManager: Finished task 0.0 in stage 148.0 (TID 239) in 150 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.243715Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSchedulerImpl: Removed TaskSet 148.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.244624Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: ShuffleMapStage 148 (count at <unknown>:0) finished in 0.171 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.244959Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.245394Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.245603Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.245806Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.282700Z","level":"info","event":"25/12/28 17:43:32 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.284626Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Got job 102 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.285064Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Final stage: ResultStage 150 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.285302Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 149)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.285902Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.286276Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Submitting ResultStage 150 (MapPartitionsRDD[405] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.290411Z","level":"info","event":"25/12/28 17:43:32 INFO MemoryStore: Block broadcast_164 stored as values in memory (estimated size 12.5 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.291712Z","level":"info","event":"25/12/28 17:43:32 INFO MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.292380Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.293028Z","level":"info","event":"25/12/28 17:43:32 INFO SparkContext: Created broadcast 164 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.293483Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 150 (MapPartitionsRDD[405] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.293638Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSchedulerImpl: Adding task set 150.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.295567Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSetManager: Starting task 0.0 in stage 150.0 (TID 240) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.296158Z","level":"info","event":"25/12/28 17:43:32 INFO Executor: Running task 0.0 in stage 150.0 (TID 240)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.301265Z","level":"info","event":"25/12/28 17:43:32 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.301569Z","level":"info","event":"25/12/28 17:43:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.305472Z","level":"info","event":"25/12/28 17:43:32 INFO Executor: Finished task 0.0 in stage 150.0 (TID 240). 3995 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.306502Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSetManager: Finished task 0.0 in stage 150.0 (TID 240) in 11 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.306671Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSchedulerImpl: Removed TaskSet 150.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.307076Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: ResultStage 150 (count at <unknown>:0) finished in 0.019 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.307146Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Job 102 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.307188Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 150: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.307587Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Job 102 finished: count at <unknown>:0, took 0.024707 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.314018Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.314779Z","level":"info","event":"Column product_description_lenght (StringType()) in olist_products has 610 null values.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.334281Z","level":"info","event":"25/12/28 17:43:32 INFO FileSourceStrategy: Pushed Filters: IsNull(product_photos_qty)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.334859Z","level":"info","event":"25/12/28 17:43:32 INFO FileSourceStrategy: Post-Scan Filters: isnull(product_photos_qty#729)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.346480Z","level":"info","event":"25/12/28 17:43:32 INFO MemoryStore: Block broadcast_165 stored as values in memory (estimated size 199.2 KiB, free 432.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.360102Z","level":"info","event":"25/12/28 17:43:32 INFO MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 432.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.360953Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.361744Z","level":"info","event":"25/12/28 17:43:32 INFO SparkContext: Created broadcast 165 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.362774Z","level":"info","event":"25/12/28 17:43:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.372037Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Registering RDD 409 (count at <unknown>:0) as input to shuffle 48","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.372232Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Got map stage job 103 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.372487Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Final stage: ShuffleMapStage 151 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.372655Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.372851Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.372988Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Submitting ShuffleMapStage 151 (MapPartitionsRDD[409] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.376276Z","level":"info","event":"25/12/28 17:43:32 INFO MemoryStore: Block broadcast_166 stored as values in memory (estimated size 18.6 KiB, free 432.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.385175Z","level":"info","event":"25/12/28 17:43:32 INFO MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 432.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.385581Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on c252dd92c865:35057 (size: 9.1 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.386246Z","level":"info","event":"25/12/28 17:43:32 INFO SparkContext: Created broadcast 166 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.386895Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 151 (MapPartitionsRDD[409] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.387088Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSchedulerImpl: Adding task set 151.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.388541Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSetManager: Starting task 0.0 in stage 151.0 (TID 241) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8279 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.389284Z","level":"info","event":"25/12/28 17:43:32 INFO Executor: Running task 0.0 in stage 151.0 (TID 241)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.395670Z","level":"info","event":"25/12/28 17:43:32 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_products_dataset.csv, range: 0-2379446, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.477597Z","level":"info","event":"25/12/28 17:43:32 INFO Executor: Finished task 0.0 in stage 151.0 (TID 241). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.479011Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSetManager: Finished task 0.0 in stage 151.0 (TID 241) in 90 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.479187Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSchedulerImpl: Removed TaskSet 151.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.480152Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: ShuffleMapStage 151 (count at <unknown>:0) finished in 0.106 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.480332Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.480518Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.480699Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.481028Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.497846Z","level":"info","event":"25/12/28 17:43:32 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.499484Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Got job 104 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.499614Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Final stage: ResultStage 153 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.499727Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 152)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.499934Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.500376Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Submitting ResultStage 153 (MapPartitionsRDD[412] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.502186Z","level":"info","event":"25/12/28 17:43:32 INFO MemoryStore: Block broadcast_167 stored as values in memory (estimated size 12.5 KiB, free 432.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.503602Z","level":"info","event":"25/12/28 17:43:32 INFO MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 432.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.503936Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.504412Z","level":"info","event":"25/12/28 17:43:32 INFO SparkContext: Created broadcast 167 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.504658Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 153 (MapPartitionsRDD[412] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.504755Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSchedulerImpl: Adding task set 153.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.505674Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSetManager: Starting task 0.0 in stage 153.0 (TID 242) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.506268Z","level":"info","event":"25/12/28 17:43:32 INFO Executor: Running task 0.0 in stage 153.0 (TID 242)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.508539Z","level":"info","event":"25/12/28 17:43:32 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.508771Z","level":"info","event":"25/12/28 17:43:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.510460Z","level":"info","event":"25/12/28 17:43:32 INFO Executor: Finished task 0.0 in stage 153.0 (TID 242). 3995 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.511727Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSetManager: Finished task 0.0 in stage 153.0 (TID 242) in 6 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.512149Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSchedulerImpl: Removed TaskSet 153.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.512255Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: ResultStage 153 (count at <unknown>:0) finished in 0.011 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.512332Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Job 104 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.512373Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 153: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.512710Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Job 104 finished: count at <unknown>:0, took 0.014746 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.513678Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.513874Z","level":"info","event":"Column product_photos_qty (StringType()) in olist_products has 610 null values.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.558620Z","level":"info","event":"25/12/28 17:43:32 INFO FileSourceStrategy: Pushed Filters: IsNull(product_weight_g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.558941Z","level":"info","event":"25/12/28 17:43:32 INFO FileSourceStrategy: Post-Scan Filters: isnull(product_weight_g#730)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.573437Z","level":"info","event":"25/12/28 17:43:32 INFO MemoryStore: Block broadcast_168 stored as values in memory (estimated size 199.2 KiB, free 432.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.646117Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Removed broadcast_166_piece0 on c252dd92c865:35057 in memory (size: 9.1 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.648087Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Removed broadcast_158_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.652755Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Removed broadcast_157_piece0 on c252dd92c865:35057 in memory (size: 9.1 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.653608Z","level":"info","event":"25/12/28 17:43:32 INFO MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 432.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.655972Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.656995Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Removed broadcast_167_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.658482Z","level":"info","event":"25/12/28 17:43:32 INFO SparkContext: Created broadcast 168 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.659082Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Removed broadcast_162_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.662022Z","level":"info","event":"25/12/28 17:43:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.662182Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Removed broadcast_154_piece0 on c252dd92c865:35057 in memory (size: 9.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.667015Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Removed broadcast_151_piece0 on c252dd92c865:35057 in memory (size: 8.8 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.671299Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Removed broadcast_160_piece0 on c252dd92c865:35057 in memory (size: 9.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.671752Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Registering RDD 416 (count at <unknown>:0) as input to shuffle 49","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.672012Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Got map stage job 105 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.672127Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Final stage: ShuffleMapStage 154 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.672240Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.672373Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.672505Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Submitting ShuffleMapStage 154 (MapPartitionsRDD[416] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.675996Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Removed broadcast_161_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.676192Z","level":"info","event":"25/12/28 17:43:32 INFO MemoryStore: Block broadcast_169 stored as values in memory (estimated size 18.6 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.678358Z","level":"info","event":"25/12/28 17:43:32 INFO MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.680284Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on c252dd92c865:35057 (size: 9.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.681602Z","level":"info","event":"25/12/28 17:43:32 INFO SparkContext: Created broadcast 169 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.682305Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Removed broadcast_153_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.682375Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 154 (MapPartitionsRDD[416] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.683288Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSchedulerImpl: Adding task set 154.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.686012Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 243) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8279 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.687186Z","level":"info","event":"25/12/28 17:43:32 INFO Executor: Running task 0.0 in stage 154.0 (TID 243)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.687801Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Removed broadcast_163_piece0 on c252dd92c865:35057 in memory (size: 9.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.692900Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Removed broadcast_164_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.694360Z","level":"info","event":"25/12/28 17:43:32 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_products_dataset.csv, range: 0-2379446, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.697117Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Removed broadcast_159_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.699602Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Removed broadcast_156_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.702129Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Removed broadcast_155_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.705175Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Removed broadcast_150_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.708876Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Removed broadcast_152_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.711126Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Removed broadcast_165_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.774918Z","level":"info","event":"25/12/28 17:43:32 INFO Executor: Finished task 0.0 in stage 154.0 (TID 243). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.775676Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 243) in 89 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.775997Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: ShuffleMapStage 154 (count at <unknown>:0) finished in 0.103 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.776242Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.776297Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.776345Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.776416Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.776718Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.804263Z","level":"info","event":"25/12/28 17:43:32 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.804442Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Got job 106 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.804477Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Final stage: ResultStage 156 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.804512Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 155)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.804543Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.804611Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Submitting ResultStage 156 (MapPartitionsRDD[419] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.804910Z","level":"info","event":"25/12/28 17:43:32 INFO MemoryStore: Block broadcast_170 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.813309Z","level":"info","event":"25/12/28 17:43:32 INFO MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.813564Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.814235Z","level":"info","event":"25/12/28 17:43:32 INFO SparkContext: Created broadcast 170 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.814353Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 156 (MapPartitionsRDD[419] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.814390Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSchedulerImpl: Adding task set 156.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.817492Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSetManager: Starting task 0.0 in stage 156.0 (TID 244) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.819584Z","level":"info","event":"25/12/28 17:43:32 INFO Executor: Running task 0.0 in stage 156.0 (TID 244)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.825954Z","level":"info","event":"25/12/28 17:43:32 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.826259Z","level":"info","event":"25/12/28 17:43:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.829720Z","level":"info","event":"25/12/28 17:43:32 INFO Executor: Finished task 0.0 in stage 156.0 (TID 244). 3995 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.831307Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSetManager: Finished task 0.0 in stage 156.0 (TID 244) in 15 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.831443Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.833655Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: ResultStage 156 (count at <unknown>:0) finished in 0.030 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.833949Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Job 106 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.834134Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 156: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.834168Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Job 106 finished: count at <unknown>:0, took 0.032794 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.834850Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.834905Z","level":"info","event":"Column product_weight_g (StringType()) in olist_products has 2 null values.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.852960Z","level":"info","event":"25/12/28 17:43:32 INFO FileSourceStrategy: Pushed Filters: IsNull(product_length_cm)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.853762Z","level":"info","event":"25/12/28 17:43:32 INFO FileSourceStrategy: Post-Scan Filters: isnull(product_length_cm#731)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.866311Z","level":"info","event":"25/12/28 17:43:32 INFO MemoryStore: Block broadcast_171 stored as values in memory (estimated size 199.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.875585Z","level":"info","event":"25/12/28 17:43:32 INFO MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.875963Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.876434Z","level":"info","event":"25/12/28 17:43:32 INFO SparkContext: Created broadcast 171 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.877009Z","level":"info","event":"25/12/28 17:43:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.880112Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Registering RDD 423 (count at <unknown>:0) as input to shuffle 50","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.880352Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Got map stage job 107 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.880603Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Final stage: ShuffleMapStage 157 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.880643Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.880670Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.880687Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Submitting ShuffleMapStage 157 (MapPartitionsRDD[423] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.882294Z","level":"info","event":"25/12/28 17:43:32 INFO MemoryStore: Block broadcast_172 stored as values in memory (estimated size 18.6 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.884806Z","level":"info","event":"25/12/28 17:43:32 INFO MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.885250Z","level":"info","event":"25/12/28 17:43:32 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on c252dd92c865:35057 (size: 9.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.886304Z","level":"info","event":"25/12/28 17:43:32 INFO SparkContext: Created broadcast 172 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.886720Z","level":"info","event":"25/12/28 17:43:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 157 (MapPartitionsRDD[423] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.886934Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSchedulerImpl: Adding task set 157.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.887977Z","level":"info","event":"25/12/28 17:43:32 INFO TaskSetManager: Starting task 0.0 in stage 157.0 (TID 245) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8279 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.889601Z","level":"info","event":"25/12/28 17:43:32 INFO Executor: Running task 0.0 in stage 157.0 (TID 245)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:32.894613Z","level":"info","event":"25/12/28 17:43:32 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_products_dataset.csv, range: 0-2379446, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.051758Z","level":"info","event":"25/12/28 17:43:33 INFO Executor: Finished task 0.0 in stage 157.0 (TID 245). 2027 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.053755Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSetManager: Finished task 0.0 in stage 157.0 (TID 245) in 166 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.054493Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSchedulerImpl: Removed TaskSet 157.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.056374Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: ShuffleMapStage 157 (count at <unknown>:0) finished in 0.174 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.056530Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.056582Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.056718Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.056789Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.074645Z","level":"info","event":"25/12/28 17:43:33 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.075994Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Got job 108 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.076072Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Final stage: ResultStage 159 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.076112Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 158)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.076371Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.077104Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Submitting ResultStage 159 (MapPartitionsRDD[426] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.080105Z","level":"info","event":"25/12/28 17:43:33 INFO MemoryStore: Block broadcast_173 stored as values in memory (estimated size 12.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.081632Z","level":"info","event":"25/12/28 17:43:33 INFO MemoryStore: Block broadcast_173_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.082064Z","level":"info","event":"25/12/28 17:43:33 INFO BlockManagerInfo: Added broadcast_173_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.082391Z","level":"info","event":"25/12/28 17:43:33 INFO SparkContext: Created broadcast 173 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.082677Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 159 (MapPartitionsRDD[426] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.082778Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSchedulerImpl: Adding task set 159.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.083833Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSetManager: Starting task 0.0 in stage 159.0 (TID 246) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.084611Z","level":"info","event":"25/12/28 17:43:33 INFO Executor: Running task 0.0 in stage 159.0 (TID 246)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.088155Z","level":"info","event":"25/12/28 17:43:33 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.088307Z","level":"info","event":"25/12/28 17:43:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.094110Z","level":"info","event":"25/12/28 17:43:33 INFO Executor: Finished task 0.0 in stage 159.0 (TID 246). 3995 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.095461Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSetManager: Finished task 0.0 in stage 159.0 (TID 246) in 12 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.095556Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSchedulerImpl: Removed TaskSet 159.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.095965Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: ResultStage 159 (count at <unknown>:0) finished in 0.017 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.095999Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Job 108 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.096017Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 159: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.096282Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Job 108 finished: count at <unknown>:0, took 0.021552 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.097728Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.097968Z","level":"info","event":"Column product_length_cm (StringType()) in olist_products has 2 null values.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.124066Z","level":"info","event":"25/12/28 17:43:33 INFO FileSourceStrategy: Pushed Filters: IsNull(product_height_cm)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.124266Z","level":"info","event":"25/12/28 17:43:33 INFO FileSourceStrategy: Post-Scan Filters: isnull(product_height_cm#732)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.138810Z","level":"info","event":"25/12/28 17:43:33 INFO MemoryStore: Block broadcast_174 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.145922Z","level":"info","event":"25/12/28 17:43:33 INFO MemoryStore: Block broadcast_174_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.146718Z","level":"info","event":"25/12/28 17:43:33 INFO BlockManagerInfo: Added broadcast_174_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.147552Z","level":"info","event":"25/12/28 17:43:33 INFO SparkContext: Created broadcast 174 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.148772Z","level":"info","event":"25/12/28 17:43:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.158508Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Registering RDD 430 (count at <unknown>:0) as input to shuffle 51","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.158622Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Got map stage job 109 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.158663Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Final stage: ShuffleMapStage 160 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.158683Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.158701Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.158965Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Submitting ShuffleMapStage 160 (MapPartitionsRDD[430] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.160139Z","level":"info","event":"25/12/28 17:43:33 INFO MemoryStore: Block broadcast_175 stored as values in memory (estimated size 18.6 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.162199Z","level":"info","event":"25/12/28 17:43:33 INFO MemoryStore: Block broadcast_175_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.162510Z","level":"info","event":"25/12/28 17:43:33 INFO BlockManagerInfo: Added broadcast_175_piece0 in memory on c252dd92c865:35057 (size: 9.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.162741Z","level":"info","event":"25/12/28 17:43:33 INFO SparkContext: Created broadcast 175 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.163038Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 160 (MapPartitionsRDD[430] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.163136Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSchedulerImpl: Adding task set 160.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.163698Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSetManager: Starting task 0.0 in stage 160.0 (TID 247) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8279 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.164814Z","level":"info","event":"25/12/28 17:43:33 INFO Executor: Running task 0.0 in stage 160.0 (TID 247)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.166920Z","level":"info","event":"25/12/28 17:43:33 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_products_dataset.csv, range: 0-2379446, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.219401Z","level":"info","event":"25/12/28 17:43:33 INFO Executor: Finished task 0.0 in stage 160.0 (TID 247). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.220445Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSetManager: Finished task 0.0 in stage 160.0 (TID 247) in 57 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.220722Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSchedulerImpl: Removed TaskSet 160.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.221482Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: ShuffleMapStage 160 (count at <unknown>:0) finished in 0.061 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.221641Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.221696Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.221734Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.221788Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.253280Z","level":"info","event":"25/12/28 17:43:33 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.254928Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Got job 110 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.255053Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Final stage: ResultStage 162 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.255134Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 161)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.255196Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.255614Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Submitting ResultStage 162 (MapPartitionsRDD[433] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.257554Z","level":"info","event":"25/12/28 17:43:33 INFO MemoryStore: Block broadcast_176 stored as values in memory (estimated size 12.5 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.262624Z","level":"info","event":"25/12/28 17:43:33 INFO MemoryStore: Block broadcast_176_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.263067Z","level":"info","event":"25/12/28 17:43:33 INFO BlockManagerInfo: Added broadcast_176_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.263728Z","level":"info","event":"25/12/28 17:43:33 INFO SparkContext: Created broadcast 176 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.264948Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 162 (MapPartitionsRDD[433] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.265640Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSchedulerImpl: Adding task set 162.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.269268Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSetManager: Starting task 0.0 in stage 162.0 (TID 248) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.269644Z","level":"info","event":"25/12/28 17:43:33 INFO Executor: Running task 0.0 in stage 162.0 (TID 248)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.271965Z","level":"info","event":"25/12/28 17:43:33 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.272083Z","level":"info","event":"25/12/28 17:43:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.275571Z","level":"info","event":"25/12/28 17:43:33 INFO Executor: Finished task 0.0 in stage 162.0 (TID 248). 3995 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.278651Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSetManager: Finished task 0.0 in stage 162.0 (TID 248) in 10 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.278954Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSchedulerImpl: Removed TaskSet 162.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.280328Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: ResultStage 162 (count at <unknown>:0) finished in 0.023 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.280947Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Job 110 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.281125Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 162: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.284021Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Job 110 finished: count at <unknown>:0, took 0.028495 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.286388Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.286503Z","level":"info","event":"Column product_height_cm (StringType()) in olist_products has 2 null values.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.318342Z","level":"info","event":"25/12/28 17:43:33 INFO FileSourceStrategy: Pushed Filters: IsNull(product_width_cm)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.318798Z","level":"info","event":"25/12/28 17:43:33 INFO FileSourceStrategy: Post-Scan Filters: isnull(product_width_cm#733)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.334944Z","level":"info","event":"25/12/28 17:43:33 INFO MemoryStore: Block broadcast_177 stored as values in memory (estimated size 199.2 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.347517Z","level":"info","event":"25/12/28 17:43:33 INFO MemoryStore: Block broadcast_177_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.348029Z","level":"info","event":"25/12/28 17:43:33 INFO BlockManagerInfo: Added broadcast_177_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.350065Z","level":"info","event":"25/12/28 17:43:33 INFO SparkContext: Created broadcast 177 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.352487Z","level":"info","event":"25/12/28 17:43:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.358583Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Registering RDD 437 (count at <unknown>:0) as input to shuffle 52","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.359102Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Got map stage job 111 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.359315Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Final stage: ShuffleMapStage 163 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.359483Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.359540Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.359591Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Submitting ShuffleMapStage 163 (MapPartitionsRDD[437] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.361565Z","level":"info","event":"25/12/28 17:43:33 INFO MemoryStore: Block broadcast_178 stored as values in memory (estimated size 18.6 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.363144Z","level":"info","event":"25/12/28 17:43:33 INFO MemoryStore: Block broadcast_178_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.363413Z","level":"info","event":"25/12/28 17:43:33 INFO BlockManagerInfo: Added broadcast_178_piece0 in memory on c252dd92c865:35057 (size: 9.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.363770Z","level":"info","event":"25/12/28 17:43:33 INFO SparkContext: Created broadcast 178 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.364088Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 163 (MapPartitionsRDD[437] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.364148Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSchedulerImpl: Adding task set 163.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.365386Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSetManager: Starting task 0.0 in stage 163.0 (TID 249) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8279 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.366001Z","level":"info","event":"25/12/28 17:43:33 INFO Executor: Running task 0.0 in stage 163.0 (TID 249)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.370706Z","level":"info","event":"25/12/28 17:43:33 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_products_dataset.csv, range: 0-2379446, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.426233Z","level":"info","event":"25/12/28 17:43:33 INFO Executor: Finished task 0.0 in stage 163.0 (TID 249). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.427443Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSetManager: Finished task 0.0 in stage 163.0 (TID 249) in 63 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.427525Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSchedulerImpl: Removed TaskSet 163.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.428195Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: ShuffleMapStage 163 (count at <unknown>:0) finished in 0.067 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.428382Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.428549Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.428756Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.428879Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.447062Z","level":"info","event":"25/12/28 17:43:33 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.448029Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Got job 112 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.448129Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Final stage: ResultStage 165 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.448177Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 164)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.448338Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.448696Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Submitting ResultStage 165 (MapPartitionsRDD[440] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.450261Z","level":"info","event":"25/12/28 17:43:33 INFO MemoryStore: Block broadcast_179 stored as values in memory (estimated size 12.5 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.454133Z","level":"info","event":"25/12/28 17:43:33 INFO MemoryStore: Block broadcast_179_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.454567Z","level":"info","event":"25/12/28 17:43:33 INFO BlockManagerInfo: Added broadcast_179_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.455152Z","level":"info","event":"25/12/28 17:43:33 INFO SparkContext: Created broadcast 179 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.455480Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 165 (MapPartitionsRDD[440] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.455639Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSchedulerImpl: Adding task set 165.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.457240Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSetManager: Starting task 0.0 in stage 165.0 (TID 250) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.460629Z","level":"info","event":"25/12/28 17:43:33 INFO Executor: Running task 0.0 in stage 165.0 (TID 250)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.468602Z","level":"info","event":"25/12/28 17:43:33 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.468900Z","level":"info","event":"25/12/28 17:43:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.470693Z","level":"info","event":"25/12/28 17:43:33 INFO Executor: Finished task 0.0 in stage 165.0 (TID 250). 3995 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.476175Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSetManager: Finished task 0.0 in stage 165.0 (TID 250) in 19 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.477025Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSchedulerImpl: Removed TaskSet 165.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.478740Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: ResultStage 165 (count at <unknown>:0) finished in 0.029 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.479945Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Job 112 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.480153Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 165: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.482038Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Job 112 finished: count at <unknown>:0, took 0.034514 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.484535Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.484705Z","level":"info","event":"Column product_width_cm (StringType()) in olist_products has 2 null values.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.537307Z","level":"info","event":"25/12/28 17:43:33 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.547812Z","level":"info","event":"25/12/28 17:43:33 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.704002Z","level":"info","event":"25/12/28 17:43:33 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.704358Z","level":"info","event":"25/12/28 17:43:33 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#893, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.717970Z","level":"info","event":"25/12/28 17:43:33 INFO MemoryStore: Block broadcast_180 stored as values in memory (estimated size 199.3 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.732408Z","level":"info","event":"25/12/28 17:43:33 INFO MemoryStore: Block broadcast_180_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.734094Z","level":"info","event":"25/12/28 17:43:33 INFO BlockManagerInfo: Added broadcast_180_piece0 in memory on c252dd92c865:35057 (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.735836Z","level":"info","event":"25/12/28 17:43:33 INFO SparkContext: Created broadcast 180 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.737877Z","level":"info","event":"25/12/28 17:43:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.747359Z","level":"info","event":"25/12/28 17:43:33 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.749978Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Got job 113 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.750770Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Final stage: ResultStage 166 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.750974Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.751041Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.751101Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Submitting ResultStage 166 (MapPartitionsRDD[444] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.755728Z","level":"info","event":"25/12/28 17:43:33 INFO MemoryStore: Block broadcast_181 stored as values in memory (estimated size 13.5 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.758078Z","level":"info","event":"25/12/28 17:43:33 INFO MemoryStore: Block broadcast_181_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.758378Z","level":"info","event":"25/12/28 17:43:33 INFO BlockManagerInfo: Added broadcast_181_piece0 in memory on c252dd92c865:35057 (size: 6.4 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.758756Z","level":"info","event":"25/12/28 17:43:33 INFO SparkContext: Created broadcast 181 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.759167Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 166 (MapPartitionsRDD[444] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.759354Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSchedulerImpl: Adding task set 166.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.764141Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSetManager: Starting task 0.0 in stage 166.0 (TID 251) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8289 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.766416Z","level":"info","event":"25/12/28 17:43:33 INFO Executor: Running task 0.0 in stage 166.0 (TID 251)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.778657Z","level":"info","event":"25/12/28 17:43:33 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_sellers_dataset.csv, range: 0-174703, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.795203Z","level":"info","event":"25/12/28 17:43:33 INFO Executor: Finished task 0.0 in stage 166.0 (TID 251). 1624 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.800118Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSetManager: Finished task 0.0 in stage 166.0 (TID 251) in 36 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.800813Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSchedulerImpl: Removed TaskSet 166.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.802700Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: ResultStage 166 (csv at NativeMethodAccessorImpl.java:0) finished in 0.048 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.802820Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Job 113 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.802869Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 166: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.802906Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Job 113 finished: csv at NativeMethodAccessorImpl.java:0, took 0.054814 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.831667Z","level":"info","event":"25/12/28 17:43:33 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.832046Z","level":"info","event":"25/12/28 17:43:33 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.834388Z","level":"info","event":"25/12/28 17:43:33 INFO MemoryStore: Block broadcast_182 stored as values in memory (estimated size 199.3 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.848703Z","level":"info","event":"25/12/28 17:43:33 INFO MemoryStore: Block broadcast_182_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 432.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.849366Z","level":"info","event":"25/12/28 17:43:33 INFO BlockManagerInfo: Added broadcast_182_piece0 in memory on c252dd92c865:35057 (size: 34.2 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.850314Z","level":"info","event":"25/12/28 17:43:33 INFO SparkContext: Created broadcast 182 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.853267Z","level":"info","event":"25/12/28 17:43:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.881416Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.899669Z","level":"info","event":"25/12/28 17:43:33 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.900340Z","level":"info","event":"25/12/28 17:43:33 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.920994Z","level":"info","event":"25/12/28 17:43:33 INFO MemoryStore: Block broadcast_183 stored as values in memory (estimated size 199.2 KiB, free 432.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.934461Z","level":"info","event":"25/12/28 17:43:33 INFO MemoryStore: Block broadcast_183_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 432.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.935113Z","level":"info","event":"25/12/28 17:43:33 INFO BlockManagerInfo: Added broadcast_183_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.937452Z","level":"info","event":"25/12/28 17:43:33 INFO SparkContext: Created broadcast 183 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.939107Z","level":"info","event":"25/12/28 17:43:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.952942Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Registering RDD 454 (count at <unknown>:0) as input to shuffle 53","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.953327Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Got map stage job 114 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.953489Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Final stage: ShuffleMapStage 167 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.953538Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.953575Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.954193Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Submitting ShuffleMapStage 167 (MapPartitionsRDD[454] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.974673Z","level":"info","event":"25/12/28 17:43:33 INFO MemoryStore: Block broadcast_184 stored as values in memory (estimated size 17.8 KiB, free 432.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.982088Z","level":"info","event":"25/12/28 17:43:33 INFO MemoryStore: Block broadcast_184_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 432.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.983907Z","level":"info","event":"25/12/28 17:43:33 INFO BlockManagerInfo: Added broadcast_184_piece0 in memory on c252dd92c865:35057 (size: 8.8 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.986575Z","level":"info","event":"25/12/28 17:43:33 INFO SparkContext: Created broadcast 184 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.987148Z","level":"info","event":"25/12/28 17:43:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 167 (MapPartitionsRDD[454] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.987252Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSchedulerImpl: Adding task set 167.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.989025Z","level":"info","event":"25/12/28 17:43:33 INFO TaskSetManager: Starting task 0.0 in stage 167.0 (TID 252) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8278 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:33.992494Z","level":"info","event":"25/12/28 17:43:33 INFO Executor: Running task 0.0 in stage 167.0 (TID 252)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.006511Z","level":"info","event":"25/12/28 17:43:34 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_sellers_dataset.csv, range: 0-174703, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.035365Z","level":"info","event":"25/12/28 17:43:34 INFO Executor: Finished task 0.0 in stage 167.0 (TID 252). 1971 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.055478Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSetManager: Finished task 0.0 in stage 167.0 (TID 252) in 66 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.057239Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSchedulerImpl: Removed TaskSet 167.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.062865Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: ShuffleMapStage 167 (count at <unknown>:0) finished in 0.103 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.063331Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.063474Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.063564Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.063666Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.109476Z","level":"info","event":"25/12/28 17:43:34 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.111940Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Got job 115 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.113269Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Final stage: ResultStage 169 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.115779Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 168)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.115886Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.116039Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Submitting ResultStage 169 (MapPartitionsRDD[457] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.153653Z","level":"info","event":"25/12/28 17:43:34 INFO MemoryStore: Block broadcast_185 stored as values in memory (estimated size 12.5 KiB, free 432.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.192277Z","level":"info","event":"25/12/28 17:43:34 INFO MemoryStore: Block broadcast_185_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 432.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.193295Z","level":"info","event":"25/12/28 17:43:34 INFO BlockManagerInfo: Added broadcast_185_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.194879Z","level":"info","event":"25/12/28 17:43:34 INFO SparkContext: Created broadcast 185 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.196188Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 169 (MapPartitionsRDD[457] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.196368Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSchedulerImpl: Adding task set 169.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.202414Z","level":"info","event":"25/12/28 17:43:34 INFO BlockManagerInfo: Removed broadcast_176_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.203297Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSetManager: Starting task 0.0 in stage 169.0 (TID 253) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.204545Z","level":"info","event":"25/12/28 17:43:34 INFO Executor: Running task 0.0 in stage 169.0 (TID 253)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.209243Z","level":"info","event":"25/12/28 17:43:34 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.209534Z","level":"info","event":"25/12/28 17:43:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.209604Z","level":"info","event":"25/12/28 17:43:34 INFO BlockManagerInfo: Removed broadcast_172_piece0 on c252dd92c865:35057 in memory (size: 9.1 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.214024Z","level":"info","event":"25/12/28 17:43:34 INFO BlockManagerInfo: Removed broadcast_173_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.218345Z","level":"info","event":"25/12/28 17:43:34 INFO Executor: Finished task 0.0 in stage 169.0 (TID 253). 3995 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.219212Z","level":"info","event":"25/12/28 17:43:34 INFO BlockManagerInfo: Removed broadcast_177_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.219570Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSetManager: Finished task 0.0 in stage 169.0 (TID 253) in 17 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.219743Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSchedulerImpl: Removed TaskSet 169.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.220215Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: ResultStage 169 (count at <unknown>:0) finished in 0.077 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.220447Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Job 115 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.220610Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 169: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.220759Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Job 115 finished: count at <unknown>:0, took 0.112564 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.223001Z","level":"info","event":"Loaded olist_sellers with 3095 records.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.223630Z","level":"info","event":"25/12/28 17:43:34 INFO BlockManagerInfo: Removed broadcast_175_piece0 on c252dd92c865:35057 in memory (size: 9.1 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.228877Z","level":"info","event":"25/12/28 17:43:34 INFO BlockManagerInfo: Removed broadcast_171_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.231104Z","level":"info","event":"25/12/28 17:43:34 INFO BlockManagerInfo: Removed broadcast_182_piece0 on c252dd92c865:35057 in memory (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.233819Z","level":"info","event":"25/12/28 17:43:34 INFO BlockManagerInfo: Removed broadcast_168_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.236407Z","level":"info","event":"25/12/28 17:43:34 INFO BlockManagerInfo: Removed broadcast_170_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.239953Z","level":"info","event":"25/12/28 17:43:34 INFO BlockManagerInfo: Removed broadcast_184_piece0 on c252dd92c865:35057 in memory (size: 8.8 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.247693Z","level":"info","event":"25/12/28 17:43:34 INFO BlockManagerInfo: Removed broadcast_180_piece0 on c252dd92c865:35057 in memory (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.251942Z","level":"info","event":"25/12/28 17:43:34 INFO BlockManagerInfo: Removed broadcast_178_piece0 on c252dd92c865:35057 in memory (size: 9.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.258700Z","level":"info","event":"25/12/28 17:43:34 INFO BlockManagerInfo: Removed broadcast_169_piece0 on c252dd92c865:35057 in memory (size: 9.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.262652Z","level":"info","event":"25/12/28 17:43:34 INFO BlockManagerInfo: Removed broadcast_179_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.265070Z","level":"info","event":"25/12/28 17:43:34 INFO BlockManagerInfo: Removed broadcast_174_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.271122Z","level":"info","event":"25/12/28 17:43:34 INFO BlockManagerInfo: Removed broadcast_181_piece0 on c252dd92c865:35057 in memory (size: 6.4 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.296680Z","level":"info","event":"25/12/28 17:43:34 INFO FileSourceStrategy: Pushed Filters: IsNull(seller_id)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.302576Z","level":"info","event":"25/12/28 17:43:34 INFO FileSourceStrategy: Post-Scan Filters: isnull(seller_id#910)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.351052Z","level":"info","event":"25/12/28 17:43:34 INFO MemoryStore: Block broadcast_186 stored as values in memory (estimated size 199.2 KiB, free 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.372663Z","level":"info","event":"25/12/28 17:43:34 INFO MemoryStore: Block broadcast_186_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.372820Z","level":"info","event":"25/12/28 17:43:34 INFO BlockManagerInfo: Added broadcast_186_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.372873Z","level":"info","event":"25/12/28 17:43:34 INFO SparkContext: Created broadcast 186 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.372926Z","level":"info","event":"25/12/28 17:43:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.381550Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Registering RDD 461 (count at <unknown>:0) as input to shuffle 54","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.382044Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Got map stage job 116 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.382249Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Final stage: ShuffleMapStage 170 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.382508Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.382572Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.384133Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Submitting ShuffleMapStage 170 (MapPartitionsRDD[461] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.386083Z","level":"info","event":"25/12/28 17:43:34 INFO MemoryStore: Block broadcast_187 stored as values in memory (estimated size 18.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.396724Z","level":"info","event":"25/12/28 17:43:34 INFO MemoryStore: Block broadcast_187_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.397705Z","level":"info","event":"25/12/28 17:43:34 INFO BlockManagerInfo: Added broadcast_187_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.399922Z","level":"info","event":"25/12/28 17:43:34 INFO SparkContext: Created broadcast 187 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.400635Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 170 (MapPartitionsRDD[461] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.400724Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSchedulerImpl: Adding task set 170.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.404906Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSetManager: Starting task 0.0 in stage 170.0 (TID 254) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8278 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.408661Z","level":"info","event":"25/12/28 17:43:34 INFO Executor: Running task 0.0 in stage 170.0 (TID 254)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.417836Z","level":"info","event":"25/12/28 17:43:34 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_sellers_dataset.csv, range: 0-174703, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.453118Z","level":"info","event":"25/12/28 17:43:34 INFO Executor: Finished task 0.0 in stage 170.0 (TID 254). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.460099Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSetManager: Finished task 0.0 in stage 170.0 (TID 254) in 56 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.460612Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSchedulerImpl: Removed TaskSet 170.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.461715Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: ShuffleMapStage 170 (count at <unknown>:0) finished in 0.077 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.461941Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.462048Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.462169Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.462330Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.513077Z","level":"info","event":"25/12/28 17:43:34 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.514608Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Got job 117 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.514866Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Final stage: ResultStage 172 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.514974Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 171)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.516441Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.518870Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Submitting ResultStage 172 (MapPartitionsRDD[464] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.530741Z","level":"info","event":"25/12/28 17:43:34 INFO MemoryStore: Block broadcast_188 stored as values in memory (estimated size 12.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.553688Z","level":"info","event":"25/12/28 17:43:34 INFO MemoryStore: Block broadcast_188_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.557995Z","level":"info","event":"25/12/28 17:43:34 INFO BlockManagerInfo: Added broadcast_188_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.558372Z","level":"info","event":"25/12/28 17:43:34 INFO SparkContext: Created broadcast 188 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.558570Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 172 (MapPartitionsRDD[464] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.558980Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSchedulerImpl: Adding task set 172.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.574722Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSetManager: Starting task 0.0 in stage 172.0 (TID 255) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.599763Z","level":"info","event":"25/12/28 17:43:34 INFO Executor: Running task 0.0 in stage 172.0 (TID 255)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.625190Z","level":"info","event":"25/12/28 17:43:34 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.627230Z","level":"info","event":"25/12/28 17:43:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.635957Z","level":"info","event":"25/12/28 17:43:34 INFO Executor: Finished task 0.0 in stage 172.0 (TID 255). 4031 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.644183Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSetManager: Finished task 0.0 in stage 172.0 (TID 255) in 72 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.644353Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSchedulerImpl: Removed TaskSet 172.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.653304Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: ResultStage 172 (count at <unknown>:0) finished in 0.128 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.657230Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Job 117 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.658693Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 172: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.660945Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Job 117 finished: count at <unknown>:0, took 0.141585 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.709777Z","level":"info","event":"25/12/28 17:43:34 INFO FileSourceStrategy: Pushed Filters: IsNull(seller_zip_code_prefix)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.710202Z","level":"info","event":"25/12/28 17:43:34 INFO FileSourceStrategy: Post-Scan Filters: isnull(seller_zip_code_prefix#911)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.729467Z","level":"info","event":"25/12/28 17:43:34 INFO MemoryStore: Block broadcast_189 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.741820Z","level":"info","event":"25/12/28 17:43:34 INFO MemoryStore: Block broadcast_189_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.742122Z","level":"info","event":"25/12/28 17:43:34 INFO BlockManagerInfo: Added broadcast_189_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.742867Z","level":"info","event":"25/12/28 17:43:34 INFO SparkContext: Created broadcast 189 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.744266Z","level":"info","event":"25/12/28 17:43:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.748950Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Registering RDD 468 (count at <unknown>:0) as input to shuffle 55","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.749184Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Got map stage job 118 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.749275Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Final stage: ShuffleMapStage 173 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.749359Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.749720Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.749871Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Submitting ShuffleMapStage 173 (MapPartitionsRDD[468] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.754236Z","level":"info","event":"25/12/28 17:43:34 INFO MemoryStore: Block broadcast_190 stored as values in memory (estimated size 18.5 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.758268Z","level":"info","event":"25/12/28 17:43:34 INFO MemoryStore: Block broadcast_190_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.758714Z","level":"info","event":"25/12/28 17:43:34 INFO BlockManagerInfo: Added broadcast_190_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.759327Z","level":"info","event":"25/12/28 17:43:34 INFO SparkContext: Created broadcast 190 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.760688Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 173 (MapPartitionsRDD[468] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.760944Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSchedulerImpl: Adding task set 173.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.762456Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSetManager: Starting task 0.0 in stage 173.0 (TID 256) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8278 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.764393Z","level":"info","event":"25/12/28 17:43:34 INFO Executor: Running task 0.0 in stage 173.0 (TID 256)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.776380Z","level":"info","event":"25/12/28 17:43:34 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_sellers_dataset.csv, range: 0-174703, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.823391Z","level":"info","event":"25/12/28 17:43:34 INFO Executor: Finished task 0.0 in stage 173.0 (TID 256). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.826946Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSetManager: Finished task 0.0 in stage 173.0 (TID 256) in 64 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.827245Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSchedulerImpl: Removed TaskSet 173.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.829079Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: ShuffleMapStage 173 (count at <unknown>:0) finished in 0.078 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.829219Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.829270Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.829316Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.829349Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.873042Z","level":"info","event":"25/12/28 17:43:34 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.874005Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Got job 119 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.874097Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Final stage: ResultStage 175 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.874133Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 174)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.874173Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.874449Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Submitting ResultStage 175 (MapPartitionsRDD[471] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.876655Z","level":"info","event":"25/12/28 17:43:34 INFO MemoryStore: Block broadcast_191 stored as values in memory (estimated size 12.5 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.879069Z","level":"info","event":"25/12/28 17:43:34 INFO MemoryStore: Block broadcast_191_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.879526Z","level":"info","event":"25/12/28 17:43:34 INFO BlockManagerInfo: Added broadcast_191_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.880214Z","level":"info","event":"25/12/28 17:43:34 INFO SparkContext: Created broadcast 191 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.880776Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 175 (MapPartitionsRDD[471] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.881943Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSchedulerImpl: Adding task set 175.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.885369Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSetManager: Starting task 0.0 in stage 175.0 (TID 257) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.886033Z","level":"info","event":"25/12/28 17:43:34 INFO Executor: Running task 0.0 in stage 175.0 (TID 257)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.888998Z","level":"info","event":"25/12/28 17:43:34 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.889140Z","level":"info","event":"25/12/28 17:43:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.891724Z","level":"info","event":"25/12/28 17:43:34 INFO Executor: Finished task 0.0 in stage 175.0 (TID 257). 3988 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.893607Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSetManager: Finished task 0.0 in stage 175.0 (TID 257) in 9 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.893717Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSchedulerImpl: Removed TaskSet 175.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.893901Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: ResultStage 175 (count at <unknown>:0) finished in 0.019 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.894088Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Job 119 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.894157Z","level":"info","event":"25/12/28 17:43:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 175: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.894260Z","level":"info","event":"25/12/28 17:43:34 INFO DAGScheduler: Job 119 finished: count at <unknown>:0, took 0.021146 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.977356Z","level":"info","event":"25/12/28 17:43:34 INFO FileSourceStrategy: Pushed Filters: IsNull(seller_city)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:34.978108Z","level":"info","event":"25/12/28 17:43:34 INFO FileSourceStrategy: Post-Scan Filters: isnull(seller_city#912)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.024535Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_192 stored as values in memory (estimated size 199.2 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.038625Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_192_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.038978Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Added broadcast_192_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.040923Z","level":"info","event":"25/12/28 17:43:35 INFO SparkContext: Created broadcast 192 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.065405Z","level":"info","event":"25/12/28 17:43:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.075936Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Registering RDD 475 (count at <unknown>:0) as input to shuffle 56","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.076376Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Got map stage job 120 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.076565Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Final stage: ShuffleMapStage 176 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.076663Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.076758Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.076908Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Submitting ShuffleMapStage 176 (MapPartitionsRDD[475] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.078600Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_193 stored as values in memory (estimated size 18.5 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.087158Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_193_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.087631Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Added broadcast_193_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.087985Z","level":"info","event":"25/12/28 17:43:35 INFO SparkContext: Created broadcast 193 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.088413Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 176 (MapPartitionsRDD[475] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.089235Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Adding task set 176.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.090409Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSetManager: Starting task 0.0 in stage 176.0 (TID 258) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8278 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.092673Z","level":"info","event":"25/12/28 17:43:35 INFO Executor: Running task 0.0 in stage 176.0 (TID 258)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.121801Z","level":"info","event":"25/12/28 17:43:35 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_sellers_dataset.csv, range: 0-174703, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.190647Z","level":"info","event":"25/12/28 17:43:35 INFO Executor: Finished task 0.0 in stage 176.0 (TID 258). 1984 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.196010Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSetManager: Finished task 0.0 in stage 176.0 (TID 258) in 106 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.196779Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Removed TaskSet 176.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.197456Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: ShuffleMapStage 176 (count at <unknown>:0) finished in 0.120 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.197789Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.198013Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.198164Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.198274Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.229750Z","level":"info","event":"25/12/28 17:43:35 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.229972Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Got job 121 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.230028Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Final stage: ResultStage 178 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.230063Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 177)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.230093Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.230135Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Submitting ResultStage 178 (MapPartitionsRDD[478] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.231361Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_194 stored as values in memory (estimated size 12.5 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.238534Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_194_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.239339Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Added broadcast_194_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.240572Z","level":"info","event":"25/12/28 17:43:35 INFO SparkContext: Created broadcast 194 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.241314Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 178 (MapPartitionsRDD[478] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.241546Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Adding task set 178.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.251250Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSetManager: Starting task 0.0 in stage 178.0 (TID 259) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.252655Z","level":"info","event":"25/12/28 17:43:35 INFO Executor: Running task 0.0 in stage 178.0 (TID 259)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.262314Z","level":"info","event":"25/12/28 17:43:35 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.262689Z","level":"info","event":"25/12/28 17:43:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.274558Z","level":"info","event":"25/12/28 17:43:35 INFO Executor: Finished task 0.0 in stage 178.0 (TID 259). 3988 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.275810Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSetManager: Finished task 0.0 in stage 178.0 (TID 259) in 25 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.275890Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Removed TaskSet 178.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.276206Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: ResultStage 178 (count at <unknown>:0) finished in 0.046 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.276458Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Job 121 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.276665Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 178: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.276779Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Job 121 finished: count at <unknown>:0, took 0.048116 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.330461Z","level":"info","event":"25/12/28 17:43:35 INFO FileSourceStrategy: Pushed Filters: IsNull(seller_state)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.331290Z","level":"info","event":"25/12/28 17:43:35 INFO FileSourceStrategy: Post-Scan Filters: isnull(seller_state#913)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.353407Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_195 stored as values in memory (estimated size 199.2 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.362745Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_195_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.363314Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Added broadcast_195_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.363774Z","level":"info","event":"25/12/28 17:43:35 INFO SparkContext: Created broadcast 195 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.365133Z","level":"info","event":"25/12/28 17:43:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.369390Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Registering RDD 482 (count at <unknown>:0) as input to shuffle 57","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.369702Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Got map stage job 122 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.369788Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Final stage: ShuffleMapStage 179 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.369917Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.370010Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.370066Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Submitting ShuffleMapStage 179 (MapPartitionsRDD[482] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.370997Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_196 stored as values in memory (estimated size 18.5 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.372366Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_196_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.372951Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Added broadcast_196_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.373343Z","level":"info","event":"25/12/28 17:43:35 INFO SparkContext: Created broadcast 196 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.373666Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 179 (MapPartitionsRDD[482] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.373733Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Adding task set 179.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.375139Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSetManager: Starting task 0.0 in stage 179.0 (TID 260) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8278 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.375939Z","level":"info","event":"25/12/28 17:43:35 INFO Executor: Running task 0.0 in stage 179.0 (TID 260)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.379559Z","level":"info","event":"25/12/28 17:43:35 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_sellers_dataset.csv, range: 0-174703, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.393433Z","level":"info","event":"25/12/28 17:43:35 INFO Executor: Finished task 0.0 in stage 179.0 (TID 260). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.394624Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSetManager: Finished task 0.0 in stage 179.0 (TID 260) in 20 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.394878Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Removed TaskSet 179.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.395204Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: ShuffleMapStage 179 (count at <unknown>:0) finished in 0.024 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.395261Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.395297Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.395331Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.395354Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.409861Z","level":"info","event":"25/12/28 17:43:35 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.410482Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Got job 123 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.410578Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Final stage: ResultStage 181 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.410628Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 180)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.410670Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.410834Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Submitting ResultStage 181 (MapPartitionsRDD[485] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.411933Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_197 stored as values in memory (estimated size 12.5 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.415783Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_197_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.417074Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Added broadcast_197_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.420113Z","level":"info","event":"25/12/28 17:43:35 INFO SparkContext: Created broadcast 197 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.420393Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 181 (MapPartitionsRDD[485] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.420459Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Adding task set 181.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.423089Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSetManager: Starting task 0.0 in stage 181.0 (TID 261) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.423762Z","level":"info","event":"25/12/28 17:43:35 INFO Executor: Running task 0.0 in stage 181.0 (TID 261)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.426854Z","level":"info","event":"25/12/28 17:43:35 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.427121Z","level":"info","event":"25/12/28 17:43:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.428591Z","level":"info","event":"25/12/28 17:43:35 INFO Executor: Finished task 0.0 in stage 181.0 (TID 261). 3988 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.429354Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSetManager: Finished task 0.0 in stage 181.0 (TID 261) in 8 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.429447Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Removed TaskSet 181.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.429641Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: ResultStage 181 (count at <unknown>:0) finished in 0.018 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.429769Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Job 123 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.429999Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 181: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.430263Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Job 123 finished: count at <unknown>:0, took 0.020375 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.445101Z","level":"info","event":"25/12/28 17:43:35 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.451716Z","level":"info","event":"25/12/28 17:43:35 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.506964Z","level":"info","event":"25/12/28 17:43:35 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.507242Z","level":"info","event":"25/12/28 17:43:35 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#968, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.512065Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_198 stored as values in memory (estimated size 199.3 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.519619Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_198_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 432.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.520619Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Added broadcast_198_piece0 in memory on c252dd92c865:35057 (size: 34.2 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.521283Z","level":"info","event":"25/12/28 17:43:35 INFO SparkContext: Created broadcast 198 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.521847Z","level":"info","event":"25/12/28 17:43:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.526697Z","level":"info","event":"25/12/28 17:43:35 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.527232Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Got job 124 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.527275Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Final stage: ResultStage 182 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.527307Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.527336Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.527591Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Submitting ResultStage 182 (MapPartitionsRDD[489] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.528450Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_199 stored as values in memory (estimated size 13.5 KiB, free 432.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.529732Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_199_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 432.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.529986Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Added broadcast_199_piece0 in memory on c252dd92c865:35057 (size: 6.4 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.530329Z","level":"info","event":"25/12/28 17:43:35 INFO SparkContext: Created broadcast 199 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.530539Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 182 (MapPartitionsRDD[489] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.530572Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Adding task set 182.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.531758Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSetManager: Starting task 0.0 in stage 182.0 (TID 262) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8301 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.532379Z","level":"info","event":"25/12/28 17:43:35 INFO Executor: Running task 0.0 in stage 182.0 (TID 262)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.535103Z","level":"info","event":"25/12/28 17:43:35 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/product_category_name_translation.csv, range: 0-2613, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.537096Z","level":"info","event":"25/12/28 17:43:35 INFO LineRecordReader: Found UTF-8 BOM and skipped it","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.538479Z","level":"info","event":"25/12/28 17:43:35 INFO Executor: Finished task 0.0 in stage 182.0 (TID 262). 1609 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.538958Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSetManager: Finished task 0.0 in stage 182.0 (TID 262) in 7 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.538997Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Removed TaskSet 182.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.539769Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: ResultStage 182 (csv at NativeMethodAccessorImpl.java:0) finished in 0.012 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.540101Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Job 124 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.540317Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 182: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.540549Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Job 124 finished: csv at NativeMethodAccessorImpl.java:0, took 0.013709 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.545191Z","level":"info","event":"25/12/28 17:43:35 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.545304Z","level":"info","event":"25/12/28 17:43:35 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.546598Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_200 stored as values in memory (estimated size 199.3 KiB, free 432.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.554523Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_200_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 432.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.554776Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Added broadcast_200_piece0 in memory on c252dd92c865:35057 (size: 34.2 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.555329Z","level":"info","event":"25/12/28 17:43:35 INFO SparkContext: Created broadcast 200 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.555888Z","level":"info","event":"25/12/28 17:43:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.562551Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.568479Z","level":"info","event":"25/12/28 17:43:35 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.568596Z","level":"info","event":"25/12/28 17:43:35 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.574090Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_201 stored as values in memory (estimated size 199.2 KiB, free 432.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.580806Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_201_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 432.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.581202Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Added broadcast_201_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.581640Z","level":"info","event":"25/12/28 17:43:35 INFO SparkContext: Created broadcast 201 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.583372Z","level":"info","event":"25/12/28 17:43:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.589149Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Registering RDD 499 (count at <unknown>:0) as input to shuffle 58","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.589272Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Got map stage job 125 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.589305Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Final stage: ShuffleMapStage 183 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.589328Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.589355Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.589533Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Submitting ShuffleMapStage 183 (MapPartitionsRDD[499] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.595656Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_202 stored as values in memory (estimated size 17.7 KiB, free 432.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.624801Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Removed broadcast_197_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.625116Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_202_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 432.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.625241Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Added broadcast_202_piece0 in memory on c252dd92c865:35057 (size: 8.7 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.626453Z","level":"info","event":"25/12/28 17:43:35 INFO SparkContext: Created broadcast 202 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.626550Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 183 (MapPartitionsRDD[499] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.626584Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Adding task set 183.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.629229Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSetManager: Starting task 0.0 in stage 183.0 (TID 263) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8290 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.629810Z","level":"info","event":"25/12/28 17:43:35 INFO Executor: Running task 0.0 in stage 183.0 (TID 263)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.632918Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Removed broadcast_187_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.634291Z","level":"info","event":"25/12/28 17:43:35 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/product_category_name_translation.csv, range: 0-2613, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.634686Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Removed broadcast_185_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.635930Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Removed broadcast_199_piece0 on c252dd92c865:35057 in memory (size: 6.4 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.638665Z","level":"info","event":"25/12/28 17:43:35 INFO LineRecordReader: Found UTF-8 BOM and skipped it","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.642851Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Removed broadcast_188_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.643045Z","level":"info","event":"25/12/28 17:43:35 INFO Executor: Finished task 0.0 in stage 183.0 (TID 263). 1928 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.643481Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSetManager: Finished task 0.0 in stage 183.0 (TID 263) in 15 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.643524Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Removed TaskSet 183.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.644011Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: ShuffleMapStage 183 (count at <unknown>:0) finished in 0.054 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.644228Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.644323Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.644445Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.644524Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.644765Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Removed broadcast_195_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.646520Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Removed broadcast_193_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.648763Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Removed broadcast_191_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.651688Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Removed broadcast_198_piece0 on c252dd92c865:35057 in memory (size: 34.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.655740Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Removed broadcast_186_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.657858Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Removed broadcast_183_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.659379Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Removed broadcast_190_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.660045Z","level":"info","event":"25/12/28 17:43:35 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.660812Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Got job 126 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.660880Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Final stage: ResultStage 185 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.660927Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 184)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.660955Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.660983Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Submitting ResultStage 185 (MapPartitionsRDD[502] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.661208Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Removed broadcast_196_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.662476Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_203 stored as values in memory (estimated size 12.5 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.665287Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Removed broadcast_194_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.671188Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Removed broadcast_189_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.671389Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_203_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.672632Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Added broadcast_203_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.673473Z","level":"info","event":"25/12/28 17:43:35 INFO SparkContext: Created broadcast 203 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.675234Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 185 (MapPartitionsRDD[502] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.675332Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Adding task set 185.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.676825Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSetManager: Starting task 0.0 in stage 185.0 (TID 264) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.677561Z","level":"info","event":"25/12/28 17:43:35 INFO Executor: Running task 0.0 in stage 185.0 (TID 264)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.679089Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Removed broadcast_192_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.682706Z","level":"info","event":"25/12/28 17:43:35 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.682823Z","level":"info","event":"25/12/28 17:43:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.684642Z","level":"info","event":"25/12/28 17:43:35 INFO Executor: Finished task 0.0 in stage 185.0 (TID 264). 3995 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.686266Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Removed broadcast_200_piece0 on c252dd92c865:35057 in memory (size: 34.2 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.688317Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSetManager: Finished task 0.0 in stage 185.0 (TID 264) in 13 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.692289Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Removed TaskSet 185.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.692406Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: ResultStage 185 (count at <unknown>:0) finished in 0.029 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.692463Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Job 126 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.692495Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 185: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.692534Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Job 126 finished: count at <unknown>:0, took 0.032098 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.695109Z","level":"info","event":"Loaded product_category_name_translation with 71 records.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.731126Z","level":"info","event":"25/12/28 17:43:35 INFO FileSourceStrategy: Pushed Filters: IsNull(product_category_name)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.731667Z","level":"info","event":"25/12/28 17:43:35 INFO FileSourceStrategy: Post-Scan Filters: isnull(product_category_name#985)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.745649Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_204 stored as values in memory (estimated size 199.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.755161Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_204_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.755415Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Added broadcast_204_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.760534Z","level":"info","event":"25/12/28 17:43:35 INFO SparkContext: Created broadcast 204 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.761530Z","level":"info","event":"25/12/28 17:43:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.766850Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Registering RDD 506 (count at <unknown>:0) as input to shuffle 59","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.767161Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Got map stage job 127 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.767216Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Final stage: ShuffleMapStage 186 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.767255Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.767288Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.767925Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Submitting ShuffleMapStage 186 (MapPartitionsRDD[506] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.772549Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_205 stored as values in memory (estimated size 18.3 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.772661Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_205_piece0 stored as bytes in memory (estimated size 8.9 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.772693Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Added broadcast_205_piece0 in memory on c252dd92c865:35057 (size: 8.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.772712Z","level":"info","event":"25/12/28 17:43:35 INFO SparkContext: Created broadcast 205 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.772740Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 186 (MapPartitionsRDD[506] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.772756Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Adding task set 186.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.772808Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSetManager: Starting task 0.0 in stage 186.0 (TID 265) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8290 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.776069Z","level":"info","event":"25/12/28 17:43:35 INFO Executor: Running task 0.0 in stage 186.0 (TID 265)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.784178Z","level":"info","event":"25/12/28 17:43:35 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/product_category_name_translation.csv, range: 0-2613, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.790638Z","level":"info","event":"25/12/28 17:43:35 INFO LineRecordReader: Found UTF-8 BOM and skipped it","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.795581Z","level":"info","event":"25/12/28 17:43:35 INFO Executor: Finished task 0.0 in stage 186.0 (TID 265). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.796486Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSetManager: Finished task 0.0 in stage 186.0 (TID 265) in 24 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.797227Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Removed TaskSet 186.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.798431Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: ShuffleMapStage 186 (count at <unknown>:0) finished in 0.031 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.800724Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.800834Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.800888Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.800925Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.822833Z","level":"info","event":"25/12/28 17:43:35 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.823825Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Got job 128 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.823898Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Final stage: ResultStage 188 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.824006Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 187)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.824065Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.824103Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Submitting ResultStage 188 (MapPartitionsRDD[509] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.825708Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_206 stored as values in memory (estimated size 12.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.830489Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_206_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.831136Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Added broadcast_206_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.831665Z","level":"info","event":"25/12/28 17:43:35 INFO SparkContext: Created broadcast 206 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.832150Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 188 (MapPartitionsRDD[509] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.832404Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Adding task set 188.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.834742Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSetManager: Starting task 0.0 in stage 188.0 (TID 266) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.835277Z","level":"info","event":"25/12/28 17:43:35 INFO Executor: Running task 0.0 in stage 188.0 (TID 266)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.839232Z","level":"info","event":"25/12/28 17:43:35 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.839454Z","level":"info","event":"25/12/28 17:43:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.843893Z","level":"info","event":"25/12/28 17:43:35 INFO Executor: Finished task 0.0 in stage 188.0 (TID 266). 4031 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.846770Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSetManager: Finished task 0.0 in stage 188.0 (TID 266) in 12 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.846909Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Removed TaskSet 188.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.847340Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: ResultStage 188 (count at <unknown>:0) finished in 0.023 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.847910Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Job 128 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.847984Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 188: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.848159Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Job 128 finished: count at <unknown>:0, took 0.025282 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.877382Z","level":"info","event":"25/12/28 17:43:35 INFO FileSourceStrategy: Pushed Filters: IsNull(product_category_name_english)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.877566Z","level":"info","event":"25/12/28 17:43:35 INFO FileSourceStrategy: Post-Scan Filters: isnull(product_category_name_english#986)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.887286Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_207 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.901495Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_207_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.901833Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Added broadcast_207_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.902642Z","level":"info","event":"25/12/28 17:43:35 INFO SparkContext: Created broadcast 207 from count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.903536Z","level":"info","event":"25/12/28 17:43:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.908835Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Registering RDD 513 (count at <unknown>:0) as input to shuffle 60","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.908960Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Got map stage job 129 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.908992Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Final stage: ShuffleMapStage 189 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.909010Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.909049Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.909273Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Submitting ShuffleMapStage 189 (MapPartitionsRDD[513] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.910147Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_208 stored as values in memory (estimated size 18.3 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.912161Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_208_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.912351Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Added broadcast_208_piece0 in memory on c252dd92c865:35057 (size: 9.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.912831Z","level":"info","event":"25/12/28 17:43:35 INFO SparkContext: Created broadcast 208 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.913069Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 189 (MapPartitionsRDD[513] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.913103Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Adding task set 189.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.913918Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSetManager: Starting task 0.0 in stage 189.0 (TID 267) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8290 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.914501Z","level":"info","event":"25/12/28 17:43:35 INFO Executor: Running task 0.0 in stage 189.0 (TID 267)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.917616Z","level":"info","event":"25/12/28 17:43:35 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/product_category_name_translation.csv, range: 0-2613, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.921268Z","level":"info","event":"25/12/28 17:43:35 INFO LineRecordReader: Found UTF-8 BOM and skipped it","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.925530Z","level":"info","event":"25/12/28 17:43:35 INFO Executor: Finished task 0.0 in stage 189.0 (TID 267). 1941 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.926479Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSetManager: Finished task 0.0 in stage 189.0 (TID 267) in 13 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.926545Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Removed TaskSet 189.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.927058Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: ShuffleMapStage 189 (count at <unknown>:0) finished in 0.017 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.927111Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.927135Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.927152Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.927187Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.938777Z","level":"info","event":"25/12/28 17:43:35 INFO SparkContext: Starting job: count at <unknown>:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.939399Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Got job 130 (count at <unknown>:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.939474Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Final stage: ResultStage 191 (count at <unknown>:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.939498Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 190)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.939522Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.939540Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Submitting ResultStage 191 (MapPartitionsRDD[516] at count at <unknown>:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.940448Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_209 stored as values in memory (estimated size 12.5 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.942505Z","level":"info","event":"25/12/28 17:43:35 INFO MemoryStore: Block broadcast_209_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.942833Z","level":"info","event":"25/12/28 17:43:35 INFO BlockManagerInfo: Added broadcast_209_piece0 in memory on c252dd92c865:35057 (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.943218Z","level":"info","event":"25/12/28 17:43:35 INFO SparkContext: Created broadcast 209 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.943579Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 191 (MapPartitionsRDD[516] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.943842Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Adding task set 191.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.944920Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSetManager: Starting task 0.0 in stage 191.0 (TID 268) (c252dd92c865, executor driver, partition 0, NODE_LOCAL, 7615 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.945710Z","level":"info","event":"25/12/28 17:43:35 INFO Executor: Running task 0.0 in stage 191.0 (TID 268)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.949064Z","level":"info","event":"25/12/28 17:43:35 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.949234Z","level":"info","event":"25/12/28 17:43:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.952837Z","level":"info","event":"25/12/28 17:43:35 INFO Executor: Finished task 0.0 in stage 191.0 (TID 268). 3988 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.953431Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSetManager: Finished task 0.0 in stage 191.0 (TID 268) in 9 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.953490Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Removed TaskSet 191.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.953735Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: ResultStage 191 (count at <unknown>:0) finished in 0.014 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.953814Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Job 130 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.953841Z","level":"info","event":"25/12/28 17:43:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 191: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.954085Z","level":"info","event":"25/12/28 17:43:35 INFO DAGScheduler: Job 130 finished: count at <unknown>:0, took 0.015247 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.954787Z","level":"info","event":"____________________________________________________","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:35.954835Z","level":"info","event":"Total null values found across datasets: 184758","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.063075Z","level":"info","event":"25/12/28 17:43:36 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.063270Z","level":"info","event":"25/12/28 17:43:36 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.101919Z","level":"info","event":"25/12/28 17:43:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.102021Z","level":"info","event":"25/12/28 17:43:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.102469Z","level":"info","event":"25/12/28 17:43:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.154869Z","level":"info","event":"25/12/28 17:43:36 INFO MemoryStore: Block broadcast_210 stored as values in memory (estimated size 199.2 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.165373Z","level":"info","event":"25/12/28 17:43:36 INFO MemoryStore: Block broadcast_210_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.165572Z","level":"info","event":"25/12/28 17:43:36 INFO BlockManagerInfo: Added broadcast_210_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.166197Z","level":"info","event":"25/12/28 17:43:36 INFO SparkContext: Created broadcast 210 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.166947Z","level":"info","event":"25/12/28 17:43:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.177248Z","level":"info","event":"25/12/28 17:43:36 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.179653Z","level":"info","event":"25/12/28 17:43:36 INFO DAGScheduler: Got job 131 (csv at NativeMethodAccessorImpl.java:0) with 3 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.179742Z","level":"info","event":"25/12/28 17:43:36 INFO DAGScheduler: Final stage: ResultStage 192 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.179774Z","level":"info","event":"25/12/28 17:43:36 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.179806Z","level":"info","event":"25/12/28 17:43:36 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.180054Z","level":"info","event":"25/12/28 17:43:36 INFO DAGScheduler: Submitting ResultStage 192 (MapPartitionsRDD[519] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.195107Z","level":"info","event":"25/12/28 17:43:36 INFO MemoryStore: Block broadcast_211 stored as values in memory (estimated size 211.8 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.196705Z","level":"info","event":"25/12/28 17:43:36 INFO MemoryStore: Block broadcast_211_piece0 stored as bytes in memory (estimated size 76.6 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.196895Z","level":"info","event":"25/12/28 17:43:36 INFO BlockManagerInfo: Added broadcast_211_piece0 in memory on c252dd92c865:35057 (size: 76.6 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.197210Z","level":"info","event":"25/12/28 17:43:36 INFO SparkContext: Created broadcast 211 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.197402Z","level":"info","event":"25/12/28 17:43:36 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 192 (MapPartitionsRDD[519] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.197471Z","level":"info","event":"25/12/28 17:43:36 INFO TaskSchedulerImpl: Adding task set 192.0 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.198868Z","level":"info","event":"25/12/28 17:43:36 INFO TaskSetManager: Starting task 0.0 in stage 192.0 (TID 269) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8291 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.198990Z","level":"info","event":"25/12/28 17:43:36 INFO TaskSetManager: Starting task 1.0 in stage 192.0 (TID 270) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8291 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.199251Z","level":"info","event":"25/12/28 17:43:36 INFO TaskSetManager: Starting task 2.0 in stage 192.0 (TID 271) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8291 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.199727Z","level":"info","event":"25/12/28 17:43:36 INFO Executor: Running task 0.0 in stage 192.0 (TID 269)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.199762Z","level":"info","event":"25/12/28 17:43:36 INFO Executor: Running task 1.0 in stage 192.0 (TID 270)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.200266Z","level":"info","event":"25/12/28 17:43:36 INFO Executor: Running task 2.0 in stage 192.0 (TID 271)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.253602Z","level":"info","event":"25/12/28 17:43:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.253703Z","level":"info","event":"25/12/28 17:43:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.253734Z","level":"info","event":"25/12/28 17:43:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.253751Z","level":"info","event":"25/12/28 17:43:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.253777Z","level":"info","event":"25/12/28 17:43:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.253794Z","level":"info","event":"25/12/28 17:43:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.253815Z","level":"info","event":"25/12/28 17:43:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.253845Z","level":"info","event":"25/12/28 17:43:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.254010Z","level":"info","event":"25/12/28 17:43:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.254198Z","level":"info","event":"25/12/28 17:43:36 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.254303Z","level":"info","event":"25/12/28 17:43:36 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 8388608-9033957, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.278501Z","level":"info","event":"25/12/28 17:43:36 INFO CodeGenerator: Code generated in 21.731458 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.355548Z","level":"info","event":"25/12/28 17:43:36 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_customers_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.551710Z","level":"info","event":"25/12/28 17:43:36 INFO FileOutputCommitter: Saved output of task 'attempt_202512281743367712108143082081785_0192_m_000002_271' to file:/opt/airflow/data/raw/olist_customers/_temporary/0/task_202512281743367712108143082081785_0192_m_000002","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.552468Z","level":"info","event":"25/12/28 17:43:36 INFO SparkHadoopMapRedUtil: attempt_202512281743367712108143082081785_0192_m_000002_271: Committed. Elapsed time: 5 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.580045Z","level":"info","event":"25/12/28 17:43:36 INFO Executor: Finished task 2.0 in stage 192.0 (TID 271). 2502 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.587673Z","level":"info","event":"25/12/28 17:43:36 INFO TaskSetManager: Finished task 2.0 in stage 192.0 (TID 271) in 388 ms on c252dd92c865 (executor driver) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.871109Z","level":"info","event":"25/12/28 17:43:36 INFO FileOutputCommitter: Saved output of task 'attempt_202512281743367712108143082081785_0192_m_000000_269' to file:/opt/airflow/data/raw/olist_customers/_temporary/0/task_202512281743367712108143082081785_0192_m_000000","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.872231Z","level":"info","event":"25/12/28 17:43:36 INFO SparkHadoopMapRedUtil: attempt_202512281743367712108143082081785_0192_m_000000_269: Committed. Elapsed time: 8 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.889877Z","level":"info","event":"25/12/28 17:43:36 INFO Executor: Finished task 0.0 in stage 192.0 (TID 269). 2502 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:36.993636Z","level":"info","event":"25/12/28 17:43:36 INFO TaskSetManager: Finished task 0.0 in stage 192.0 (TID 269) in 793 ms on c252dd92c865 (executor driver) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.003368Z","level":"info","event":"25/12/28 17:43:37 INFO BlockManagerInfo: Removed broadcast_203_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.006271Z","level":"info","event":"25/12/28 17:43:37 INFO BlockManagerInfo: Removed broadcast_202_piece0 on c252dd92c865:35057 in memory (size: 8.7 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.014234Z","level":"info","event":"25/12/28 17:43:37 INFO BlockManagerInfo: Removed broadcast_207_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.023595Z","level":"info","event":"25/12/28 17:43:37 INFO BlockManagerInfo: Removed broadcast_206_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.027123Z","level":"info","event":"25/12/28 17:43:37 INFO BlockManagerInfo: Removed broadcast_205_piece0 on c252dd92c865:35057 in memory (size: 8.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.029136Z","level":"info","event":"25/12/28 17:43:37 INFO BlockManagerInfo: Removed broadcast_208_piece0 on c252dd92c865:35057 in memory (size: 9.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.032977Z","level":"info","event":"25/12/28 17:43:37 INFO BlockManagerInfo: Removed broadcast_204_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.034597Z","level":"info","event":"25/12/28 17:43:37 INFO BlockManagerInfo: Removed broadcast_209_piece0 on c252dd92c865:35057 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.035931Z","level":"info","event":"25/12/28 17:43:37 INFO BlockManagerInfo: Removed broadcast_201_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.042400Z","level":"info","event":"25/12/28 17:43:37 INFO FileOutputCommitter: Saved output of task 'attempt_202512281743367712108143082081785_0192_m_000001_270' to file:/opt/airflow/data/raw/olist_customers/_temporary/0/task_202512281743367712108143082081785_0192_m_000001","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.042571Z","level":"info","event":"25/12/28 17:43:37 INFO SparkHadoopMapRedUtil: attempt_202512281743367712108143082081785_0192_m_000001_270: Committed. Elapsed time: 0 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.044672Z","level":"info","event":"25/12/28 17:43:37 INFO Executor: Finished task 1.0 in stage 192.0 (TID 270). 2502 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.047791Z","level":"info","event":"25/12/28 17:43:37 INFO TaskSetManager: Finished task 1.0 in stage 192.0 (TID 270) in 848 ms on c252dd92c865 (executor driver) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.050890Z","level":"info","event":"25/12/28 17:43:37 INFO TaskSchedulerImpl: Removed TaskSet 192.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.051186Z","level":"info","event":"25/12/28 17:43:37 INFO DAGScheduler: ResultStage 192 (csv at NativeMethodAccessorImpl.java:0) finished in 0.867 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.059275Z","level":"info","event":"25/12/28 17:43:37 INFO DAGScheduler: Job 131 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.059729Z","level":"info","event":"25/12/28 17:43:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 192: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.060681Z","level":"info","event":"25/12/28 17:43:37 INFO DAGScheduler: Job 131 finished: csv at NativeMethodAccessorImpl.java:0, took 0.882987 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.079019Z","level":"info","event":"25/12/28 17:43:37 INFO FileFormatWriter: Start to commit write Job 40b4bc4d-1f2f-4222-8f49-ac34438be4fb.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.228578Z","level":"info","event":"25/12/28 17:43:37 INFO FileFormatWriter: Write Job 40b4bc4d-1f2f-4222-8f49-ac34438be4fb committed. Elapsed time: 146 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.244296Z","level":"info","event":"25/12/28 17:43:37 INFO FileFormatWriter: Finished processing stats for write job 40b4bc4d-1f2f-4222-8f49-ac34438be4fb.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.290184Z","level":"info","event":"Saved cleaned olist_customers to data/raw/olist_customers","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.354316Z","level":"info","event":"25/12/28 17:43:37 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.354875Z","level":"info","event":"25/12/28 17:43:37 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.382449Z","level":"info","event":"25/12/28 17:43:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.382699Z","level":"info","event":"25/12/28 17:43:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.383283Z","level":"info","event":"25/12/28 17:43:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.438566Z","level":"info","event":"25/12/28 17:43:37 INFO MemoryStore: Block broadcast_212 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.458056Z","level":"info","event":"25/12/28 17:43:37 INFO MemoryStore: Block broadcast_212_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.458750Z","level":"info","event":"25/12/28 17:43:37 INFO BlockManagerInfo: Added broadcast_212_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.459797Z","level":"info","event":"25/12/28 17:43:37 INFO SparkContext: Created broadcast 212 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.461622Z","level":"info","event":"25/12/28 17:43:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 9352598 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.469210Z","level":"info","event":"25/12/28 17:43:37 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.473082Z","level":"info","event":"25/12/28 17:43:37 INFO DAGScheduler: Got job 132 (csv at NativeMethodAccessorImpl.java:0) with 7 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.473226Z","level":"info","event":"25/12/28 17:43:37 INFO DAGScheduler: Final stage: ResultStage 193 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.473269Z","level":"info","event":"25/12/28 17:43:37 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.473302Z","level":"info","event":"25/12/28 17:43:37 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.473654Z","level":"info","event":"25/12/28 17:43:37 INFO DAGScheduler: Submitting ResultStage 193 (MapPartitionsRDD[522] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.557742Z","level":"info","event":"25/12/28 17:43:37 INFO MemoryStore: Block broadcast_213 stored as values in memory (estimated size 211.8 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.565751Z","level":"info","event":"25/12/28 17:43:37 INFO MemoryStore: Block broadcast_213_piece0 stored as bytes in memory (estimated size 76.6 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.567106Z","level":"info","event":"25/12/28 17:43:37 INFO BlockManagerInfo: Added broadcast_213_piece0 in memory on c252dd92c865:35057 (size: 76.6 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.568517Z","level":"info","event":"25/12/28 17:43:37 INFO SparkContext: Created broadcast 213 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.569748Z","level":"info","event":"25/12/28 17:43:37 INFO DAGScheduler: Submitting 7 missing tasks from ResultStage 193 (MapPartitionsRDD[522] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.570041Z","level":"info","event":"25/12/28 17:43:37 INFO TaskSchedulerImpl: Adding task set 193.0 with 7 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.582512Z","level":"info","event":"25/12/28 17:43:37 INFO TaskSetManager: Starting task 0.0 in stage 193.0 (TID 272) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8293 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.586007Z","level":"info","event":"25/12/28 17:43:37 INFO TaskSetManager: Starting task 1.0 in stage 193.0 (TID 273) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8293 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.587105Z","level":"info","event":"25/12/28 17:43:37 INFO TaskSetManager: Starting task 2.0 in stage 193.0 (TID 274) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8293 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.588827Z","level":"info","event":"25/12/28 17:43:37 INFO TaskSetManager: Starting task 3.0 in stage 193.0 (TID 275) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8293 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.590122Z","level":"info","event":"25/12/28 17:43:37 INFO TaskSetManager: Starting task 4.0 in stage 193.0 (TID 276) (c252dd92c865, executor driver, partition 4, PROCESS_LOCAL, 8293 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.590511Z","level":"info","event":"25/12/28 17:43:37 INFO TaskSetManager: Starting task 5.0 in stage 193.0 (TID 277) (c252dd92c865, executor driver, partition 5, PROCESS_LOCAL, 8293 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.591023Z","level":"info","event":"25/12/28 17:43:37 INFO TaskSetManager: Starting task 6.0 in stage 193.0 (TID 278) (c252dd92c865, executor driver, partition 6, PROCESS_LOCAL, 8293 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.592727Z","level":"info","event":"25/12/28 17:43:37 INFO Executor: Running task 0.0 in stage 193.0 (TID 272)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.594209Z","level":"info","event":"25/12/28 17:43:37 INFO Executor: Running task 3.0 in stage 193.0 (TID 275)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.600605Z","level":"info","event":"25/12/28 17:43:37 INFO Executor: Running task 4.0 in stage 193.0 (TID 276)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.600903Z","level":"info","event":"25/12/28 17:43:37 INFO Executor: Running task 1.0 in stage 193.0 (TID 273)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.602275Z","level":"info","event":"25/12/28 17:43:37 INFO Executor: Running task 2.0 in stage 193.0 (TID 274)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.603302Z","level":"info","event":"25/12/28 17:43:37 INFO Executor: Running task 6.0 in stage 193.0 (TID 278)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.614771Z","level":"info","event":"25/12/28 17:43:37 INFO Executor: Running task 5.0 in stage 193.0 (TID 277)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.687627Z","level":"info","event":"25/12/28 17:43:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.689289Z","level":"info","event":"25/12/28 17:43:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.689469Z","level":"info","event":"25/12/28 17:43:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.691784Z","level":"info","event":"25/12/28 17:43:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.692491Z","level":"info","event":"25/12/28 17:43:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.692857Z","level":"info","event":"25/12/28 17:43:37 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 56115588-61273883, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.694222Z","level":"info","event":"25/12/28 17:43:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.726525Z","level":"info","event":"25/12/28 17:43:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.731715Z","level":"info","event":"25/12/28 17:43:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.733075Z","level":"info","event":"25/12/28 17:43:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.733311Z","level":"info","event":"25/12/28 17:43:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.733556Z","level":"info","event":"25/12/28 17:43:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.733666Z","level":"info","event":"25/12/28 17:43:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.733815Z","level":"info","event":"25/12/28 17:43:37 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 28057794-37410392, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.743025Z","level":"info","event":"25/12/28 17:43:37 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 37410392-46762990, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.749336Z","level":"info","event":"25/12/28 17:43:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.749980Z","level":"info","event":"25/12/28 17:43:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.750058Z","level":"info","event":"25/12/28 17:43:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.750339Z","level":"info","event":"25/12/28 17:43:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.750517Z","level":"info","event":"25/12/28 17:43:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.750634Z","level":"info","event":"25/12/28 17:43:37 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 46762990-56115588, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.754118Z","level":"info","event":"25/12/28 17:43:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.754332Z","level":"info","event":"25/12/28 17:43:37 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 9352598-18705196, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.755155Z","level":"info","event":"25/12/28 17:43:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.755347Z","level":"info","event":"25/12/28 17:43:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.755897Z","level":"info","event":"25/12/28 17:43:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.756043Z","level":"info","event":"25/12/28 17:43:37 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 18705196-28057794, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:37.850788Z","level":"info","event":"25/12/28 17:43:37 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_geolocation_dataset.csv, range: 0-9352598, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:38.175392Z","level":"info","event":"25/12/28 17:43:38 INFO BlockManagerInfo: Removed broadcast_211_piece0 on c252dd92c865:35057 in memory (size: 76.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:38.191794Z","level":"info","event":"25/12/28 17:43:38 INFO BlockManagerInfo: Removed broadcast_210_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:39.004038Z","level":"info","event":"25/12/28 17:43:38 INFO FileOutputCommitter: Saved output of task 'attempt_20251228174337809004170536184871_0193_m_000006_278' to file:/opt/airflow/data/raw/olist_geolocation/_temporary/0/task_20251228174337809004170536184871_0193_m_000006","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:39.007967Z","level":"info","event":"25/12/28 17:43:39 INFO SparkHadoopMapRedUtil: attempt_20251228174337809004170536184871_0193_m_000006_278: Committed. Elapsed time: 11 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:39.021707Z","level":"info","event":"25/12/28 17:43:39 INFO Executor: Finished task 6.0 in stage 193.0 (TID 278). 2545 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:39.049605Z","level":"info","event":"25/12/28 17:43:39 INFO TaskSetManager: Finished task 6.0 in stage 193.0 (TID 278) in 1457 ms on c252dd92c865 (executor driver) (1/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:40.279819Z","level":"info","event":"25/12/28 17:43:40 INFO FileOutputCommitter: Saved output of task 'attempt_20251228174337809004170536184871_0193_m_000003_275' to file:/opt/airflow/data/raw/olist_geolocation/_temporary/0/task_20251228174337809004170536184871_0193_m_000003","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:40.296359Z","level":"info","event":"25/12/28 17:43:40 INFO SparkHadoopMapRedUtil: attempt_20251228174337809004170536184871_0193_m_000003_275: Committed. Elapsed time: 21 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:40.297024Z","level":"info","event":"25/12/28 17:43:40 INFO FileOutputCommitter: Saved output of task 'attempt_20251228174337809004170536184871_0193_m_000005_277' to file:/opt/airflow/data/raw/olist_geolocation/_temporary/0/task_20251228174337809004170536184871_0193_m_000005","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:40.297109Z","level":"info","event":"25/12/28 17:43:40 INFO SparkHadoopMapRedUtil: attempt_20251228174337809004170536184871_0193_m_000005_277: Committed. Elapsed time: 18 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:40.323710Z","level":"info","event":"25/12/28 17:43:40 INFO Executor: Finished task 5.0 in stage 193.0 (TID 277). 2545 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:40.332987Z","level":"info","event":"25/12/28 17:43:40 INFO Executor: Finished task 3.0 in stage 193.0 (TID 275). 2545 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:40.336585Z","level":"info","event":"25/12/28 17:43:40 INFO FileOutputCommitter: Saved output of task 'attempt_20251228174337809004170536184871_0193_m_000004_276' to file:/opt/airflow/data/raw/olist_geolocation/_temporary/0/task_20251228174337809004170536184871_0193_m_000004","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:40.336724Z","level":"info","event":"25/12/28 17:43:40 INFO SparkHadoopMapRedUtil: attempt_20251228174337809004170536184871_0193_m_000004_276: Committed. Elapsed time: 38 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:40.337833Z","level":"info","event":"25/12/28 17:43:40 INFO Executor: Finished task 4.0 in stage 193.0 (TID 276). 2502 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:40.343067Z","level":"info","event":"25/12/28 17:43:40 INFO TaskSetManager: Finished task 3.0 in stage 193.0 (TID 275) in 2753 ms on c252dd92c865 (executor driver) (2/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:40.349766Z","level":"info","event":"25/12/28 17:43:40 INFO TaskSetManager: Finished task 5.0 in stage 193.0 (TID 277) in 2759 ms on c252dd92c865 (executor driver) (3/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:40.353563Z","level":"info","event":"25/12/28 17:43:40 INFO TaskSetManager: Finished task 4.0 in stage 193.0 (TID 276) in 2764 ms on c252dd92c865 (executor driver) (4/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:40.850219Z","level":"info","event":"25/12/28 17:43:40 INFO FileOutputCommitter: Saved output of task 'attempt_20251228174337809004170536184871_0193_m_000002_274' to file:/opt/airflow/data/raw/olist_geolocation/_temporary/0/task_20251228174337809004170536184871_0193_m_000002","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:40.853684Z","level":"info","event":"25/12/28 17:43:40 INFO SparkHadoopMapRedUtil: attempt_20251228174337809004170536184871_0193_m_000002_274: Committed. Elapsed time: 17 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:40.853848Z","level":"info","event":"25/12/28 17:43:40 INFO FileOutputCommitter: Saved output of task 'attempt_20251228174337809004170536184871_0193_m_000000_272' to file:/opt/airflow/data/raw/olist_geolocation/_temporary/0/task_20251228174337809004170536184871_0193_m_000000","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:40.853884Z","level":"info","event":"25/12/28 17:43:40 INFO SparkHadoopMapRedUtil: attempt_20251228174337809004170536184871_0193_m_000000_272: Committed. Elapsed time: 20 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:40.868653Z","level":"info","event":"25/12/28 17:43:40 INFO Executor: Finished task 2.0 in stage 193.0 (TID 274). 2545 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:40.870782Z","level":"info","event":"25/12/28 17:43:40 INFO Executor: Finished task 0.0 in stage 193.0 (TID 272). 2545 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:40.893298Z","level":"info","event":"25/12/28 17:43:40 INFO TaskSetManager: Finished task 2.0 in stage 193.0 (TID 274) in 3306 ms on c252dd92c865 (executor driver) (5/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:40.895242Z","level":"info","event":"25/12/28 17:43:40 INFO TaskSetManager: Finished task 0.0 in stage 193.0 (TID 272) in 3314 ms on c252dd92c865 (executor driver) (6/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.060209Z","level":"info","event":"25/12/28 17:43:41 INFO FileOutputCommitter: Saved output of task 'attempt_20251228174337809004170536184871_0193_m_000001_273' to file:/opt/airflow/data/raw/olist_geolocation/_temporary/0/task_20251228174337809004170536184871_0193_m_000001","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.060521Z","level":"info","event":"25/12/28 17:43:41 INFO SparkHadoopMapRedUtil: attempt_20251228174337809004170536184871_0193_m_000001_273: Committed. Elapsed time: 4 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.064919Z","level":"info","event":"25/12/28 17:43:41 INFO Executor: Finished task 1.0 in stage 193.0 (TID 273). 2502 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.067033Z","level":"info","event":"25/12/28 17:43:41 INFO TaskSetManager: Finished task 1.0 in stage 193.0 (TID 273) in 3484 ms on c252dd92c865 (executor driver) (7/7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.071856Z","level":"info","event":"25/12/28 17:43:41 INFO TaskSchedulerImpl: Removed TaskSet 193.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.072476Z","level":"info","event":"25/12/28 17:43:41 INFO DAGScheduler: ResultStage 193 (csv at NativeMethodAccessorImpl.java:0) finished in 3.595 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.080804Z","level":"info","event":"25/12/28 17:43:41 INFO DAGScheduler: Job 132 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.082952Z","level":"info","event":"25/12/28 17:43:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 193: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.094601Z","level":"info","event":"25/12/28 17:43:41 INFO DAGScheduler: Job 132 finished: csv at NativeMethodAccessorImpl.java:0, took 3.621172 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.102260Z","level":"info","event":"25/12/28 17:43:41 INFO FileFormatWriter: Start to commit write Job 29c3dfde-1910-448a-8baa-710f4a3bea50.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.251566Z","level":"info","event":"25/12/28 17:43:41 INFO FileFormatWriter: Write Job 29c3dfde-1910-448a-8baa-710f4a3bea50 committed. Elapsed time: 149 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.253541Z","level":"info","event":"25/12/28 17:43:41 INFO FileFormatWriter: Finished processing stats for write job 29c3dfde-1910-448a-8baa-710f4a3bea50.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.267430Z","level":"info","event":"Saved cleaned olist_geolocation to data/raw/olist_geolocation","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.466635Z","level":"info","event":"25/12/28 17:43:41 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.483301Z","level":"info","event":"25/12/28 17:43:41 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.516605Z","level":"info","event":"25/12/28 17:43:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.517846Z","level":"info","event":"25/12/28 17:43:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.518138Z","level":"info","event":"25/12/28 17:43:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.604817Z","level":"info","event":"25/12/28 17:43:41 INFO MemoryStore: Block broadcast_214 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.622592Z","level":"info","event":"25/12/28 17:43:41 INFO MemoryStore: Block broadcast_214_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.626298Z","level":"info","event":"25/12/28 17:43:41 INFO BlockManagerInfo: Added broadcast_214_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.626563Z","level":"info","event":"25/12/28 17:43:41 INFO SparkContext: Created broadcast 214 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.630699Z","level":"info","event":"25/12/28 17:43:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.643762Z","level":"info","event":"25/12/28 17:43:41 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.646543Z","level":"info","event":"25/12/28 17:43:41 INFO DAGScheduler: Got job 133 (csv at NativeMethodAccessorImpl.java:0) with 4 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.646706Z","level":"info","event":"25/12/28 17:43:41 INFO DAGScheduler: Final stage: ResultStage 194 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.646761Z","level":"info","event":"25/12/28 17:43:41 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.646991Z","level":"info","event":"25/12/28 17:43:41 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.647491Z","level":"info","event":"25/12/28 17:43:41 INFO DAGScheduler: Submitting ResultStage 194 (MapPartitionsRDD[525] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.681630Z","level":"info","event":"25/12/28 17:43:41 INFO MemoryStore: Block broadcast_215 stored as values in memory (estimated size 212.1 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.692095Z","level":"info","event":"25/12/28 17:43:41 INFO MemoryStore: Block broadcast_215_piece0 stored as bytes in memory (estimated size 76.6 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.692560Z","level":"info","event":"25/12/28 17:43:41 INFO BlockManagerInfo: Added broadcast_215_piece0 in memory on c252dd92c865:35057 (size: 76.6 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.697391Z","level":"info","event":"25/12/28 17:43:41 INFO SparkContext: Created broadcast 215 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.698826Z","level":"info","event":"25/12/28 17:43:41 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 194 (MapPartitionsRDD[525] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.707462Z","level":"info","event":"25/12/28 17:43:41 INFO TaskSchedulerImpl: Adding task set 194.0 with 4 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.707621Z","level":"info","event":"25/12/28 17:43:41 INFO TaskSetManager: Starting task 0.0 in stage 194.0 (TID 279) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8293 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.707680Z","level":"info","event":"25/12/28 17:43:41 INFO TaskSetManager: Starting task 1.0 in stage 194.0 (TID 280) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8293 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.707734Z","level":"info","event":"25/12/28 17:43:41 INFO TaskSetManager: Starting task 2.0 in stage 194.0 (TID 281) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8293 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.708142Z","level":"info","event":"25/12/28 17:43:41 INFO TaskSetManager: Starting task 3.0 in stage 194.0 (TID 282) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8293 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.718385Z","level":"info","event":"25/12/28 17:43:41 INFO Executor: Running task 0.0 in stage 194.0 (TID 279)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.718901Z","level":"info","event":"25/12/28 17:43:41 INFO Executor: Running task 3.0 in stage 194.0 (TID 282)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.719772Z","level":"info","event":"25/12/28 17:43:41 INFO Executor: Running task 1.0 in stage 194.0 (TID 280)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.720075Z","level":"info","event":"25/12/28 17:43:41 INFO Executor: Running task 2.0 in stage 194.0 (TID 281)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.787646Z","level":"info","event":"25/12/28 17:43:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.789190Z","level":"info","event":"25/12/28 17:43:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.789579Z","level":"info","event":"25/12/28 17:43:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.790003Z","level":"info","event":"25/12/28 17:43:41 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.820380Z","level":"info","event":"25/12/28 17:43:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.829325Z","level":"info","event":"25/12/28 17:43:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.829439Z","level":"info","event":"25/12/28 17:43:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.829625Z","level":"info","event":"25/12/28 17:43:41 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.845422Z","level":"info","event":"25/12/28 17:43:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.845840Z","level":"info","event":"25/12/28 17:43:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.846859Z","level":"info","event":"25/12/28 17:43:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.847433Z","level":"info","event":"25/12/28 17:43:41 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 12582912-15438671, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.859317Z","level":"info","event":"25/12/28 17:43:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.859666Z","level":"info","event":"25/12/28 17:43:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:41.859786Z","level":"info","event":"25/12/28 17:43:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:42.128941Z","level":"info","event":"25/12/28 17:43:42 INFO CodeGenerator: Code generated in 252.5775 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:42.439268Z","level":"info","event":"25/12/28 17:43:42 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_items_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:42.929298Z","level":"info","event":"25/12/28 17:43:42 INFO BlockManagerInfo: Removed broadcast_212_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:42.955445Z","level":"info","event":"25/12/28 17:43:42 INFO BlockManagerInfo: Removed broadcast_213_piece0 on c252dd92c865:35057 in memory (size: 76.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.064503Z","level":"info","event":"25/12/28 17:43:43 INFO FileOutputCommitter: Saved output of task 'attempt_202512281743417843156490141231325_0194_m_000003_282' to file:/opt/airflow/data/raw/olist_order_items/_temporary/0/task_202512281743417843156490141231325_0194_m_000003","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.064803Z","level":"info","event":"25/12/28 17:43:43 INFO SparkHadoopMapRedUtil: attempt_202512281743417843156490141231325_0194_m_000003_282: Committed. Elapsed time: 4 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.085923Z","level":"info","event":"25/12/28 17:43:43 INFO Executor: Finished task 3.0 in stage 194.0 (TID 282). 2545 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.114471Z","level":"info","event":"25/12/28 17:43:43 INFO TaskSetManager: Finished task 3.0 in stage 194.0 (TID 282) in 1402 ms on c252dd92c865 (executor driver) (1/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.179654Z","level":"info","event":"25/12/28 17:43:43 INFO FileOutputCommitter: Saved output of task 'attempt_202512281743417843156490141231325_0194_m_000000_279' to file:/opt/airflow/data/raw/olist_order_items/_temporary/0/task_202512281743417843156490141231325_0194_m_000000","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.179772Z","level":"info","event":"25/12/28 17:43:43 INFO SparkHadoopMapRedUtil: attempt_202512281743417843156490141231325_0194_m_000000_279: Committed. Elapsed time: 10 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.180739Z","level":"info","event":"25/12/28 17:43:43 INFO Executor: Finished task 0.0 in stage 194.0 (TID 279). 2502 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.181702Z","level":"info","event":"25/12/28 17:43:43 INFO TaskSetManager: Finished task 0.0 in stage 194.0 (TID 279) in 1476 ms on c252dd92c865 (executor driver) (2/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.191754Z","level":"info","event":"25/12/28 17:43:43 INFO FileOutputCommitter: Saved output of task 'attempt_202512281743417843156490141231325_0194_m_000001_280' to file:/opt/airflow/data/raw/olist_order_items/_temporary/0/task_202512281743417843156490141231325_0194_m_000001","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.191904Z","level":"info","event":"25/12/28 17:43:43 INFO SparkHadoopMapRedUtil: attempt_202512281743417843156490141231325_0194_m_000001_280: Committed. Elapsed time: 2 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.193714Z","level":"info","event":"25/12/28 17:43:43 INFO Executor: Finished task 1.0 in stage 194.0 (TID 280). 2502 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.197011Z","level":"info","event":"25/12/28 17:43:43 INFO TaskSetManager: Finished task 1.0 in stage 194.0 (TID 280) in 1490 ms on c252dd92c865 (executor driver) (3/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.200227Z","level":"info","event":"25/12/28 17:43:43 INFO FileOutputCommitter: Saved output of task 'attempt_202512281743417843156490141231325_0194_m_000002_281' to file:/opt/airflow/data/raw/olist_order_items/_temporary/0/task_202512281743417843156490141231325_0194_m_000002","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.200658Z","level":"info","event":"25/12/28 17:43:43 INFO SparkHadoopMapRedUtil: attempt_202512281743417843156490141231325_0194_m_000002_281: Committed. Elapsed time: 2 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.201515Z","level":"info","event":"25/12/28 17:43:43 INFO Executor: Finished task 2.0 in stage 194.0 (TID 281). 2502 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.206041Z","level":"info","event":"25/12/28 17:43:43 INFO TaskSetManager: Finished task 2.0 in stage 194.0 (TID 281) in 1497 ms on c252dd92c865 (executor driver) (4/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.206144Z","level":"info","event":"25/12/28 17:43:43 INFO DAGScheduler: ResultStage 194 (csv at NativeMethodAccessorImpl.java:0) finished in 1.556 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.206176Z","level":"info","event":"25/12/28 17:43:43 INFO TaskSchedulerImpl: Removed TaskSet 194.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.212746Z","level":"info","event":"25/12/28 17:43:43 INFO DAGScheduler: Job 133 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.212893Z","level":"info","event":"25/12/28 17:43:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 194: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.217074Z","level":"info","event":"25/12/28 17:43:43 INFO DAGScheduler: Job 133 finished: csv at NativeMethodAccessorImpl.java:0, took 1.569561 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.230544Z","level":"info","event":"25/12/28 17:43:43 INFO FileFormatWriter: Start to commit write Job 77816418-4d91-43b0-8f43-3d39af22d7c9.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.324974Z","level":"info","event":"25/12/28 17:43:43 INFO FileFormatWriter: Write Job 77816418-4d91-43b0-8f43-3d39af22d7c9 committed. Elapsed time: 93 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.325918Z","level":"info","event":"25/12/28 17:43:43 INFO FileFormatWriter: Finished processing stats for write job 77816418-4d91-43b0-8f43-3d39af22d7c9.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.333353Z","level":"info","event":"Saved cleaned olist_order_items to data/raw/olist_order_items","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.444101Z","level":"info","event":"25/12/28 17:43:43 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.444641Z","level":"info","event":"25/12/28 17:43:43 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.465767Z","level":"info","event":"25/12/28 17:43:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.466952Z","level":"info","event":"25/12/28 17:43:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.470302Z","level":"info","event":"25/12/28 17:43:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.516524Z","level":"info","event":"25/12/28 17:43:43 INFO MemoryStore: Block broadcast_216 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.530976Z","level":"info","event":"25/12/28 17:43:43 INFO MemoryStore: Block broadcast_216_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.531644Z","level":"info","event":"25/12/28 17:43:43 INFO BlockManagerInfo: Added broadcast_216_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.533371Z","level":"info","event":"25/12/28 17:43:43 INFO SparkContext: Created broadcast 216 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.535207Z","level":"info","event":"25/12/28 17:43:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.539274Z","level":"info","event":"25/12/28 17:43:43 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.540948Z","level":"info","event":"25/12/28 17:43:43 INFO DAGScheduler: Got job 134 (csv at NativeMethodAccessorImpl.java:0) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.541170Z","level":"info","event":"25/12/28 17:43:43 INFO DAGScheduler: Final stage: ResultStage 195 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.541358Z","level":"info","event":"25/12/28 17:43:43 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.541532Z","level":"info","event":"25/12/28 17:43:43 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.541576Z","level":"info","event":"25/12/28 17:43:43 INFO DAGScheduler: Submitting ResultStage 195 (MapPartitionsRDD[528] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.558180Z","level":"info","event":"25/12/28 17:43:43 INFO MemoryStore: Block broadcast_217 stored as values in memory (estimated size 211.8 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.562149Z","level":"info","event":"25/12/28 17:43:43 INFO MemoryStore: Block broadcast_217_piece0 stored as bytes in memory (estimated size 76.6 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.563745Z","level":"info","event":"25/12/28 17:43:43 INFO BlockManagerInfo: Added broadcast_217_piece0 in memory on c252dd92c865:35057 (size: 76.6 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.566073Z","level":"info","event":"25/12/28 17:43:43 INFO SparkContext: Created broadcast 217 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.567263Z","level":"info","event":"25/12/28 17:43:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 195 (MapPartitionsRDD[528] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.567342Z","level":"info","event":"25/12/28 17:43:43 INFO TaskSchedulerImpl: Adding task set 195.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.569389Z","level":"info","event":"25/12/28 17:43:43 INFO TaskSetManager: Starting task 0.0 in stage 195.0 (TID 283) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8296 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.569572Z","level":"info","event":"25/12/28 17:43:43 INFO TaskSetManager: Starting task 1.0 in stage 195.0 (TID 284) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8296 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.570497Z","level":"info","event":"25/12/28 17:43:43 INFO Executor: Running task 0.0 in stage 195.0 (TID 283)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.570686Z","level":"info","event":"25/12/28 17:43:43 INFO Executor: Running task 1.0 in stage 195.0 (TID 284)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.588461Z","level":"info","event":"25/12/28 17:43:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.588905Z","level":"info","event":"25/12/28 17:43:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.589102Z","level":"info","event":"25/12/28 17:43:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.590016Z","level":"info","event":"25/12/28 17:43:43 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_payments_dataset.csv, range: 4194304-5777138, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.595110Z","level":"info","event":"25/12/28 17:43:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.596053Z","level":"info","event":"25/12/28 17:43:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.596705Z","level":"info","event":"25/12/28 17:43:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.640496Z","level":"info","event":"25/12/28 17:43:43 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_payments_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.771255Z","level":"info","event":"25/12/28 17:43:43 INFO FileOutputCommitter: Saved output of task 'attempt_202512281743437324787138647863350_0195_m_000001_284' to file:/opt/airflow/data/raw/olist_order_payments/_temporary/0/task_202512281743437324787138647863350_0195_m_000001","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.771456Z","level":"info","event":"25/12/28 17:43:43 INFO SparkHadoopMapRedUtil: attempt_202512281743437324787138647863350_0195_m_000001_284: Committed. Elapsed time: 4 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.782858Z","level":"info","event":"25/12/28 17:43:43 INFO Executor: Finished task 1.0 in stage 195.0 (TID 284). 2502 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:43.785911Z","level":"info","event":"25/12/28 17:43:43 INFO TaskSetManager: Finished task 1.0 in stage 195.0 (TID 284) in 216 ms on c252dd92c865 (executor driver) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.062120Z","level":"info","event":"25/12/28 17:43:44 INFO BlockManagerInfo: Removed broadcast_214_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.071791Z","level":"info","event":"25/12/28 17:43:44 INFO BlockManagerInfo: Removed broadcast_215_piece0 on c252dd92c865:35057 in memory (size: 76.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.104993Z","level":"info","event":"25/12/28 17:43:44 INFO FileOutputCommitter: Saved output of task 'attempt_202512281743437324787138647863350_0195_m_000000_283' to file:/opt/airflow/data/raw/olist_order_payments/_temporary/0/task_202512281743437324787138647863350_0195_m_000000","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.105383Z","level":"info","event":"25/12/28 17:43:44 INFO SparkHadoopMapRedUtil: attempt_202512281743437324787138647863350_0195_m_000000_283: Committed. Elapsed time: 2 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.109823Z","level":"info","event":"25/12/28 17:43:44 INFO Executor: Finished task 0.0 in stage 195.0 (TID 283). 2545 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.114314Z","level":"info","event":"25/12/28 17:43:44 INFO TaskSetManager: Finished task 0.0 in stage 195.0 (TID 283) in 545 ms on c252dd92c865 (executor driver) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.114715Z","level":"info","event":"25/12/28 17:43:44 INFO TaskSchedulerImpl: Removed TaskSet 195.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.115982Z","level":"info","event":"25/12/28 17:43:44 INFO DAGScheduler: ResultStage 195 (csv at NativeMethodAccessorImpl.java:0) finished in 0.574 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.121434Z","level":"info","event":"25/12/28 17:43:44 INFO DAGScheduler: Job 134 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.121846Z","level":"info","event":"25/12/28 17:43:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 195: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.123008Z","level":"info","event":"25/12/28 17:43:44 INFO DAGScheduler: Job 134 finished: csv at NativeMethodAccessorImpl.java:0, took 0.583183 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.124908Z","level":"info","event":"25/12/28 17:43:44 INFO FileFormatWriter: Start to commit write Job aa0abf89-6ad9-4936-ace0-bb7c8de84b67.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.225419Z","level":"info","event":"25/12/28 17:43:44 INFO FileFormatWriter: Write Job aa0abf89-6ad9-4936-ace0-bb7c8de84b67 committed. Elapsed time: 88 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.237013Z","level":"info","event":"25/12/28 17:43:44 INFO FileFormatWriter: Finished processing stats for write job aa0abf89-6ad9-4936-ace0-bb7c8de84b67.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.241798Z","level":"info","event":"Saved cleaned olist_order_payments to data/raw/olist_order_payments","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.385829Z","level":"info","event":"25/12/28 17:43:44 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.386158Z","level":"info","event":"25/12/28 17:43:44 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.410056Z","level":"info","event":"25/12/28 17:43:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.410394Z","level":"info","event":"25/12/28 17:43:44 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.410619Z","level":"info","event":"25/12/28 17:43:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.483139Z","level":"info","event":"25/12/28 17:43:44 INFO MemoryStore: Block broadcast_218 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.501936Z","level":"info","event":"25/12/28 17:43:44 INFO MemoryStore: Block broadcast_218_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.502664Z","level":"info","event":"25/12/28 17:43:44 INFO BlockManagerInfo: Added broadcast_218_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.511909Z","level":"info","event":"25/12/28 17:43:44 INFO SparkContext: Created broadcast 218 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.516396Z","level":"info","event":"25/12/28 17:43:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.540095Z","level":"info","event":"25/12/28 17:43:44 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.545382Z","level":"info","event":"25/12/28 17:43:44 INFO DAGScheduler: Got job 135 (csv at NativeMethodAccessorImpl.java:0) with 4 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.545530Z","level":"info","event":"25/12/28 17:43:44 INFO DAGScheduler: Final stage: ResultStage 196 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.546290Z","level":"info","event":"25/12/28 17:43:44 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.546473Z","level":"info","event":"25/12/28 17:43:44 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.551228Z","level":"info","event":"25/12/28 17:43:44 INFO DAGScheduler: Submitting ResultStage 196 (MapPartitionsRDD[531] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.609425Z","level":"info","event":"25/12/28 17:43:44 INFO MemoryStore: Block broadcast_219 stored as values in memory (estimated size 212.2 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.613962Z","level":"info","event":"25/12/28 17:43:44 INFO MemoryStore: Block broadcast_219_piece0 stored as bytes in memory (estimated size 76.6 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.614648Z","level":"info","event":"25/12/28 17:43:44 INFO BlockManagerInfo: Added broadcast_219_piece0 in memory on c252dd92c865:35057 (size: 76.6 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.615574Z","level":"info","event":"25/12/28 17:43:44 INFO SparkContext: Created broadcast 219 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.617417Z","level":"info","event":"25/12/28 17:43:44 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 196 (MapPartitionsRDD[531] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.622679Z","level":"info","event":"25/12/28 17:43:44 INFO TaskSchedulerImpl: Adding task set 196.0 with 4 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.635947Z","level":"info","event":"25/12/28 17:43:44 INFO TaskSetManager: Starting task 0.0 in stage 196.0 (TID 285) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8295 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.636428Z","level":"info","event":"25/12/28 17:43:44 INFO TaskSetManager: Starting task 1.0 in stage 196.0 (TID 286) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8295 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.638427Z","level":"info","event":"25/12/28 17:43:44 INFO TaskSetManager: Starting task 2.0 in stage 196.0 (TID 287) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8295 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.638807Z","level":"info","event":"25/12/28 17:43:44 INFO TaskSetManager: Starting task 3.0 in stage 196.0 (TID 288) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8295 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.640369Z","level":"info","event":"25/12/28 17:43:44 INFO Executor: Running task 1.0 in stage 196.0 (TID 286)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.645169Z","level":"info","event":"25/12/28 17:43:44 INFO Executor: Running task 0.0 in stage 196.0 (TID 285)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.651602Z","level":"info","event":"25/12/28 17:43:44 INFO Executor: Running task 3.0 in stage 196.0 (TID 288)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.672395Z","level":"info","event":"25/12/28 17:43:44 INFO Executor: Running task 2.0 in stage 196.0 (TID 287)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.763863Z","level":"info","event":"25/12/28 17:43:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.766440Z","level":"info","event":"25/12/28 17:43:44 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.776575Z","level":"info","event":"25/12/28 17:43:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.778306Z","level":"info","event":"25/12/28 17:43:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.778416Z","level":"info","event":"25/12/28 17:43:44 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.779892Z","level":"info","event":"25/12/28 17:43:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.780156Z","level":"info","event":"25/12/28 17:43:44 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.787388Z","level":"info","event":"25/12/28 17:43:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.787796Z","level":"info","event":"25/12/28 17:43:44 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.789489Z","level":"info","event":"25/12/28 17:43:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.797324Z","level":"info","event":"25/12/28 17:43:44 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 12582912-14451670, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.952921Z","level":"info","event":"25/12/28 17:43:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.954182Z","level":"info","event":"25/12/28 17:43:44 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.955705Z","level":"info","event":"25/12/28 17:43:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:44.957363Z","level":"info","event":"25/12/28 17:43:44 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:45.277078Z","level":"info","event":"25/12/28 17:43:45 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_order_reviews_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:48.753849Z","level":"info","event":"25/12/28 17:43:48 INFO FileOutputCommitter: Saved output of task 'attempt_202512281743445909284232905959043_0196_m_000003_288' to file:/opt/airflow/data/raw/olist_order_reviews/_temporary/0/task_202512281743445909284232905959043_0196_m_000003","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:48.773701Z","level":"info","event":"25/12/28 17:43:48 INFO SparkHadoopMapRedUtil: attempt_202512281743445909284232905959043_0196_m_000003_288: Committed. Elapsed time: 24 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:48.860119Z","level":"info","event":"25/12/28 17:43:48 INFO Executor: Finished task 3.0 in stage 196.0 (TID 288). 2502 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:48.967956Z","level":"info","event":"25/12/28 17:43:48 INFO TaskSetManager: Finished task 3.0 in stage 196.0 (TID 288) in 4324 ms on c252dd92c865 (executor driver) (1/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.134822Z","level":"info","event":"25/12/28 17:43:50 INFO BlockManagerInfo: Removed broadcast_217_piece0 on c252dd92c865:35057 in memory (size: 76.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.183511Z","level":"info","event":"25/12/28 17:43:50 INFO BlockManagerInfo: Removed broadcast_216_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.256446Z","level":"info","event":"25/12/28 17:43:50 INFO FileOutputCommitter: Saved output of task 'attempt_202512281743445909284232905959043_0196_m_000002_287' to file:/opt/airflow/data/raw/olist_order_reviews/_temporary/0/task_202512281743445909284232905959043_0196_m_000002","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.257037Z","level":"info","event":"25/12/28 17:43:50 INFO SparkHadoopMapRedUtil: attempt_202512281743445909284232905959043_0196_m_000002_287: Committed. Elapsed time: 37 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.320473Z","level":"info","event":"25/12/28 17:43:50 INFO FileOutputCommitter: Saved output of task 'attempt_202512281743445909284232905959043_0196_m_000000_285' to file:/opt/airflow/data/raw/olist_order_reviews/_temporary/0/task_202512281743445909284232905959043_0196_m_000000","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.329397Z","level":"info","event":"25/12/28 17:43:50 INFO SparkHadoopMapRedUtil: attempt_202512281743445909284232905959043_0196_m_000000_285: Committed. Elapsed time: 11 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.336306Z","level":"info","event":"25/12/28 17:43:50 INFO Executor: Finished task 2.0 in stage 196.0 (TID 287). 2545 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.345647Z","level":"info","event":"25/12/28 17:43:50 INFO Executor: Finished task 0.0 in stage 196.0 (TID 285). 2502 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.410288Z","level":"info","event":"25/12/28 17:43:50 INFO FileOutputCommitter: Saved output of task 'attempt_202512281743445909284232905959043_0196_m_000001_286' to file:/opt/airflow/data/raw/olist_order_reviews/_temporary/0/task_202512281743445909284232905959043_0196_m_000001","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.413268Z","level":"info","event":"25/12/28 17:43:50 INFO SparkHadoopMapRedUtil: attempt_202512281743445909284232905959043_0196_m_000001_286: Committed. Elapsed time: 5 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.413544Z","level":"info","event":"25/12/28 17:43:50 INFO TaskSetManager: Finished task 2.0 in stage 196.0 (TID 287) in 5753 ms on c252dd92c865 (executor driver) (2/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.413770Z","level":"info","event":"25/12/28 17:43:50 INFO TaskSetManager: Finished task 0.0 in stage 196.0 (TID 285) in 5758 ms on c252dd92c865 (executor driver) (3/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.413903Z","level":"info","event":"25/12/28 17:43:50 INFO Executor: Finished task 1.0 in stage 196.0 (TID 286). 2545 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.454210Z","level":"info","event":"25/12/28 17:43:50 INFO TaskSetManager: Finished task 1.0 in stage 196.0 (TID 286) in 5816 ms on c252dd92c865 (executor driver) (4/4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.460417Z","level":"info","event":"25/12/28 17:43:50 INFO TaskSchedulerImpl: Removed TaskSet 196.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.462999Z","level":"info","event":"25/12/28 17:43:50 INFO DAGScheduler: ResultStage 196 (csv at NativeMethodAccessorImpl.java:0) finished in 5.895 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.475423Z","level":"info","event":"25/12/28 17:43:50 INFO DAGScheduler: Job 135 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.475727Z","level":"info","event":"25/12/28 17:43:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 196: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.480369Z","level":"info","event":"25/12/28 17:43:50 INFO DAGScheduler: Job 135 finished: csv at NativeMethodAccessorImpl.java:0, took 5.938373 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.512745Z","level":"info","event":"25/12/28 17:43:50 INFO FileFormatWriter: Start to commit write Job 70ad6983-42e0-48fd-a92b-64a7214dcc7e.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.744805Z","level":"info","event":"25/12/28 17:43:50 INFO FileFormatWriter: Write Job 70ad6983-42e0-48fd-a92b-64a7214dcc7e committed. Elapsed time: 231 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.752113Z","level":"info","event":"25/12/28 17:43:50 INFO FileFormatWriter: Finished processing stats for write job 70ad6983-42e0-48fd-a92b-64a7214dcc7e.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.763424Z","level":"info","event":"Saved cleaned olist_order_reviews to data/raw/olist_order_reviews","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.950850Z","level":"info","event":"25/12/28 17:43:50 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.951155Z","level":"info","event":"25/12/28 17:43:50 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.995736Z","level":"info","event":"25/12/28 17:43:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.996093Z","level":"info","event":"25/12/28 17:43:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:50.997329Z","level":"info","event":"25/12/28 17:43:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.037835Z","level":"info","event":"25/12/28 17:43:51 INFO MemoryStore: Block broadcast_220 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.056671Z","level":"info","event":"25/12/28 17:43:51 INFO MemoryStore: Block broadcast_220_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.057832Z","level":"info","event":"25/12/28 17:43:51 INFO BlockManagerInfo: Added broadcast_220_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.062216Z","level":"info","event":"25/12/28 17:43:51 INFO SparkContext: Created broadcast 220 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.070668Z","level":"info","event":"25/12/28 17:43:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.079708Z","level":"info","event":"25/12/28 17:43:51 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.089699Z","level":"info","event":"25/12/28 17:43:51 INFO DAGScheduler: Got job 136 (csv at NativeMethodAccessorImpl.java:0) with 5 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.089909Z","level":"info","event":"25/12/28 17:43:51 INFO DAGScheduler: Final stage: ResultStage 197 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.090024Z","level":"info","event":"25/12/28 17:43:51 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.090621Z","level":"info","event":"25/12/28 17:43:51 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.096887Z","level":"info","event":"25/12/28 17:43:51 INFO DAGScheduler: Submitting ResultStage 197 (MapPartitionsRDD[534] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.114881Z","level":"info","event":"25/12/28 17:43:51 INFO MemoryStore: Block broadcast_221 stored as values in memory (estimated size 212.4 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.117440Z","level":"info","event":"25/12/28 17:43:51 INFO MemoryStore: Block broadcast_221_piece0 stored as bytes in memory (estimated size 76.7 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.118170Z","level":"info","event":"25/12/28 17:43:51 INFO BlockManagerInfo: Added broadcast_221_piece0 in memory on c252dd92c865:35057 (size: 76.7 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.120605Z","level":"info","event":"25/12/28 17:43:51 INFO SparkContext: Created broadcast 221 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.120729Z","level":"info","event":"25/12/28 17:43:51 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 197 (MapPartitionsRDD[534] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.120913Z","level":"info","event":"25/12/28 17:43:51 INFO TaskSchedulerImpl: Adding task set 197.0 with 5 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.126915Z","level":"info","event":"25/12/28 17:43:51 INFO TaskSetManager: Starting task 0.0 in stage 197.0 (TID 289) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8288 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.127952Z","level":"info","event":"25/12/28 17:43:51 INFO TaskSetManager: Starting task 1.0 in stage 197.0 (TID 290) (c252dd92c865, executor driver, partition 1, PROCESS_LOCAL, 8288 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.129222Z","level":"info","event":"25/12/28 17:43:51 INFO TaskSetManager: Starting task 2.0 in stage 197.0 (TID 291) (c252dd92c865, executor driver, partition 2, PROCESS_LOCAL, 8288 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.129677Z","level":"info","event":"25/12/28 17:43:51 INFO TaskSetManager: Starting task 3.0 in stage 197.0 (TID 292) (c252dd92c865, executor driver, partition 3, PROCESS_LOCAL, 8288 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.130331Z","level":"info","event":"25/12/28 17:43:51 INFO TaskSetManager: Starting task 4.0 in stage 197.0 (TID 293) (c252dd92c865, executor driver, partition 4, PROCESS_LOCAL, 8288 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.134228Z","level":"info","event":"25/12/28 17:43:51 INFO Executor: Running task 0.0 in stage 197.0 (TID 289)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.134487Z","level":"info","event":"25/12/28 17:43:51 INFO Executor: Running task 1.0 in stage 197.0 (TID 290)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.134581Z","level":"info","event":"25/12/28 17:43:51 INFO Executor: Running task 2.0 in stage 197.0 (TID 291)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.136275Z","level":"info","event":"25/12/28 17:43:51 INFO Executor: Running task 3.0 in stage 197.0 (TID 292)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.141637Z","level":"info","event":"25/12/28 17:43:51 INFO Executor: Running task 4.0 in stage 197.0 (TID 293)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.202197Z","level":"info","event":"25/12/28 17:43:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.202517Z","level":"info","event":"25/12/28 17:43:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.205311Z","level":"info","event":"25/12/28 17:43:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.205428Z","level":"info","event":"25/12/28 17:43:51 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 12582912-16777216, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.218508Z","level":"info","event":"25/12/28 17:43:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.218632Z","level":"info","event":"25/12/28 17:43:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.221309Z","level":"info","event":"25/12/28 17:43:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.221424Z","level":"info","event":"25/12/28 17:43:51 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 16777216-17654914, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.229451Z","level":"info","event":"25/12/28 17:43:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.232041Z","level":"info","event":"25/12/28 17:43:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.233105Z","level":"info","event":"25/12/28 17:43:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.233791Z","level":"info","event":"25/12/28 17:43:51 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 8388608-12582912, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.234359Z","level":"info","event":"25/12/28 17:43:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.234628Z","level":"info","event":"25/12/28 17:43:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.238136Z","level":"info","event":"25/12/28 17:43:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.277920Z","level":"info","event":"25/12/28 17:43:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.278518Z","level":"info","event":"25/12/28 17:43:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.279629Z","level":"info","event":"25/12/28 17:43:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.281861Z","level":"info","event":"25/12/28 17:43:51 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 4194304-8388608, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.358341Z","level":"info","event":"25/12/28 17:43:51 INFO CodeGenerator: Code generated in 137.748458 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.363296Z","level":"info","event":"25/12/28 17:43:51 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_orders_dataset.csv, range: 0-4194304, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.920848Z","level":"info","event":"25/12/28 17:43:51 INFO FileOutputCommitter: Saved output of task 'attempt_202512281743518386661608650269331_0197_m_000004_293' to file:/opt/airflow/data/raw/olist_orders/_temporary/0/task_202512281743518386661608650269331_0197_m_000004","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.937188Z","level":"info","event":"25/12/28 17:43:51 INFO SparkHadoopMapRedUtil: attempt_202512281743518386661608650269331_0197_m_000004_293: Committed. Elapsed time: 22 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:51.975731Z","level":"info","event":"25/12/28 17:43:51 INFO Executor: Finished task 4.0 in stage 197.0 (TID 293). 2502 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:52.008931Z","level":"info","event":"25/12/28 17:43:52 INFO TaskSetManager: Finished task 4.0 in stage 197.0 (TID 293) in 875 ms on c252dd92c865 (executor driver) (1/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:52.744144Z","level":"info","event":"25/12/28 17:43:52 INFO FileOutputCommitter: Saved output of task 'attempt_202512281743518386661608650269331_0197_m_000000_289' to file:/opt/airflow/data/raw/olist_orders/_temporary/0/task_202512281743518386661608650269331_0197_m_000000","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:52.769953Z","level":"info","event":"25/12/28 17:43:52 INFO SparkHadoopMapRedUtil: attempt_202512281743518386661608650269331_0197_m_000000_289: Committed. Elapsed time: 18 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:52.770417Z","level":"info","event":"25/12/28 17:43:52 INFO BlockManagerInfo: Removed broadcast_218_piece0 on c252dd92c865:35057 in memory (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:52.770698Z","level":"info","event":"25/12/28 17:43:52 INFO BlockManagerInfo: Removed broadcast_219_piece0 on c252dd92c865:35057 in memory (size: 76.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:52.818103Z","level":"info","event":"25/12/28 17:43:52 INFO Executor: Finished task 0.0 in stage 197.0 (TID 289). 2545 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:52.878965Z","level":"info","event":"25/12/28 17:43:52 INFO FileOutputCommitter: Saved output of task 'attempt_202512281743518386661608650269331_0197_m_000003_292' to file:/opt/airflow/data/raw/olist_orders/_temporary/0/task_202512281743518386661608650269331_0197_m_000003","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:52.879208Z","level":"info","event":"25/12/28 17:43:52 INFO SparkHadoopMapRedUtil: attempt_202512281743518386661608650269331_0197_m_000003_292: Committed. Elapsed time: 14 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:52.883507Z","level":"info","event":"25/12/28 17:43:52 INFO FileOutputCommitter: Saved output of task 'attempt_202512281743518386661608650269331_0197_m_000001_290' to file:/opt/airflow/data/raw/olist_orders/_temporary/0/task_202512281743518386661608650269331_0197_m_000001","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:52.883597Z","level":"info","event":"25/12/28 17:43:52 INFO SparkHadoopMapRedUtil: attempt_202512281743518386661608650269331_0197_m_000001_290: Committed. Elapsed time: 19 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:52.883624Z","level":"info","event":"25/12/28 17:43:52 INFO Executor: Finished task 1.0 in stage 197.0 (TID 290). 2502 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:52.918366Z","level":"info","event":"25/12/28 17:43:52 INFO Executor: Finished task 3.0 in stage 197.0 (TID 292). 2545 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:52.924771Z","level":"info","event":"25/12/28 17:43:52 INFO TaskSetManager: Finished task 1.0 in stage 197.0 (TID 290) in 1789 ms on c252dd92c865 (executor driver) (2/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:52.932850Z","level":"info","event":"25/12/28 17:43:52 INFO TaskSetManager: Finished task 0.0 in stage 197.0 (TID 289) in 1807 ms on c252dd92c865 (executor driver) (3/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:52.936988Z","level":"info","event":"25/12/28 17:43:52 INFO TaskSetManager: Finished task 3.0 in stage 197.0 (TID 292) in 1806 ms on c252dd92c865 (executor driver) (4/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:52.941164Z","level":"info","event":"25/12/28 17:43:52 INFO FileOutputCommitter: Saved output of task 'attempt_202512281743518386661608650269331_0197_m_000002_291' to file:/opt/airflow/data/raw/olist_orders/_temporary/0/task_202512281743518386661608650269331_0197_m_000002","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:52.941400Z","level":"info","event":"25/12/28 17:43:52 INFO SparkHadoopMapRedUtil: attempt_202512281743518386661608650269331_0197_m_000002_291: Committed. Elapsed time: 9 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:52.946370Z","level":"info","event":"25/12/28 17:43:52 INFO Executor: Finished task 2.0 in stage 197.0 (TID 291). 2545 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:52.959284Z","level":"info","event":"25/12/28 17:43:52 INFO TaskSetManager: Finished task 2.0 in stage 197.0 (TID 291) in 1827 ms on c252dd92c865 (executor driver) (5/5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:52.959693Z","level":"info","event":"25/12/28 17:43:52 INFO TaskSchedulerImpl: Removed TaskSet 197.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:52.970155Z","level":"info","event":"25/12/28 17:43:52 INFO DAGScheduler: ResultStage 197 (csv at NativeMethodAccessorImpl.java:0) finished in 1.858 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:52.975101Z","level":"info","event":"25/12/28 17:43:52 INFO DAGScheduler: Job 136 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:52.981267Z","level":"info","event":"25/12/28 17:43:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 197: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:52.997309Z","level":"info","event":"25/12/28 17:43:52 INFO DAGScheduler: Job 136 finished: csv at NativeMethodAccessorImpl.java:0, took 1.913975 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:53.021500Z","level":"info","event":"25/12/28 17:43:53 INFO FileFormatWriter: Start to commit write Job a8b80392-f275-4ac7-b7a3-52e0528447ba.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:53.197993Z","level":"info","event":"25/12/28 17:43:53 INFO FileFormatWriter: Write Job a8b80392-f275-4ac7-b7a3-52e0528447ba committed. Elapsed time: 175 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:53.207640Z","level":"info","event":"25/12/28 17:43:53 INFO FileFormatWriter: Finished processing stats for write job a8b80392-f275-4ac7-b7a3-52e0528447ba.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:53.233877Z","level":"info","event":"Saved cleaned olist_orders to data/raw/olist_orders","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:53.581986Z","level":"info","event":"25/12/28 17:43:53 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:53.584700Z","level":"info","event":"25/12/28 17:43:53 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:53.714300Z","level":"info","event":"25/12/28 17:43:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:53.715022Z","level":"info","event":"25/12/28 17:43:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:53.717396Z","level":"info","event":"25/12/28 17:43:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:53.823283Z","level":"info","event":"25/12/28 17:43:53 INFO MemoryStore: Block broadcast_222 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:53.856287Z","level":"info","event":"25/12/28 17:43:53 INFO MemoryStore: Block broadcast_222_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:53.875110Z","level":"info","event":"25/12/28 17:43:53 INFO BlockManagerInfo: Added broadcast_222_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:53.885901Z","level":"info","event":"25/12/28 17:43:53 INFO SparkContext: Created broadcast 222 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:53.902557Z","level":"info","event":"25/12/28 17:43:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:53.964081Z","level":"info","event":"25/12/28 17:43:53 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:53.975085Z","level":"info","event":"25/12/28 17:43:53 INFO DAGScheduler: Got job 137 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:53.975649Z","level":"info","event":"25/12/28 17:43:53 INFO DAGScheduler: Final stage: ResultStage 198 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:53.975783Z","level":"info","event":"25/12/28 17:43:53 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:53.976277Z","level":"info","event":"25/12/28 17:43:53 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:53.982449Z","level":"info","event":"25/12/28 17:43:53 INFO DAGScheduler: Submitting ResultStage 198 (MapPartitionsRDD[537] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:54.011362Z","level":"info","event":"25/12/28 17:43:54 INFO MemoryStore: Block broadcast_223 stored as values in memory (estimated size 212.5 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:54.016823Z","level":"info","event":"25/12/28 17:43:54 INFO MemoryStore: Block broadcast_223_piece0 stored as bytes in memory (estimated size 76.7 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:54.019501Z","level":"info","event":"25/12/28 17:43:54 INFO BlockManagerInfo: Added broadcast_223_piece0 in memory on c252dd92c865:35057 (size: 76.7 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:54.020196Z","level":"info","event":"25/12/28 17:43:54 INFO SparkContext: Created broadcast 223 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:54.022351Z","level":"info","event":"25/12/28 17:43:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 198 (MapPartitionsRDD[537] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:54.023184Z","level":"info","event":"25/12/28 17:43:54 INFO TaskSchedulerImpl: Adding task set 198.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:54.049173Z","level":"info","event":"25/12/28 17:43:54 INFO TaskSetManager: Starting task 0.0 in stage 198.0 (TID 294) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8290 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:54.051308Z","level":"info","event":"25/12/28 17:43:54 INFO Executor: Running task 0.0 in stage 198.0 (TID 294)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:54.097477Z","level":"info","event":"25/12/28 17:43:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:54.097974Z","level":"info","event":"25/12/28 17:43:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:54.098285Z","level":"info","event":"25/12/28 17:43:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:54.176372Z","level":"info","event":"25/12/28 17:43:54 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_products_dataset.csv, range: 0-2379446, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:54.265755Z","level":"info","event":"25/12/28 17:43:54 INFO CodeGenerator: Code generated in 72.426791 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.037793Z","level":"info","event":"25/12/28 17:43:55 INFO FileOutputCommitter: Saved output of task 'attempt_202512281743537545823706053342545_0198_m_000000_294' to file:/opt/airflow/data/raw/olist_products/_temporary/0/task_202512281743537545823706053342545_0198_m_000000","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.046472Z","level":"info","event":"25/12/28 17:43:55 INFO SparkHadoopMapRedUtil: attempt_202512281743537545823706053342545_0198_m_000000_294: Committed. Elapsed time: 10 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.072425Z","level":"info","event":"25/12/28 17:43:55 INFO Executor: Finished task 0.0 in stage 198.0 (TID 294). 2502 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.093733Z","level":"info","event":"25/12/28 17:43:55 INFO TaskSetManager: Finished task 0.0 in stage 198.0 (TID 294) in 1046 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.094086Z","level":"info","event":"25/12/28 17:43:55 INFO TaskSchedulerImpl: Removed TaskSet 198.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.107409Z","level":"info","event":"25/12/28 17:43:55 INFO DAGScheduler: ResultStage 198 (csv at NativeMethodAccessorImpl.java:0) finished in 1.113 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.110143Z","level":"info","event":"25/12/28 17:43:55 INFO DAGScheduler: Job 137 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.110899Z","level":"info","event":"25/12/28 17:43:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 198: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.111402Z","level":"info","event":"25/12/28 17:43:55 INFO DAGScheduler: Job 137 finished: csv at NativeMethodAccessorImpl.java:0, took 1.143146 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.127948Z","level":"info","event":"25/12/28 17:43:55 INFO FileFormatWriter: Start to commit write Job 6918b87c-0ef6-48fa-86c1-cf1074f9a77f.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.190372Z","level":"info","event":"25/12/28 17:43:55 INFO FileFormatWriter: Write Job 6918b87c-0ef6-48fa-86c1-cf1074f9a77f committed. Elapsed time: 62 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.191467Z","level":"info","event":"25/12/28 17:43:55 INFO FileFormatWriter: Finished processing stats for write job 6918b87c-0ef6-48fa-86c1-cf1074f9a77f.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.195401Z","level":"info","event":"Saved cleaned olist_products to data/raw/olist_products","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.320570Z","level":"info","event":"25/12/28 17:43:55 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.321107Z","level":"info","event":"25/12/28 17:43:55 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.402718Z","level":"info","event":"25/12/28 17:43:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.403224Z","level":"info","event":"25/12/28 17:43:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.403328Z","level":"info","event":"25/12/28 17:43:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.499116Z","level":"info","event":"25/12/28 17:43:55 INFO MemoryStore: Block broadcast_224 stored as values in memory (estimated size 199.2 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.524143Z","level":"info","event":"25/12/28 17:43:55 INFO MemoryStore: Block broadcast_224_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.528193Z","level":"info","event":"25/12/28 17:43:55 INFO BlockManagerInfo: Added broadcast_224_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.560464Z","level":"info","event":"25/12/28 17:43:55 INFO SparkContext: Created broadcast 224 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.568276Z","level":"info","event":"25/12/28 17:43:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.597680Z","level":"info","event":"25/12/28 17:43:55 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.607393Z","level":"info","event":"25/12/28 17:43:55 INFO DAGScheduler: Got job 138 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.608347Z","level":"info","event":"25/12/28 17:43:55 INFO DAGScheduler: Final stage: ResultStage 199 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.608636Z","level":"info","event":"25/12/28 17:43:55 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.611167Z","level":"info","event":"25/12/28 17:43:55 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.611499Z","level":"info","event":"25/12/28 17:43:55 INFO DAGScheduler: Submitting ResultStage 199 (MapPartitionsRDD[540] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.750606Z","level":"info","event":"25/12/28 17:43:55 INFO MemoryStore: Block broadcast_225 stored as values in memory (estimated size 211.7 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.793270Z","level":"info","event":"25/12/28 17:43:55 INFO MemoryStore: Block broadcast_225_piece0 stored as bytes in memory (estimated size 76.6 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.831340Z","level":"info","event":"25/12/28 17:43:55 INFO BlockManagerInfo: Added broadcast_225_piece0 in memory on c252dd92c865:35057 (size: 76.6 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.888473Z","level":"info","event":"25/12/28 17:43:55 INFO SparkContext: Created broadcast 225 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.895557Z","level":"info","event":"25/12/28 17:43:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 199 (MapPartitionsRDD[540] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:55.901517Z","level":"info","event":"25/12/28 17:43:55 INFO TaskSchedulerImpl: Adding task set 199.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:56.018680Z","level":"info","event":"25/12/28 17:43:56 INFO TaskSetManager: Starting task 0.0 in stage 199.0 (TID 295) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8289 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:56.043106Z","level":"info","event":"25/12/28 17:43:56 INFO Executor: Running task 0.0 in stage 199.0 (TID 295)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:56.394780Z","level":"info","event":"25/12/28 17:43:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:56.399416Z","level":"info","event":"25/12/28 17:43:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:56.406345Z","level":"info","event":"25/12/28 17:43:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:56.574729Z","level":"info","event":"25/12/28 17:43:56 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/olist_sellers_dataset.csv, range: 0-174703, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:56.709809Z","level":"info","event":"25/12/28 17:43:56 INFO CodeGenerator: Code generated in 104.594917 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:56.777533Z","level":"info","event":"25/12/28 17:43:56 INFO FileOutputCommitter: Saved output of task 'attempt_20251228174355872891871607627054_0199_m_000000_295' to file:/opt/airflow/data/raw/olist_sellers/_temporary/0/task_20251228174355872891871607627054_0199_m_000000","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:56.777785Z","level":"info","event":"25/12/28 17:43:56 INFO SparkHadoopMapRedUtil: attempt_20251228174355872891871607627054_0199_m_000000_295: Committed. Elapsed time: 2 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:56.782897Z","level":"info","event":"25/12/28 17:43:56 INFO Executor: Finished task 0.0 in stage 199.0 (TID 295). 2502 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:56.791967Z","level":"info","event":"25/12/28 17:43:56 INFO TaskSetManager: Finished task 0.0 in stage 199.0 (TID 295) in 778 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:56.793566Z","level":"info","event":"25/12/28 17:43:56 INFO TaskSchedulerImpl: Removed TaskSet 199.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:56.795891Z","level":"info","event":"25/12/28 17:43:56 INFO DAGScheduler: ResultStage 199 (csv at NativeMethodAccessorImpl.java:0) finished in 1.179 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:56.804223Z","level":"info","event":"25/12/28 17:43:56 INFO DAGScheduler: Job 138 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:56.804987Z","level":"info","event":"25/12/28 17:43:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 199: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:56.814187Z","level":"info","event":"25/12/28 17:43:56 INFO DAGScheduler: Job 138 finished: csv at NativeMethodAccessorImpl.java:0, took 1.215311 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:56.820085Z","level":"info","event":"25/12/28 17:43:56 INFO FileFormatWriter: Start to commit write Job 6d0419c5-c6ad-434a-a762-b4661155fa87.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:56.896703Z","level":"info","event":"25/12/28 17:43:56 INFO FileFormatWriter: Write Job 6d0419c5-c6ad-434a-a762-b4661155fa87 committed. Elapsed time: 76 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:56.901232Z","level":"info","event":"25/12/28 17:43:56 INFO FileFormatWriter: Finished processing stats for write job 6d0419c5-c6ad-434a-a762-b4661155fa87.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:56.904801Z","level":"info","event":"Saved cleaned olist_sellers to data/raw/olist_sellers","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:56.988192Z","level":"info","event":"25/12/28 17:43:56 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:56.988817Z","level":"info","event":"25/12/28 17:43:56 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.034993Z","level":"info","event":"25/12/28 17:43:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.035434Z","level":"info","event":"25/12/28 17:43:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.035562Z","level":"info","event":"25/12/28 17:43:57 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.124381Z","level":"info","event":"25/12/28 17:43:57 INFO MemoryStore: Block broadcast_226 stored as values in memory (estimated size 199.2 KiB, free 432.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.161619Z","level":"info","event":"25/12/28 17:43:57 INFO MemoryStore: Block broadcast_226_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 432.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.162500Z","level":"info","event":"25/12/28 17:43:57 INFO BlockManagerInfo: Added broadcast_226_piece0 in memory on c252dd92c865:35057 (size: 34.1 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.164498Z","level":"info","event":"25/12/28 17:43:57 INFO SparkContext: Created broadcast 226 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.171893Z","level":"info","event":"25/12/28 17:43:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.185025Z","level":"info","event":"25/12/28 17:43:57 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.188470Z","level":"info","event":"25/12/28 17:43:57 INFO DAGScheduler: Got job 139 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.188910Z","level":"info","event":"25/12/28 17:43:57 INFO DAGScheduler: Final stage: ResultStage 200 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.189182Z","level":"info","event":"25/12/28 17:43:57 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.189327Z","level":"info","event":"25/12/28 17:43:57 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.189463Z","level":"info","event":"25/12/28 17:43:57 INFO DAGScheduler: Submitting ResultStage 200 (MapPartitionsRDD[543] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.218673Z","level":"info","event":"25/12/28 17:43:57 INFO MemoryStore: Block broadcast_227 stored as values in memory (estimated size 211.4 KiB, free 432.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.236189Z","level":"info","event":"25/12/28 17:43:57 INFO MemoryStore: Block broadcast_227_piece0 stored as bytes in memory (estimated size 76.5 KiB, free 432.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.236784Z","level":"info","event":"25/12/28 17:43:57 INFO BlockManagerInfo: Added broadcast_227_piece0 in memory on c252dd92c865:35057 (size: 76.5 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.237365Z","level":"info","event":"25/12/28 17:43:57 INFO SparkContext: Created broadcast 227 from broadcast at DAGScheduler.scala:1580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.237770Z","level":"info","event":"25/12/28 17:43:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 200 (MapPartitionsRDD[543] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.237854Z","level":"info","event":"25/12/28 17:43:57 INFO TaskSchedulerImpl: Adding task set 200.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.241693Z","level":"info","event":"25/12/28 17:43:57 INFO TaskSetManager: Starting task 0.0 in stage 200.0 (TID 296) (c252dd92c865, executor driver, partition 0, PROCESS_LOCAL, 8301 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.246981Z","level":"info","event":"25/12/28 17:43:57 INFO Executor: Running task 0.0 in stage 200.0 (TID 296)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.282845Z","level":"info","event":"25/12/28 17:43:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.283877Z","level":"info","event":"25/12/28 17:43:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.284143Z","level":"info","event":"25/12/28 17:43:57 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.645430Z","level":"info","event":"25/12/28 17:43:57 INFO FileScanRDD: Reading File path: file:///home/airflow/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2/product_category_name_translation.csv, range: 0-2613, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.910221Z","level":"info","event":"25/12/28 17:43:57 INFO CodeGenerator: Code generated in 210.176834 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:57.965786Z","level":"info","event":"25/12/28 17:43:57 INFO LineRecordReader: Found UTF-8 BOM and skipped it","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:58.021097Z","level":"info","event":"25/12/28 17:43:58 INFO FileOutputCommitter: Saved output of task 'attempt_202512281743577405088334799670448_0200_m_000000_296' to file:/opt/airflow/data/raw/product_category_name_translation/_temporary/0/task_202512281743577405088334799670448_0200_m_000000","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:58.021662Z","level":"info","event":"25/12/28 17:43:58 INFO SparkHadoopMapRedUtil: attempt_202512281743577405088334799670448_0200_m_000000_296: Committed. Elapsed time: 7 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:58.049473Z","level":"info","event":"25/12/28 17:43:58 INFO Executor: Finished task 0.0 in stage 200.0 (TID 296). 2502 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:58.083857Z","level":"info","event":"25/12/28 17:43:58 INFO TaskSetManager: Finished task 0.0 in stage 200.0 (TID 296) in 841 ms on c252dd92c865 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:58.084265Z","level":"info","event":"25/12/28 17:43:58 INFO TaskSchedulerImpl: Removed TaskSet 200.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:58.092976Z","level":"info","event":"25/12/28 17:43:58 INFO DAGScheduler: ResultStage 200 (csv at NativeMethodAccessorImpl.java:0) finished in 0.895 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:58.109762Z","level":"info","event":"25/12/28 17:43:58 INFO DAGScheduler: Job 139 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:58.110022Z","level":"info","event":"25/12/28 17:43:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 200: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:58.119529Z","level":"info","event":"25/12/28 17:43:58 INFO DAGScheduler: Job 139 finished: csv at NativeMethodAccessorImpl.java:0, took 0.933594 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:58.181039Z","level":"info","event":"25/12/28 17:43:58 INFO FileFormatWriter: Start to commit write Job e9a86323-3e23-4147-b81e-3621ea30ff3b.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:58.283846Z","level":"info","event":"25/12/28 17:43:58 INFO FileFormatWriter: Write Job e9a86323-3e23-4147-b81e-3621ea30ff3b committed. Elapsed time: 101 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:58.285299Z","level":"info","event":"25/12/28 17:43:58 INFO FileFormatWriter: Finished processing stats for write job e9a86323-3e23-4147-b81e-3621ea30ff3b.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:58.296181Z","level":"info","event":"Saved cleaned product_category_name_translation to data/raw/product_category_name_translation","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:58.297203Z","level":"info","event":"['olist_customers', 'olist_geolocation', 'olist_order_items', 'olist_order_payments', 'olist_order_reviews', 'olist_orders', 'olist_products', 'olist_sellers', 'product_category_name_translation']","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:58.343065Z","level":"info","event":"25/12/28 17:43:58 INFO SparkContext: SparkContext is stopping with exitCode 0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:58.469859Z","level":"info","event":"25/12/28 17:43:58 INFO SparkUI: Stopped Spark web UI at http://c252dd92c865:4040","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:58.536555Z","level":"info","event":"25/12/28 17:43:58 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:58.762056Z","level":"info","event":"25/12/28 17:43:58 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:58.762649Z","level":"info","event":"25/12/28 17:43:58 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:58.812105Z","level":"info","event":"25/12/28 17:43:58 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:58.848512Z","level":"info","event":"25/12/28 17:43:58 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:59.014306Z","level":"info","event":"25/12/28 17:43:59 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:59.936794Z","level":"info","event":"25/12/28 17:43:59 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:43:59.941835Z","level":"info","event":"25/12/28 17:43:59 INFO ShutdownHookManager: Deleting directory /tmp/spark-81a001ba-ad6f-4021-a624-631ae227165d","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:00.017976Z","level":"info","event":"25/12/28 17:44:00 INFO ShutdownHookManager: Deleting directory /tmp/spark-81a001ba-ad6f-4021-a624-631ae227165d/pyspark-eb831698-2620-4a50-af65-d1612fc31d9f","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:00.029639Z","level":"info","event":"25/12/28 17:44:00 INFO ShutdownHookManager: Deleting directory /tmp/spark-4fbc6d02-03b8-4b98-9023-c0774fbf4b4d","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:44:02.266371Z","level":"info","event":"SUCCESS","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:44:02.270752Z","level":"info","event":"Task instance in success state","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:44:02.272325Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:44:02.286276Z","level":"info","event":"Task operator:<Task(SparkSubmitOperator): extract_data>","logger":"task.stdout"}
