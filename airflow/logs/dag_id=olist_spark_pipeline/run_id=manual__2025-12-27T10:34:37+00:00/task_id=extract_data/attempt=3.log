{"timestamp":"2025-12-28T17:05:27.120347Z","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2025-12-28T17:05:27.122228Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/ecom_pipeline.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2025-12-28T17:05:27.450741Z","level":"warning","event":"The `airflow.hooks.base.BaseHook` attribute is deprecated. Please use `'airflow.sdk.bases.hook.BaseHook'`.","category":"DeprecatedImportWarning","filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py","lineno":35,"logger":"py.warnings"}
{"timestamp":"2025-12-28T17:05:27.580253Z","level":"info","event":"Task instance is in running state","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:05:27.580810Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:05:27.580977Z","level":"info","event":"Current task name:extract_data","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:05:27.581133Z","level":"info","event":"Dag name:olist_spark_pipeline","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:05:27.606886Z","level":"info","event":"Could not load connection string spark_default, defaulting to yarn","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":305}
{"timestamp":"2025-12-28T17:05:27.607371Z","level":"info","event":"Spark-Submit cmd: spark-submit --master yarn --name arrow-spark --verbose opt/airflow/srcextract.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":474}
{"timestamp":"2025-12-28T17:05:32.326636Z","level":"info","event":"Using properties file: null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:05:33.285906Z","level":"info","event":"Exception in thread \"main\" org.apache.spark.SparkException: When running with master 'yarn' either HADOOP_CONF_DIR or YARN_CONF_DIR must be set in the environment.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:05:33.299161Z","level":"info","event":"at org.apache.spark.deploy.SparkSubmitArguments.error(SparkSubmitArguments.scala:650)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:05:33.299319Z","level":"info","event":"at org.apache.spark.deploy.SparkSubmitArguments.validateSubmitArguments(SparkSubmitArguments.scala:281)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:05:33.300871Z","level":"info","event":"at org.apache.spark.deploy.SparkSubmitArguments.validateArguments(SparkSubmitArguments.scala:237)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:05:33.301182Z","level":"info","event":"at org.apache.spark.deploy.SparkSubmitArguments.<init>(SparkSubmitArguments.scala:122)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:05:33.305511Z","level":"info","event":"at org.apache.spark.deploy.SparkSubmit$$anon$2$$anon$3.<init>(SparkSubmit.scala:1103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:05:33.305688Z","level":"info","event":"at org.apache.spark.deploy.SparkSubmit$$anon$2.parseArguments(SparkSubmit.scala:1103)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:05:33.305804Z","level":"info","event":"at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:05:33.306131Z","level":"info","event":"at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:05:33.307948Z","level":"info","event":"at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:05:33.308152Z","level":"info","event":"at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-28T17:05:33.959106Z","level":"error","event":"Task failed with exception","logger":"task","filename":"task_runner.py","lineno":986,"error_detail":[{"exc_type":"AirflowException","exc_value":"Cannot execute: spark-submit --master yarn --name arrow-spark --verbose opt/airflow/srcextract.py. Error code is: 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":934,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1320,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":417,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py","lineno":197,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py","lineno":566,"name":"submit"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2025-12-28T17:05:34.520237Z","level":"info","event":"Task instance in failure state","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:05:34.522778Z","level":"info","event":"Task start","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:05:34.523354Z","level":"info","event":"Task:<Task(SparkSubmitOperator): extract_data>","logger":"task.stdout"}
{"timestamp":"2025-12-28T17:05:34.523726Z","level":"info","event":"Failure caused by Cannot execute: spark-submit --master yarn --name arrow-spark --verbose opt/airflow/srcextract.py. Error code is: 1.","logger":"task.stdout"}
